[
  {
    "id": "9c07149e-052e-40fa-b99a-8f4e4170cae2",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_1.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Module 1: StratÃ©gies de recherche"
      }
    ]
  },
  {
    "id": "9a3cb63f-c247-4f49-a7ee-f4a2898a850f",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_2.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Contenu du cours\n2ConsidÃ©rations pratiques et sociÃ©talesModule 10: Utilisation en industrie, Ã©thique, et philosophie Raisonnement par recherche (essais-erreurs avec de l'intuition)Module 1: StratÃ©gies de recherche Module 2: Recherche en prÃ©sence d'adversaires Module 3: Recherche locale \nRaisonnement par apprentissageModule 6: Apprentissage supervisÃ© Module 7: RÃ©seaux de neurones et apprentissage profond Module 8: Apprentissage non-supervisÃ© Module 9: Apprentissage par renforcement \nRaisonnement logiqueModule 4: Programmation par contraintes Module 5: Agents logiques"
      }
    ]
  },
  {
    "id": "51723490-ed91-4b06-9d37-bcc870fac06a",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_3.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Table des matiÃ¨res\n3StratÃ©gies de recherche1. DÃ©ï¬nition et modÃ©lisation d'un problÃ¨me de recherche 2. Agents rÃ©ï¬‚exes 3. Agents axÃ©s sur la recherche 4. Recherche en arbre (tree search) 5. Recherche sans information: DFS, BFS, UCS, IDS 6. Recherche avec information: greedy search, A* 7. Conception d'heuristiques 8. Recherche en graphe (graph search)ProblÃ¨mes abordÃ©s1. Pacman 2. 8-puzzle 3. Planiï¬cation de routes\nSDEPBACAEHRPQQFCGAHRQQFCGAQP"
      }
    ]
  },
  {
    "id": "b9f47048-cb7c-48f1-bd9a-c9dfa63f47df",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_4.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Cas d'Ã©tude: Pacman (1980)\n4\nComment implÃ©menter un agent eï¬ƒcace pour cette tÃ¢che ?Objectif: concevoir un agent mangeant tous les points en exÃ©cutant le moins de dÃ©placements possiblesHypothÃ¨ses simpliï¬catrices: pas de fantÃ´mes, et pas de bonus\nActions possibles pour Pacman: dÃ©placement Ã  gauche, droite, haut, ou bas"
      }
    ]
  },
  {
    "id": "c6622418-431b-4c29-801f-dba680790d38",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_5.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Agent rÃ©ï¬‚exe\n5PremiÃ¨re idÃ©e\n(1) Observer l'environnement actuel\nEst-ce que cet agent est rationnel ?Avantage: trÃ¨s rapide Ã  exÃ©cuterInconvÃ©nient: ne considÃ¨re pas les consÃ©quences des actions faites\n(3) Eï¬€ectuer l'action(2) Choisir une action en fonction de l'observationVariante: intÃ©gration Ã©ventuelle dâ€™un mÃ©canisme de mÃ©moireRÃ©sultat: une action sur base de l'observation et de la mÃ©moiref:ObservationÃ—MÃ©moireâ†’ActionExemple (Pacman)MÃ©moire: aucuneObservation (ou perception): la grille du jeuAction: prendre la direction du point le plus procheAgent qui agit en fonction de comment le monde lui apparait (sa perception actuelle)Agent rÃ©ï¬‚exe (reï¬‚ex agent)"
      }
    ]
  },
  {
    "id": "3266c2bb-20c8-46ec-8704-6a789060fc20",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_6.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Agent rÃ©ï¬‚exe: exemples\n6\nEst-ce qu'on agit parfois comme un agent rÃ©ï¬‚exe ?(1) L'instinct: sans rÃ©ï¬‚Ã©chir aux consÃ©quences de nos actionsComportement rationnelS'Ã©loigner d'une source de douleur (main sur une surface brÃ»lante)(2) Par urgence: lorsqu'on a pas le temps de prendre une dÃ©cision !Freiner en bloc lorsqu'un piÃ©ton apparaÃ®t brusquement sur la routeSituation 1Situation 2\nComportement non-rationnel\nCligner des yeux lorsqu'une poussiÃ¨re arrive Ã  notre paupiÃ¨re"
      }
    ]
  },
  {
    "id": "903bef4c-4972-477c-83dd-67349d6f8efe",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_7.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Agent axÃ© sur la recherche (planning agent)\n7Remarque: la dÃ©ï¬nition suppose l'existence d'un objectif, pouvant Ãªtre atteint par une sÃ©quence d'actionsAvantage: exploite de l'information Ã  long terme, menant Ã  une meilleure stratÃ©gie que l'agent rÃ©ï¬‚exeInconvÃ©nient: la simulation des scÃ©narios demandent plus de ressourcesInconvÃ©nient: demande de connaÃ®tre la dynamique du monde (l'impact de chaque action)Principe: diï¬€Ã©rents scÃ©narios sont simulÃ©s, jusqu'Ã  ce qu'une sÃ©quence favorable soit trouvÃ©e\nExemple pour Pacman: manger tous les pointsAgent qui va dÃ©rouler une sÃ©rie de scÃ©narios, dÃ©coulant des actions permises, aï¬n de trouver une sÃ©quence d'actions amenant Ã  la rÃ©alisation de l'objectifAgent axÃ© sur la recherche (planning agent)\nDÃ©ï¬ principal: dÃ©rouler eï¬ƒcacement les diï¬€Ã©rentes sÃ©quences d'actions possibles\nTemps dâ€™exÃ©cution: environ 10 secondes d'exÃ©cutionNombre dâ€™Ã©valuations: environ 3000 actions ont Ã©tÃ© Ã©valuÃ©es\nComment formaliser ce fonctionnement ?Solution: capture des points en un minimum de mouvements"
      }
    ]
  },
  {
    "id": "ca264315-bd48-45db-b1eb-2cc07fc6265d",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_8.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Formalisation d'un problÃ¨me de recherche\n8Ensemble d'Ã©tatsEnsemble d'actionsDÃ©ï¬nition: toutes les conï¬gurations possibles que peut prendre l'environnement\nCas de Pacman: dÃ©placement Ã  gauche, Ã  droite, en haut, ou en basProblÃ¨me consistant Ã  trouver la meilleure sÃ©quence d'action pour atteindre un Ã©tat ï¬nal Ã  partir d'un Ã©tat initial. Il est formellement dÃ©ï¬ni par:ProblÃ¨me de recherche\nS:unÂ ensembleÂ d'Ã©tatsÂ (contenantÂ unÂ Ã©tatÂ initialÂ etÂ un/desÂ Ã©tatsÂ ï¬naux)A:unÂ ensembleÂ d'actionsT:(SÃ—Aâ†’S):uneÂ fonctionÂ deÂ transitionÂ dÃ©crivantÂ leÂ nouvelÂ Ã©tatÂ Ã©manantÂ d'uneÂ actionC:(SÃ—Aâ†’â„):uneÂ fonctionÂ dÃ©crivantÂ leÂ coÃ»tÂ d'eï¬€ectuerÂ uneÂ actionÂ Ã Â partirÂ d'unÂ Ã©tatÂ \nInitialFinal\n...DÃ©ï¬nition: toutes les actions possibles que peut prendre lâ€™agent"
      }
    ]
  },
  {
    "id": "26d7434b-0e0f-4464-be9f-b7125d9e7c2f",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_9.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Formalisation d'un problÃ¨me de recherche\n9Fonction de transition et de coÃ»tFonction de transition: indique le nouvel Ã©tat si une action est faite Ã  partir d'un Ã©tat spÃ©ciï¬que\nSolutionDÃ©ï¬nition: sÃ©quence d'actions amenant un Ã©tat initial Ã  un Ã©tat ï¬nal\n(GAUCHE, 1)(DROITE, 1)\n...Transition de Pacman: le mouvement est eï¬€ectuÃ© et le point est mangÃ©, le cas Ã©chÃ©antFonction de coÃ»t: associe une valeur numÃ©rique Ã  lâ€™action rÃ©alisÃ©e sur cet Ã©tatCoÃ»t de lâ€™action: un coÃ»t unitaire est associÃ© Ã  chaque dÃ©placement\n(HAUT, 1)(DROITE, 1)"
      }
    ]
  },
  {
    "id": "0a18bd47-e170-4573-85a8-49111a2f5363",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_10.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "ProblÃ¨me rÃ©el de planiï¬cation de routes\n10Objectif : trouver le chemin le plus court entre Arad et Bucarest\nComment modÃ©liser cette situation en un problÃ¨me de recherche ?"
      }
    ]
  },
  {
    "id": "5c2ed5e6-83f4-489a-ba3b-7e7060b86f55",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_11.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "ModÃ©lisation d'un problÃ¨me\n11Etape 1: le problÃ¨me modÃ©lisÃ© est rÃ©solu via un algorithme de rÃ©solution\nOpÃ©ration consistante Ã  encoder notre problÃ¨me base dâ€™une formalisation particuliÃ¨reModÃ©lisation dâ€™un problÃ¨me\nExemple: on peut modÃ©liser un problÃ¨me sur base de la formalisation des slides prÃ©cÃ©dentsEtape 2: la solution est rÃ©-exprimÃ©e comme solution du problÃ¨me rÃ©el\nSibiuR. VilceaPitesti"
      }
    ]
  },
  {
    "id": "4ef191c8-2818-43c2-bca7-c365804eed82",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_12.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "ModÃ©lisation du monde rÃ©el\n12Abstraction trop forte: le modÃ¨le ne reï¬‚Ã¨te pas assez la rÃ©alitÃ©Abstraction trop faible: le modÃ¨le peut Ãªtre trop diï¬ƒcile Ã  rÃ©soudreSimpliï¬cation de la rÃ©alitÃ© qui est faite en dÃ©ï¬nissant le modÃ¨leNiveau dâ€™abstraction\nExemple de la planiï¬cation de routesAbstraction: considÃ©rer un sous-ensemble de villes et de liaisonsObjectif: atteindre Bucharest Ã  partir d'AradEnsemble dâ€™Ã©tats: toutes les positions possibles du modÃ¨leEtat initial et ï¬nal: Arad et BucharestEnsemble dâ€™actions: toutes les arÃªtes adjacentes Ã  notre positionFonction de coÃ»t: pÃ©nalisation Ã©gale Ã  la distance de l'arÃªteFonction de transition: eï¬€ectuer le dÃ©placement sur lâ€™arÃªte\nComment pourrait-on obtenir une abstraction plus proche de la rÃ©alitÃ© ?Exemples: plus de points de passages, information temps-rÃ©el, prÃ©sence de travaux, etc. \nUne abstraction faible permet de mieux reï¬‚Ã©ter la rÃ©alitÃ©, au dÃ©triment d'un modÃ¨le plus diï¬ƒcile Ã  rÃ©soudre"
      }
    ]
  },
  {
    "id": "ddefa0c5-7e46-4de3-9fb6-a7b93a585c19",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_13.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Il est important d'Ãªtre capable de calculer le nombre d'Ã©tats d'un modÃ¨le Taille de l'ensemble des Ã©tats\n13Objectif: trouver une sÃ©quence d'actions amenant un Ã©tat initial Ã  un Ã©tat ï¬nalNombre dâ€™Ã©lÃ©ments diï¬€Ã©rents dans lâ€™ensemble des Ã©tats (ou actions) du problÃ¨me de rechercheTaille de lâ€™ensemble des Ã©tats (ou actions)\nComment peut-on quantiï¬er la diï¬ƒcultÃ© Ã  rÃ©soudre dâ€™un problÃ¨me de recherche ?RÃ©ponse: il y a plusieurs facteurs, mais un trÃ¨s important est la taille de lâ€™ensemble des Ã©tats et dâ€™actionsIntuition: plus le nombre de possibilitÃ©s est grand, plus il sera diï¬ƒcile de trouver une bonne sÃ©quence\nCombien dâ€™Ã©tats sont prÃ©sents dans ce problÃ¨me de recherche ?Principe: on a un Ã©tat par position possible\nNombreÂ d'Ã©tats:20Observation: avec plus de villes, jâ€™agrandis mon nombre dâ€™Ã©tats\nRegardons un cas plus complexeNombre dâ€™actions: au maximum 4 (Ã  Sibiu)"
      }
    ]
  },
  {
    "id": "2d2eed09-7f13-4bef-8917-76115cbeda8c",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_14.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Taille de l'ensemble des Ã©tats\n14Exemple: niveau de Pacman avec 2 fantÃ´mes\nPositions possibles pour Pacman: 120Nombre de points Ã  manger: 30Positions possibles pour un fantÃ´me: 12\nCombien d'Ã©tats comporte cette reprÃ©sentation globale ?\nPacman:120Â possibilitÃ©s\n30Â points:2Ã—â€¦Ã—2=230Â possibilitÃ©s\n2Â fantomes:12Ã—12Â possibilitÃ©sNourriture: dÃ©ï¬ni par une valeur binaire (mangÃ© ou non)\nNombreÂ totalÂ d'Ã©tats=120Ã—230Ã—122=18,554,258,718,720Mauvaise nouvelle: la taille de lâ€™espace grandit exponentiellement avec le nombre dâ€™informations considÃ©rÃ©esBesoin: on a besoin dâ€™encoder toutes les conï¬gurations de plateau en Ã©tatsPacman: dÃ©ï¬ni par sa position (parmi 120 choix)FantÃ´me: dÃ©ï¬ni par sa position (parmi 12 choix)\nEn pratique: on est souvent intÃ©ressÃ© par avoir une borne supÃ©rieure sur le nombre dâ€™Ã©tatsIntuition: Ã§a nous donne une garantie sur le pire cas qui peut se produire"
      }
    ]
  },
  {
    "id": "3d3ad685-8b9e-4776-9156-00d1012575b4",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_15.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "ProblÃ¨me de recherche 1: chemin entre deux points\n15\nA t-on besoin de toutes les informations disponibles pour rÃ©soudre un problÃ¨me ?Bonne nouvelle: en fonction du problÃ¨me Ã  rÃ©soudre, une partie des informations peut Ãªtre ignorÃ©e Exemple dâ€™un problÃ¨me: trouver le chemin le plus court pour amener Pacman d'un point A Ã  un point B\nComment pourrait-on modÃ©liser ce problÃ¨me ?\nBAEnsemble d'Ã©tats: positions possibles de PacmanEtat initial: coordonnÃ©es de la position ATransition et coÃ»t: dÃ©placement de Pacman, avec un coÃ»t unitaireEtat ï¬nal: coordonnÃ©es de la position BActions: gauche, droite, haut, basDÃ©tection de lâ€™Ã©tat ï¬nal: les coordonnÃ©es de Pacman sont sur BBas:(x,y)â†(x,yâˆ’1)Haut:(x,y)â†(x,y+1)Gauche:(x,y)â†(xâˆ’1,y)Droite:(x,y)â†(x+1,y)xyEtatÂ ï¬nal:x=xBÂ etÂ y=yBEtat:(x,y)\nCombien a t-on d'Ã©tats ?EtatÂ initial:x=xAÂ etÂ y=yA\nNombreÂ totalÂ d'Ã©tats=120Conclusion: toutes les informations de l'environnement global ne sont pas nÃ©cessairesAnalyse: seulement les positions de Pacman sont utilisÃ©es (et non les fantÃ´mes ou les nourritures)Remarque: Ã  ce stade, on ne fait que modÃ©liser le problÃ¨me (sans essayer de le rÃ©soudre)"
      }
    ]
  },
  {
    "id": "d33ba94c-0720-43ea-a45f-d87e5266fb45",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_16.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "ProblÃ¨me de recherche 2: manger tous les points\n16Ensemble d'Ã©tats:\nCombien a t-on d'Ã©tats ?Etat initial: coordonnÃ©es initiales de Pacman, et 0 pour tous les pointsTransition et coÃ»t: dÃ©placement et prise de Pacman (coÃ»t unitaire)Etat ï¬nal: valeur de 1 pour tous les points (Pacman non important)Actions: gauche, droite, haut, bas (1) Positions possibles de Pacman - celles des points sont ï¬xes (2) Indication binaire pour chaque point (p), indiquant sâ€™il est mangÃ©\nQuelles informations devraient Ãªtre contenues dans un Ã©tat ?(1) Les informations nÃ©cessaires pour construire la fonction de transition (et qui changent de valeur)(2) Les informations nÃ©cessaires pour tester si un Ã©tat est ï¬nal \nProblÃ¨me: trouver le chemin le plus court pour manger tous les points\nComment pourrait-on modÃ©liser ce problÃ¨me ?\nEtat:(x,y,p1,p2,â€¦,pn)EtatÂ initial:(xA,yA,0,0,â€¦,0)EtatÂ ï¬nal:(_,_,1,1,â€¦,1)Nombre de points: 30\nNombreÂ totalÂ d'Ã©tats=120Ã—230=128,849,018,880Remarque: la position des points nâ€™est pas considÃ©rÃ© dans lâ€™Ã©tat car câ€™est une valeur ï¬xeValeur ï¬xe: valeur utilisÃ©e pour les transitions mais non considÃ©rÃ©e dans la recherche dâ€™une solutionA"
      }
    ]
  },
  {
    "id": "9af5c2a0-6f82-4efd-97a2-37e11492ab57",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_17.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "ReprÃ©sentation du problÃ¨me par un graphe des Ã©tats\n17\nComment rÃ©soudre un problÃ¨me de recherche ?PremiÃ¨re Ã©tape: on va reprÃ©senter de maniÃ¨re structurÃ©e le problÃ¨me de rechercheReprÃ©sentation dâ€™un problÃ¨me de recherche en un graphe, en liant tous les Ã©tats par leurs actionsGraphe des Ã©tats\nNoeud du graphe: un Ã©tat possibleArÃªte du graphe: une action, liant un Ã©tat avec son successeurPoids de l'arÃªte: coÃ»t de la transitionAvantage: reprÃ©sente explicitement le problÃ¨me Ã  rÃ©soudrePropriÃ©tÃ©: chaque Ã©tat nâ€™apparaÃ®t quâ€™une seule fois dans le grapheInconvÃ©nient: gÃ©nÃ©ralement trop gros pour Ãªtre mis en mÃ©moire \nSD\nPQHEBACFRG\nAvantage: cette reprÃ©sentation est gÃ©nÃ©rique\nCette reprÃ©sentation va nous servir de base pour  concevoir nos premiers algorithmes de rÃ©solutionInconvÃ©nient: plusieurs diï¬ƒcultÃ©s pour la conception dâ€™algorithmes"
      }
    ]
  },
  {
    "id": "2b1c5026-b16e-423a-9a4f-5469e48da651",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_18.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Illustration d'un algorithme de recherche\n18Etape 0: initialiser la recherche en se plaÃ§ant sur l'Ã©tat initial (S)Etape 1: maintenir une liste de candidats, correspondant Ã  lâ€™ensemble des voisins non Ã©tendus (fringe)Etape 2: choisir un Ã©tat dans cette liste, et Ã©tendre cet Ã©tat (succession)Etape 3: si le nouvel Ã©tat n'est pas un Ã©tat ï¬nal (G), rÃ©pÃ©ter le processus (Etapes 1 Ã  3)\nSD\nPQHEBACFRG\n[state:S,fringe:âŸ¨âŸ©]Etat initialSD\nPQHEBACFRG\n[state:S,fringe:âŸ¨D,E,PâŸ©]Mise Ã  jour des voisinsSD\nPQHEBACFRG\n[state:E,fringe:âŸ¨D,PâŸ©]Succession\nOk ! Construisons un premier algorithme pour aller dâ€™un Ã©tat initial S Ã  un Ã©tat ï¬nal Gstate:notreÂ Ã©tatÂ actuelÂ (enÂ vertÂ dansÂ l'exemple)fringe:l'ensembleÂ desÂ Ã©tatsÂ atteignablesÂ depuisÂ unÂ Ã©tatÂ visitÃ©Â maisÂ pasÂ encoreÂ explorÃ©Â (enÂ jaune)\nRemarque: notez bien que cette reprÃ©sentation est gÃ©nÃ©rique, et peut sâ€™appliquer Ã  notre situation Pacman"
      }
    ]
  },
  {
    "id": "b0a82115-e22a-477e-9fb2-4cfc425d753f",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_19.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Illustration d'un algorithme de recherche\n19SD\nPQHEBACFRGSD\nPQHEBACFRGSD\nPQHEBACFRG[state:S,fringe:âŸ¨âŸ©][state:S,fringe:âŸ¨D,E,PâŸ©][state:E,fringe:âŸ¨D,PâŸ©]\nSD\nPQHEBACFRG[state:E,fringe:âŸ¨D,P,H,RâŸ©]SD\nPQHEBACFRG[state:R,fringe:âŸ¨D,P,HâŸ©]SD\nPQHEBACFRG[state:R,fringe:âŸ¨D,P,H,FâŸ©]\nSD\nPQHEBACFRG[state:F,fringe:âŸ¨D,P,HâŸ©]SD\nPQHEBACFRG[state:G,path:Sâ†’Eâ†’Râ†’Fâ†’G]SD\nPQHEBACFRG[state:F,fringe:âŸ¨D,P,H,C,GâŸ©]"
      }
    ]
  },
  {
    "id": "e3ee32d7-4adc-4627-9eac-4affb83d993d",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_20.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Algorithme de recherche en graphe (graph search)\n20\ns=ğ—Œğ–¾ğ—…ğ–¾ğ–¼ğ—ğ– ğ—‡ğ–½ğ–±ğ–¾ğ—†ğ—ˆğ—ğ–¾(L)C={câˆˆğ—Œğ—ğ–¼ğ–¼ğ–¾ğ—Œğ—ˆğ—‹ğ—Œ(s,P)|cğ—‡ğ—ˆğ—ğ—‚ğ—‡V}ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—‡ğ—ˆğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¦ğ—‹ğ–ºğ—‰ğ—ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P):ğ—ğ—ğ—‚ğ—…ğ–¾Lâ‰ âˆ…:s=ğ—‚ğ—‡ğ—‚ğ—ğ—‚ğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P)L={s}V=âˆ…\nV=VâˆªsL=(LâˆªC)âˆ–sInitialisation: commencer Ã  l'Ã©tat initial du problÃ¨me Ã  rÃ©soudre (P)\nSD\nPQHEBACFRG\nStructure de donnÃ©es: garde en mÃ©moire les Ã©tats dÃ©jÃ  visitÃ©sFringe: ensemble des Ã©tats candidatsBoucle: tant qu'on a des candidats Ã  Ã©tendre\n... et les ajouter dans la fringe (en empÃªchant de le rÃ©gÃ©nÃ©rer lâ€™Ã©tat prÃ©cÃ©dent)Extension dâ€™un Ã©tat: retirer un noeud candidat de la fringe, et l'Ã©tendre\nMettre Ã  jour l'ensemble des Ã©tats visitÃ©s\nGestion de la fringe: comment choisir le prochain noeud Ã  Ã©tendre ?ğ—‚ğ–¿s=ğ—€ğ—ˆğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P):ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¾ğ—…ğ—Œğ–¾:ArrÃªt: si l'Ã©tat est ï¬nal, retourner la solution (chemin du noeud initial au ï¬nal)\nCette question va donner lieu Ã  diï¬€Ã©rents algorithmes de recherchesConsidÃ©rer les Ã©tats successeurs comme candidats, s'ils n'ont pas encore Ã©tÃ© pris...Sinonâ€¦Pas de solution: situation oÃ¹ on a pas rÃ©ussi Ã  atteindre lâ€™Ã©tat ï¬nal\nQuel est le point de conception majeur de cet algorithme ?On a ainsi notre premier algorithme de rÃ©solution !Bonne nouvelle: oï¬€re une excellente base pour plusieurs algorithmes"
      }
    ]
  },
  {
    "id": "0e77aa83-6515-495a-a1c9-269c92b573f0",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_21.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Algorithme de recherche en graphe (graph search)\n21\ns=ğ—Œğ–¾ğ—…ğ–¾ğ–¼ğ—ğ– ğ—‡ğ–½ğ–±ğ–¾ğ—†ğ—ˆğ—ğ–¾(L)C={câˆˆğ—Œğ—ğ–¼ğ–¼ğ–¾ğ—Œğ—ˆğ—‹ğ—Œ(s,P)|cğ—‡ğ—ˆğ—ğ—‚ğ—‡V}ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—‡ğ—ˆğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¦ğ—‹ğ–ºğ—‰ğ—ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P):ğ—ğ—ğ—‚ğ—…ğ–¾Lâ‰ âˆ…:s=ğ—‚ğ—‡ğ—‚ğ—ğ—‚ğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P)L={s}V=âˆ…\nV=VâˆªsL=(LâˆªC)âˆ–s\nSD\nPQHEBACFRG\nğ—‚ğ–¿s=ğ—€ğ—ˆğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P):ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¾ğ—…ğ—Œğ–¾:\nQuelle est la faiblesse majeure de cet algorithme ?Diï¬ƒcultÃ©: le nombre d'Ã©tats est souvent extrÃªmement grand CaractÃ©ristique: il demande de retenir tous les Ã©tats visitÃ©s (V)\nNombreÂ d'Ã©tatsÂ pourÂ Pacman:120Ã—230=128,849,018,880ProblÃ¨me 1: la mÃ©moire va vite Ãªtre saturÃ©e\nComment peut-on rÃ©soudre ce problÃ¨me ?IdÃ©e: ne pas retenir du tout les Ã©tats dÃ©jÃ  visitÃ©sRecherche en arbre: famille dâ€™algorithmes basÃ©s sur ce principeAvantage: rÃ©duit drastiquement la consommation mÃ©moire InconvÃ©nient: engendre un risque de retomber sur un Ã©tat dÃ©jÃ  vuProblÃ¨me 2: le coÃ»t dâ€™accÃ¨s Ã  la mÃ©moire sera plus important"
      }
    ]
  },
  {
    "id": "ecb9c372-1d7e-4ce7-af10-30bbb19a50a9",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_22.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "ReprÃ©sentation du problÃ¨me en arbre\n22Le problÃ¨me est reprÃ©sentÃ© comme un arbre, sur base du graphe des Ã©tatsRacine de l'arbre: l'Ã©tat initial du problÃ¨meNoeud de l'arbre: un Ã©tat possible (et implicitement les Ã©tats prÃ©cÃ©dents)Successeurs d'un noeud: tous les Ã©tats autorisÃ©s par la transitionPoids de l'arÃªte: coÃ»t de la transitionReprÃ©sentation du problÃ¨me en arbre, sur base du graphe des Ã©tatsReprÃ©sentation en arbre\nDiï¬€Ã©rence avec une reprÃ©sentation en graphe: les Ã©tats peuvent apparaÃ®tre plusieurs fois\nPropriÃ©tÃ© 1: les Ã©tats dÃ©jÃ  visitÃ©s ne sont pas mÃ©morisÃ©sPropriÃ©tÃ© 2: chaque Ã©tat peut apparaÃ®tre plusieurs fois dans l'arbrePropriÃ©tÃ© 3: l'arbre complet est gÃ©nÃ©ralement trop grand pour la mÃ©moire (voire inï¬ni)Bonne nouvelle: un stockage complet nâ€™est pas nÃ©cessaire (on oublie ce quâ€™on a vu)Noeud dans une recherche en graphe: un Ã©tat Noeud dans une recherche en arbre: un Ã©tat et implicitement la sÃ©quence d'actions pour y parvenir\nConcrÃ¨tement, quâ€™est-ce que Ã§a change au niveau de lâ€™algorithme ?"
      }
    ]
  },
  {
    "id": "aa0ac7d5-95fb-4e29-a032-878af110bd3f",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_23.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Algorithme de recherche en arbre (tree search)\n23\ns=ğ—Œğ–¾ğ—…ğ–¾ğ–¼ğ—ğ– ğ—‡ğ–½ğ–±ğ–¾ğ—†ğ—ˆğ—ğ–¾(L)C={câˆˆğ—Œğ—ğ–¼ğ–¼ğ–¾ğ—Œğ—ˆğ—‹ğ—Œ(s,P)|cğ—‡ğ—ˆğ—ğ—‚ğ—‡V}ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—‡ğ—ˆğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¦ğ—‹ğ–ºğ—‰ğ—ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P):ğ—ğ—ğ—‚ğ—…ğ–¾Lâ‰ âˆ…:s=ğ—‚ğ—‡ğ—‚ğ—ğ—‚ğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P)L={s}V=âˆ…\nV=VâˆªsL=(LâˆªC)âˆ–sğ—‚ğ–¿s=ğ—€ğ—ˆğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P):ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¾ğ—…ğ—Œğ–¾:\ns=ğ—Œğ–¾ğ—…ğ–¾ğ–¼ğ—ğ– ğ—‡ğ–½ğ–±ğ–¾ğ—†ğ—ˆğ—ğ–¾(L)C={câˆˆğ—Œğ—ğ–¼ğ–¼ğ–¾ğ—Œğ—ˆğ—‹ğ—Œ(s,P)}ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—‡ğ—ˆğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–³ğ—‹ğ–¾ğ–¾ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P):ğ—ğ—ğ—‚ğ—…ğ–¾Lâ‰ âˆ…:s=ğ—‚ğ—‡ğ—‚ğ—ğ—‚ğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P)L={s}L=LâˆªCğ—‚ğ–¿s=ğ—€ğ—ˆğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P):ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¾ğ—…ğ—Œğ–¾:V=âˆ…\nGrÃ¢ce Ã  notre formalisation gÃ©nÃ©rique, il nâ€™y a que peu de changementsInconvÃ©nient: recherche ralentie par la rÃ©pÃ©tition des Ã©tatsAvantage: permet une meilleure eï¬ƒcacitÃ© mÃ©moireUnique diï¬€Ã©rence: les Ã©tats dÃ©jÃ  visitÃ©s ne sont pas stockÃ©sEn pratique: on a un risque de retourner sur un Ã©tat dÃ©jÃ  visitÃ©Choix de conception: toujours la faÃ§on de retirer des noeuds de la fringe"
      }
    ]
  },
  {
    "id": "1472aa35-cf83-4c16-8f56-ec302538cd6b",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_24.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Deux grandes familles d'algorithmes de recherches\n24SD\nPQHEBACFRG\nSDEPBACAEHRPQQFCGAHRQQFCGAQP\nRecherche en graphe: consommation mÃ©moire plus lourde, mais exÃ©cution plus rapideRecherche en arbre: consommation mÃ©moire moins lourde, mais exÃ©cution plus lenteRemarque 1: ces deux stratÃ©gies ont plusieurs variantes permettant dâ€™autres compromisRemarque 2: elles ont Ã©galement chacune des diï¬ƒcultÃ©s spÃ©ciï¬ques Recherche en graphe: chaque noeud correspond Ã  un Ã©tatRecherche en arbre: chaque noeud est relatif au chemin empruntÃ©"
      }
    ]
  },
  {
    "id": "ffdf9688-0475-424c-9fc0-e7a702a6187d",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_25.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Diï¬ƒcultÃ© de la recherche en arbre\n25SA\nBG\nSABBGAGAGBGBGAG......\nQuelle diï¬ƒcultÃ© pratique voyez-vous avec une recherche en arbre ?Exemple pathologique: situation simple Ã  4 noeuds\nCombien de noeuds comporte l'arbre de recherche relatif ?RÃ©ponse: une inï¬nitÃ©â€¦ (mÃªme si le nombre d'Ã©tats est ï¬ni)Danger: si on n'y prend pas garde, une recherche dans un arbre peut cyclerRemarque: la possibilitÃ© d'avoir un arbre inï¬ni est une considÃ©ration cruciale pour la recherche en arbre\nCycle:Â Sâ†’Aâ†’Bâ†’Aâ†’Bâ†’..."
      }
    ]
  },
  {
    "id": "364e36ad-dc23-442a-a167-2b9101e318b0",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_26.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Table des matiÃ¨res\n26StratÃ©gies de recherche1. DÃ©ï¬nition et modÃ©lisation d'un problÃ¨me de recherche 2. Agents rÃ©ï¬‚exes 3. Agents axÃ©s sur la recherche 4. Recherche en arbre (tree search) 5. Recherche sans information: DFS, BFS, UCS, IDS 6. Recherche avec information: greedy search, A* 7. Conception d'heuristiques 8. Recherche en graphe (graph search)ProblÃ¨mes abordÃ©s1. Pacman 2. 8-puzzle 3. Planiï¬cation de routes\nSDEPBACAEHRPQQFCGAHRQQFCGAQP"
      }
    ]
  },
  {
    "id": "884d7282-756e-4f2f-8ce8-87b43db4551f",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_27.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Algorithme de recherche en arbreSDEPBACAEHRPQQFCGAHRQQFCGAQP\ns=ğ—Œğ–¾ğ—…ğ–¾ğ–¼ğ—ğ– ğ—‡ğ–½ğ–±ğ–¾ğ—†ğ—ˆğ—ğ–¾(L)C={câˆˆğ—Œğ—ğ–¼ğ–¼ğ–¾ğ—Œğ—ˆğ—‹ğ—Œ(s,P)}ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—‡ğ—ˆğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–³ğ—‹ğ–¾ğ–¾ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P):ğ—ğ—ğ—‚ğ—…ğ–¾Lâ‰ âˆ…:s=ğ—‚ğ—‡ğ—‚ğ—ğ—‚ğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P)L={s}L=LâˆªCğ—‚ğ–¿s=ğ—€ğ—ˆğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P):ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¾ğ—…ğ—Œğ–¾:V=âˆ…\nQuel est le point de conception majeur de cet algorithme ?Gestion de la fringe: comment choisir le prochain noeud Ã  Ã©tendre ?ConsidÃ©ration similaire Ã  la recherche en graphe\nRÃ©pondre Ã  cette question va donner lieu Ã  diï¬€Ã©rents algorithmes de recherche"
      }
    ]
  },
  {
    "id": "ed69940e-6c3a-4478-aff7-bf0522ac5908",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_28.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "CritÃ¨res de performance d'une recherche\n28\nComment Ã©valuer l'eï¬ƒcacitÃ© d'une stratÃ©gie de recherche ?CritÃ¨re 1: la complÃ©tude (completeness)Principe: garantie que le recherche va trouver une solution (s'il en existe une)\nCas contraire: garantie qu'un Ã©chec est reportÃ© CritÃ¨re 2: lâ€™optimalitÃ© (optimality)Principe: garantie que la recherche retourne la meilleure solution existante\nRemarque: cette solution correspond Ã  celle engendrant le moins de coÃ»tsCritÃ¨re 3: la complexitÃ© temporelle (time complexity)Principe: analyse du temps de calcul nÃ©cessaire pour exÃ©cuter la recherche\nNotation: souvent exprimÃ©e par la notation asymptotique dans le pire des casCritÃ¨re 4: la complexitÃ© spatiale (space complexity)\nPrincipe: analyse de la consommation mÃ©moire nÃ©cessaire pour exÃ©cuter la rechercheNotation: souvent exprimÃ©e par la notation asymptotique dans le pire des cas\nUne bonne analyse d'un algorithme de recherche doit tenir compte de ces quatre aspects\nğ’ª(n)Mesure: souvent calculÃ©e en fonction du nombre de noeuds explorÃ©s"
      }
    ]
  },
  {
    "id": "a16cf1f5-6c6a-4b6d-a10c-938f6b238160",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_29.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Analyse d'une recherche en arbre\n29...\nCombien de noeuds, au plus, y a t-il dans un arbre Ã  facteur de branchement b et de profondeur m ?NiveauÂ 1:1Â noeudNiveauÂ 3:b2Â noeudsNiveauÂ m:bmÂ noeudsParamÃ¨tresb:nombreÂ maximumÂ deÂ successeursÂ (branchingÂ factor)bm:profondeurÂ maximaleÂ deÂ l'arbreÂ (depth)m:Â noeudÂ correspondantÂ Ã Â unÂ Ã©tatÂ ï¬nal:Â noeudÂ deÂ recherche\nNiveauÂ 2:bÂ noeuds\nd:profondeurÂ deÂ laÂ solutionÂ laÂ plusÂ proched\n(b=5,m=10)â†’12,207,030Â noeuds(b=20,m=10)â†’10,778,947,368,420Â noeuds(b=5,m=20)â†’119,209,289,550,780Â noeudsBonne nouvelle: on peut concevoir des algorithmes qui nâ€™explorent pas tous les noeuds\n#noeuds=1+b+b2+â€¦+bm=ğ’ª(bm)"
      }
    ]
  },
  {
    "id": "6d415186-5d12-44a1-b803-4775f40d1473",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_30.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche en profondeur (DFS - depth ï¬rst search)\n30Algorithme de recherche consistant Ã  retirer systÃ©matiquement le dernier noeud ajoutÃ© Ã  la fringeRecherche en profondeur (DFS - depth ï¬rst search)\nPour avoir un algorithme concret, on doit indiquer quel noeud retirer en prioritÃ© de la fringeObservation: cela revient Ã  retirer en prioritÃ© le noeud le plus profond dans l'arbrePropriÃ©tÃ©: la fringe est une structure LIFO (last-in ï¬rst-out - dernier arrivÃ©, premier sorti)ğ—‰ğ—ğ—Œğ—(L,s):ajouteÂ l'Ã©lÃ©mentÂ sÂ Ã Â laÂ structureÂ Lğ—‰ğ—ˆğ—‰(L):retireÂ deÂ LÂ leÂ dernierÂ Ã©lÃ©mentÂ ajoutÃ©\ns=ğ—Œğ–¾ğ—…ğ–¾ğ–¼ğ—ğ– ğ—‡ğ–½ğ–±ğ–¾ğ—†ğ—ˆğ—ğ–¾(L)C={câˆˆğ—Œğ—ğ–¼ğ–¼ğ–¾ğ—Œğ—ˆğ—‹ğ—Œ(s,P)}ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—‡ğ—ˆğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–³ğ—‹ğ–¾ğ–¾ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P):ğ—ğ—ğ—‚ğ—…ğ–¾Lâ‰ âˆ…:s=ğ—‚ğ—‡ğ—‚ğ—ğ—‚ğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P)L={s}L=LâˆªCğ—‚ğ–¿s=ğ—€ğ—ˆğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P):ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¾ğ—…ğ—Œğ–¾:\ns=ğ—‰ğ—ˆğ—‰(L)C={câˆˆğ—Œğ—ğ–¼ğ–¼ğ–¾ğ—Œğ—ˆğ—‹ğ—Œ(s,P)}ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—‡ğ—ˆğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–£ğ–¾ğ—‰ğ—ğ—ğ–¥ğ—‚ğ—‹ğ—Œğ—ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P):ğ—ğ—ğ—‚ğ—…ğ–¾Lâ‰ âˆ…:s=ğ—‚ğ—‡ğ—‚ğ—ğ—‚ğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P)ğ—‰ğ—ğ—Œğ—(L,s)ğ—‰ğ—ğ—Œğ—(L,C)ğ—‚ğ–¿s=ğ—€ğ—ˆğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P):ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¾ğ—…ğ—Œğ–¾:L=ğ–«ğ–¨ğ–¥ğ–®()"
      }
    ]
  },
  {
    "id": "b81292d2-5db3-498b-bd73-b911aa458231",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_31.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche en profondeur - exemple\n31\ns=ğ—‰ğ—ˆğ—‰(L)C={câˆˆğ—Œğ—ğ–¼ğ–¼ğ–¾ğ—Œğ—ˆğ—‹ğ—Œ(s,P)}ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—‡ğ—ˆğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–£ğ–¾ğ—‰ğ—ğ—ğ–¥ğ—‚ğ—‹ğ—Œğ—ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P):ğ—ğ—ğ—‚ğ—…ğ–¾Lâ‰ âˆ…:s=ğ—‚ğ—‡ğ—‚ğ—ğ—‚ğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P)ğ—‰ğ—ğ—Œğ—(L,s)ğ—‰ğ—ğ—Œğ—(L,C)ğ—‚ğ–¿s=ğ—€ğ—ˆğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P):ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¾ğ—…ğ—Œğ–¾:L=ğ–«ğ–¨ğ–¥ğ–®()ExempleEtapeÂ 1:[state:S,fringe:âŸ¨DS,PS,ESâŸ©]EtapeÂ 3:[state:BD,fringe:âŸ¨AB,CD,ED,PS,ESâŸ©]EtapeÂ 2:[state:DS,fringe:âŸ¨BD,CD,ED,PS,ESâŸ©]EtapeÂ 4:[state:AB,fringe:âŸ¨CD,ED,PS,ESâŸ©]EtapeÂ 5:[state:CD,fringe:âŸ¨AC,ED,PS,ESâŸ©]EtapeÂ 7:[state:ED,fringe:âŸ¨HE,RE,PS,ESâŸ©]EtapeÂ 6:[state:AC,fringe:âŸ¨ED,PS,ESâŸ©]â€¦Notation: l'exposant indique l'Ã©tat parent d'un Ã©tat\nSDEPBACAEHRPQQFCGAHRQQFCGAQPstate:S,fringe:âŸ¨DS,PS,ESâŸ©SDEPBACAEHRPQQFCGAHRQQFCGAQPstate:BD,fringe:âŸ¨AB,CD,ED,PS,ESâŸ©SDEPBACAEHRPQQFCGAHRQQFCGAQPstate:DS,fringe:âŸ¨BD,CD,ED,PS,ESâŸ©"
      }
    ]
  },
  {
    "id": "b7d28fba-e073-466d-b72e-22455e3b2c9e",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_32.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche en profondeur - illustration\n32SDEPBACAEHRPQQFCGAHRQQFCGAQPstate:S,fringe:âŸ¨DS,PS,ESâŸ©SDEPBACAEHRPQQFCGAHRQQFCGAQPstate:BD,fringe:âŸ¨AB,CD,ED,PS,ESâŸ©SDEPBACAEHRPQQFCGAHRQQFCGAQPstate:DS,fringe:âŸ¨BD,CD,ED,PS,ESâŸ©SDEPBACAEHRPQQFCGAHRQQFCGAQPstate:AB,fringe:âŸ¨CD,ED,PS,ESâŸ©SDEPBACAEHRPQQFCGAHRQQFCGAQPstate:CD,fringe:âŸ¨AC,ED,PS,ESâŸ©SDEPBACAEHRPQQFCGAHRQQFCGAQPstate:AC,fringe:âŸ¨ED,PS,ESâŸ©"
      }
    ]
  },
  {
    "id": "a6c1bfe2-558b-45a6-9503-19631b1a39e6",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_33.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche en profondeur - analyse des performances\n33CritÃ¨re 3: complÃ©tude\nQuelles sont les performances d'une recherche en profondeur ?CritÃ¨re 1: complexitÃ© temporelle (pire des cas)Pire des cas: tout l'arbre doit Ãªtre explorÃ© pour trouver une solutionComplexitÃ©Â temporelle:Â ğ’ª(bm)(trÃ¨sÂ coÃ»teux)CritÃ¨re 2: complexitÃ© spatiale (pire des cas)Principe: revient Ã  Ã©valuer le nombre maximum de noeuds dans la fringeObservation: la profondeur (m) de l'arbre n'est pas bornÃ©e (cycle)ComplexitÃ©Â spatiale:Â ğ’ª(bm)Â (trÃ¨sÂ eï¬ƒcace)...bm\nm..................bbbbbbbCritÃ¨re 4: optimalitÃ©Observation: la recherche s'arrÃªte dÃ¨s qu'une solution est trouvÃ©e, pas forcÃ©ment de plus faible coÃ»tFringe: contient seulement les noeuds successeurs des noeuds se trouvant sur le chemin actuelObservation: les autres noeuds dÃ©jÃ  visitÃ©s (hors du chemin) ne doivent plus Ãªtre retenusConsÃ©quence: la recherche peut plonger dans une profondeur inï¬nieConclusion nÃ©gative: la recherche est incomplÃ¨teConclusion nÃ©gative: la recherche nâ€™est pas optimale"
      }
    ]
  },
  {
    "id": "e813eb38-e8ad-4511-bd97-9260f3599a9b",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_34.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche en largeur (BFS - breadth ï¬rst search)\n34Algorithme de recherche consistant Ã  retirer systÃ©matiquement le plus ancien noeud de la fringeRecherche en largeur (BFS - breadth ï¬rst search)\nLe manque de garanties (complÃ©tude et optimalitÃ©) du DFS est un problÃ¨me. A t-on une alternative ?Observation: cela revient Ã  retirer en prioritÃ© le noeud le moins profond dans l'arbrePropriÃ©tÃ©: la fringe est une structure FIFO (ï¬rst-in ï¬rst-out - premier arrivÃ©, premier sorti)ğ—‰ğ—ğ—Œğ—(L,s):ajouteÂ l'Ã©lÃ©mentÂ sÂ Ã Â laÂ structureÂ Lğ—‰ğ—ˆğ—‰(L):retireÂ l'Ã©lÃ©mentÂ leÂ plusÂ ancienÂ deÂ LBonne nouvelle: le reste est identique Ã  DFS! (une ligne de code de diï¬€Ã©rence)\ns=ğ—‰ğ—ˆğ—‰(L)C={câˆˆğ—Œğ—ğ–¼ğ–¼ğ–¾ğ—Œğ—ˆğ—‹ğ—Œ(s,P)}ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—‡ğ—ˆğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–£ğ–¾ğ—‰ğ—ğ—ğ–¥ğ—‚ğ—‹ğ—Œğ—ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P):ğ—ğ—ğ—‚ğ—…ğ–¾Lâ‰ âˆ…:s=ğ—‚ğ—‡ğ—‚ğ—ğ—‚ğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P)ğ—‰ğ—ğ—Œğ—(L,s)ğ—‰ğ—ğ—Œğ—(L,C)ğ—‚ğ–¿s=ğ—€ğ—ˆğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P):ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¾ğ—…ğ—Œğ–¾:L=ğ–«ğ–¨ğ–¥ğ–®()\ns=ğ—‰ğ—ˆğ—‰(L)C={câˆˆğ—Œğ—ğ–¼ğ–¼ğ–¾ğ—Œğ—ˆğ—‹ğ—Œ(s,P)}ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—‡ğ—ˆğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¡ğ—‹ğ–¾ğ–ºğ–½ğ—ğ—ğ–¥ğ—‚ğ—‹ğ—Œğ—ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P):ğ—ğ—ğ—‚ğ—…ğ–¾Lâ‰ âˆ…:s=ğ—‚ğ—‡ğ—‚ğ—ğ—‚ğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P)ğ—‰ğ—ğ—Œğ—(L,s)ğ—‰ğ—ğ—Œğ—(L,C)ğ—‚ğ–¿s=ğ—€ğ—ˆğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P):ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¾ğ—…ğ—Œğ–¾:L=ğ–¥ğ–¨ğ–¥ğ–®()"
      }
    ]
  },
  {
    "id": "b6fd78a3-42a2-41a8-bfe4-5ee0cf919d1c",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_35.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche en largeur (BFS - breadth ï¬rst search)\n35EtapeÂ 1:[state:S,fringe:âŸ¨DS,PS,ESâŸ©]EtapeÂ 3:[state:PS,fringe:âŸ¨ES,BD,CD,ED,QPâŸ©]EtapeÂ 2:[state:DS,fringe:âŸ¨PS,ES,BD,CD,EDâŸ©]EtapeÂ 4:[state:ES,fringe:âŸ¨BD,CD,ED,QP,HE,REâŸ©]EtapeÂ 5:[state:BD,fringe:âŸ¨CD,ED,QP,HE,RE,ABâŸ©]EtapeÂ 7:[state:ED,fringe:âŸ¨QP,HE,RE,AB,AC,HE,REâŸ©]EtapeÂ 6:[state:CD,fringe:âŸ¨ED,QP,HE,RE,AB,ACâŸ©]â€¦\ns=ğ—‰ğ—ˆğ—‰(L)C={câˆˆğ—Œğ—ğ–¼ğ–¼ğ–¾ğ—Œğ—ˆğ—‹ğ—Œ(s,P)}ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—‡ğ—ˆğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¡ğ—‹ğ–¾ğ–ºğ–½ğ—ğ—ğ–¥ğ—‚ğ—‹ğ—Œğ—ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P):ğ—ğ—ğ—‚ğ—…ğ–¾Lâ‰ âˆ…:s=ğ—‚ğ—‡ğ—‚ğ—ğ—‚ğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P)ğ—‰ğ—ğ—Œğ—(L,s)ğ—‰ğ—ğ—Œğ—(L,C)ğ—‚ğ–¿s=ğ—€ğ—ˆğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P):ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¾ğ—…ğ—Œğ–¾:L=ğ–¥ğ–¨ğ–¥ğ–®()Exemple\nSDEPBACAEHRPQQFCGAHRQQFCGAQPstate:S,fringe:âŸ¨DS,PS,ESâŸ©SDEPBACAEHRPQQFCGAHRQQFCGAQPstate:PS,fringe:âŸ¨ES,BD,CD,ED,QPâŸ©SDEPBACAEHRPQQFCGAHRQQFCGAQPstate:DS,fringe:âŸ¨PS,ES,BD,CD,EDâŸ©"
      }
    ]
  },
  {
    "id": "d2cca305-6c96-4ca7-bebf-73552f6db071",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_36.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche en largeur - illustration\n36SDEPBACAEHRPQQFCGAHRQQFCGAQPstate:S,fringe:âŸ¨DS,PS,ESâŸ©SDEPBACAEHRPQQFCGAHRQQFCGAQPstate:PS,fringe:âŸ¨ES,BD,CD,ED,QPâŸ©SDEPBACAEHRPQQFCGAHRQQFCGAQPstate:DS,fringe:âŸ¨PS,ES,BD,CD,EDâŸ©SDEPBACAEHRPQQFCGAHRQQFCGAQPstate:ES,fringe:âŸ¨BD,CD,ED,QP,HE,REâŸ©SDEPBACAEHRPQQFCGAHRQQFCGAQP\nstate:BD,fringe:âŸ¨CD,ED,QP,HE,RE,ABâŸ©SDEPBACAEHRPQQFCGAHRQQFCGAQPstate:CD,fringe:âŸ¨ED,QP,HE,RE,AB,ACâŸ©"
      }
    ]
  },
  {
    "id": "9220ed21-6cff-4a38-9dd2-c8084046c969",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_37.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche en largeur - analyse\n37Observation: les niveaux infÃ©rieurs au premier Ã©tat ï¬nal doivent Ãªtre explorÃ©s\nObservation: mÃªme en cas de profondeur inï¬nie une solution sera trouvÃ©e (sâ€™il en existe une)Conclusion positive: optimal si tous les coÃ»ts ont la mÃªme valeurFringe: peut contenir tous les noeuds d'un niveau spÃ©ciï¬que de l'arbreObservation: les autres noeuds visitÃ©s (niveaux infÃ©rieurs) ne doivent plus Ãªtre retenus\n............dbdÂ noeudsObservation: la solution retournÃ©e est celle ayant le moins d'actionsConclusion nÃ©gative: non-optimal dans le cas gÃ©nÃ©ralCritÃ¨re 3: complÃ©tude\nQuelles sont les performances d'une recherche en largeur ?CritÃ¨re 1: complexitÃ© temporelleCritÃ¨re 2: complexitÃ© spatiale (pire des cas)\nCritÃ¨re 4: optimalitÃ©ComplexitÃ©Â temporelle:Â ğ’ª(bd)(trÃ¨sÂ coÃ»teux)ComplexitÃ©Â spatiale:Â ğ’ª(bd)(trÃ¨sÂ coÃ»teux)Intuition: on explore niveau par niveauConclusion positive: la recherche est complÃ¨te...bmd"
      }
    ]
  },
  {
    "id": "482ae21b-1344-4a0f-aa22-df211d1a8b9c",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_38.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "DFS vs BFS: visualisation\n38\nRecherche en largeur\nQuelle stratÃ©gie de recherche a Ã©tÃ© appliquÃ©e ?\nRecherche en profondeur\nRecherche en profondeurRecherche en largeur"
      }
    ]
  },
  {
    "id": "61bb3860-bffc-4a6d-afa2-cfbe2f966786",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_39.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "DFS vs BFS: comparaison\n39\nQuand une alternative est-elle prÃ©fÃ©rable Ã  une autre ?\nArgument 1: lorsque l'arbre est bornÃ© (moyen d'enlever les cycles)Argument 2: lorsqu'avoir la meilleure solution n'est pas importantArgument 3: lorsque la consommation mÃ©moire doit Ãªtre limitÃ©eArgument 1: lorsquâ€™il est important d'obtenir la solution optimale\nEn pratique: souvent, en plan B face Ã  un BFS trop coÃ»teux\nArguments pour une recherche en largeur\nSouhait 1: complÃ©tude et optimalitÃ© de la recherche en largeurSouhait 2: consommation mÃ©moire similaire Ã  une recherche en profondeurArgument 2: lorsqu'obtenir une solution ne requiert que peu d'actionsArgument 3: lorsqu'on a une trÃ¨s bonne capacitÃ© mÃ©moireArguments pour une recherche en profondeur\nPeut-on faire mieux ?On aimerait pouvoir exploiter les points forts des deux mÃ©thodes\nComment rÃ©aliser cela ?"
      }
    ]
  },
  {
    "id": "ab916a4c-e544-4e9c-ac9a-286080170103",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_40.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche Ã  profondeur itÃ©rÃ©e  (Iterative deepening search - IDS)\n40Aucune solution: relancer un DFS jusqu'Ã  un niveau en dessousSolution trouvÃ©e: stopper la recherche et retourner la solutionAlgorithme de recherche qui exÃ©cute des DFS, en augmentant itÃ©rativement la profondeur maximaleRecherche Ã  profondeur itÃ©rÃ©e (IDS - iterative deepening search)\nMotivation: combiner les avantages d'un DFS avec un BFSbd...1234\ns=ğ—‰ğ—ˆğ—‰(L)C={câˆˆğ—Œğ—ğ–¼ğ–¼ğ–¾ğ—Œğ—ˆğ—‹ğ—Œ(s,P)|ğ–½ğ–¾ğ—‰ğ—ğ—(c)â‰¤d}ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡âˆ…ğ–£ğ–¾ğ—‰ğ—ğ—ğ–«ğ—‚ğ—†ğ—‚ğ—ğ–¾ğ–½ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P,d):ğ—ğ—ğ—‚ğ—…ğ–¾Lâ‰ âˆ…:s=ğ—‚ğ—‡ğ—‚ğ—ğ—‚ğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P)ğ—‰ğ—ğ—Œğ—(L,s)ğ—‰ğ—ğ—Œğ—(L,C)ğ—‚ğ–¿s=ğ—€ğ—ˆğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P):ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¾ğ—…ğ—Œğ–¾:L=ğ–«ğ–¨ğ–¥ğ–®()ComplexitÃ©Â spatiale:Â ğ’ª(bd)Â (hÃ©ritageÂ duÂ DFS)ComplexitÃ©Â temporelle:ğ’ª(bd)+travailÂ redondantComplÃ©tude:Â rechercheÂ complÃ¨teÂ (hÃ©ritageÂ duÂ BFS)OptimalitÃ©:Â oui,Â siÂ lesÂ coÃ»tsÂ sontÂ identiquesÂ (hÃ©ritageÂ duÂ BFS)\nQuâ€™en est-il des performances ?Intuition: un BFS est simulÃ© en exÃ©cutant des DFS successifs\nDFS bornÃ© Ã  la profondeur d\nğ–¨ğ—ğ–¾ğ—‹ğ–ºğ—ğ—‚ğ—ğ–¾ğ–£ğ–¾ğ–¾ğ—‰ğ–¾ğ—‡ğ—‚ğ—‡ğ—€ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P):ğ–¿ğ—ˆğ—‹dâˆˆ1ğ—ğ—ˆâˆ:s=ğ–£ğ–¾ğ—‰ğ—ğ—ğ–«ğ—‚ğ—†ğ—‚ğ—ğ–¾ğ–½ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P,d)ğ—‚ğ–¿sâ‰ âˆ…:ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡s"
      }
    ]
  },
  {
    "id": "ccad670b-f47f-4824-b9e7-90cb894a3959",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_41.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Iterative deepening search - illustration\n41SDEPBACAEHRPQQFCGAHRQQFCGAQPğ–½ğ–¾ğ—‰ğ—ğ—=0SDEPBACAEHRPQQFCGAHRQQFCGAQPğ–½ğ–¾ğ—‰ğ—ğ—=1SDEPBACAEHRPQQFCGAHRQQFCGAQPğ–½ğ–¾ğ—‰ğ—ğ—=1\nSDEPBACAEHRPQQFCGAHRQQFCGAQPğ–½ğ–¾ğ—‰ğ—ğ—=1SDEPBACAEHRPQQFCGAHRQQFCGAQPğ–½ğ–¾ğ—‰ğ—ğ—=1\nSDEPBACAEHRPQQFCGAHRQQFCGAQPğ–½ğ–¾ğ—‰ğ—ğ—=2SDEPBACAEHRPQQFCGAHRQQFCGAQPğ–½ğ–¾ğ—‰ğ—ğ—=2SDEPBACAEHRPQQFCGAHRQQFCGAQPğ–½ğ–¾ğ—‰ğ—ğ—=2"
      }
    ]
  },
  {
    "id": "98f71b30-c971-4058-9eaa-8e8b83009a37",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_42.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "#noeudsÂ explorÃ©s:db+(dâˆ’1)b2+(dâˆ’2)b3+â€¦+2bdâˆ’1+bdIterative deepening search - analyse\n42\nEst-ce un gros problÃ¨me ?\nConclusion: en pratique, IDS est une stratÃ©gie majoritairement prÃ©fÃ©rable Ã  un DFS ou un BFS simpleObservation: IDS redemande de rÃ©-explorer des noeuds de l'arbre de rechercheDiï¬ƒcultÃ©: la recherche souï¬€re ainsi de redondance par rapport Ã  DFS ou BFSObservation: câ€™est particuliÃ¨rement le cas pour les noeuds proches de la racine\nFait: câ€™est exact qu'une certaine quantitÃ© de travail redondant est nÃ©cessaireBonne nouvelle: ce travail redondant est relativement nÃ©gligeable\nRecherche en largeur 10+100+1,000+10,000+100,000=111,110#noeuds:b+b2+b3+b4+b5\nIterative deepening search50+400+3,000+20,000+100,000=123,450#noeuds:db+(dâˆ’1)b2+(dâˆ’2)b3+(dâˆ’3)b4+b5Observation: seulement environ 11% de noeuds supplÃ©mentaires (et sâ€™attÃ©nue plus le problÃ¨me est grand)Observation: le 1er niveau doit Ãªtre explorÃ© d fois, le 2eme d-1 fois, etc.\nExemple: considÃ©rons une situation avec b = 10 et d = 5bd...1234\nExplication: le gros du travail se fait sur le dernier niveau qui est nâ€™explorÃ© quâ€™une fois dans les deux cas"
      }
    ]
  },
  {
    "id": "000a5d99-7b45-4f45-a0a3-0ec49f6dc451",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_43.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "ProblÃ¨mes de recherche avec coÃ»ts non identiques\n43SD\nPQHEBACFRG\nToutes nos situations avaient des coÃ»ts identiques ! Que se passe t-il si ce nâ€™est pas le cas ?\nSD\nPQHEBACFRG21823911582124432\nDiï¬€Ã©rence: chaque action a un coÃ»t qui lui est propre (p.e., une distance entre deux noeuds)Solution optimale: celle ayant le plus petit coÃ»t (somme des coÃ»ts des actions faites)\nQue va faire une recherche en largeur ? Nature du BFS: donne la solution la plus proche en termes de nombre d'actionsObservation: cela ne correspond pas toujours Ã  la solution optimale !\nDans cette situation, BFS (et notre version d'IDS) perdent leur comportement optimal"
      }
    ]
  },
  {
    "id": "c5a2b035-c493-47e4-b76f-895b0f327337",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_44.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche Ã  coÃ»t uniforme (UCS - uniform cost search)\n44CoÃ»t d'un noeud: correspond Ã  la somme des coÃ»ts depuis la racineAlgorithme de recherche consistant Ã  retirer systÃ©matiquement le noeud ayant le plus faible coÃ»tRecherche Ã  coÃ»t uniforme (UCS - uniform cost search)\nNouvel Ã©lÃ©ment: on intÃ¨gre une fonction de coÃ»t pour un noeudSD\nPQHEBACFRG21823911582124432\ng(n):ğ–­ğ—ˆğ–½ğ–¾â†’â„1:[state:S,fringe:âŸ¨(D,3)S,(P,1)S,(E,9)SâŸ©]2:[state:PS,fringe:âŸ¨(D,3)S,(E,9)S,(Q,16)PâŸ©]3:[state:DS,fringe:âŸ¨(E,9)S,(Q,16)P,(B,4)D,(C,11)D,(E,5)DâŸ©]4:[state:BD,fringe:âŸ¨(E,9)S,(Q,16)P,(C,11)D,(E,5)D,(A,6)BâŸ©]5:[state:ED,fringe:âŸ¨(E,9)S,(Q,16)P,(C,11)D,(A,6)B,(H,13)E,(R,7)EâŸ©]6:[state:AB,fringe:âŸ¨(E,9)S,(Q,16)P,(C,11)D,(H,13)E,(R,7)EâŸ©]7:[state:RE,fringe:âŸ¨(E,9)S,(Q,16)P,(C,11)D,(H,13)E,(F,8)RâŸ©]8:[state:FR,fringe:âŸ¨(E,9)S,(Q,16)P,(C,11)D,(H,13)E,(G,10)F,(C,11)FâŸ©]9:[state:ES,fringe:âŸ¨(Q,16)P,(C,11)D,(H,13)E,(G,10)F,(H,17)E,(R,11)EâŸ©]10:[state:GF,path:Sâ†’Dâ†’Eâ†’Râ†’Fâ†’G,cost:10]Exemple: exÃ©cution de lâ€™algorithme sur cette situationPrincipe: les coÃ»ts sont calculÃ©s quand le noeud est dans la frontiÃ¨re\nS,0D,3E,9P,1B,4A,6C,11A,13E,5H,13R,7P,17Q,17Q,32F,8C,11G,10A,13H,17R,11Q,21Q,36F,12C,15G,14A,17Q,16P,21Notation: le nombre aprÃ¨s lâ€™Ã©tat indique son coÃ»t"
      }
    ]
  },
  {
    "id": "fa200d29-18f3-4872-b5a9-a96b410b1482",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_45.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "UCS - PiÃ¨ge classique et algorithme\n45\nPeut-on arrÃªter la recherche, vu qu'un Ã©tat ï¬nal est dans la fringe ?Explication: rien nâ€™assure que via E, il n'existe pas un chemin de plus faible coÃ»tConclusion: la recherche est ï¬nie QUE si vous Ãªtes Ã  l'Ã©tat ï¬nalAlgorithme: implÃ©mentation de la fringe par une liste de prioritÃ©\ns=ğ—‰ğ—ˆğ—‰(L)C={âŸ¨c,g(c)âŸ©âˆˆğ—Œğ—ğ–¼ğ–¼ğ–¾ğ—Œğ—ˆğ—‹ğ—Œ(s,P)}ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—‡ğ—ˆğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–´ğ—‡ğ—‚ğ–¿ğ—ˆğ—‹ğ—†ğ–¢ğ—ˆğ—Œğ—ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P):ğ—ğ—ğ—‚ğ—…ğ–¾Lâ‰ âˆ…:s=ğ—‚ğ—‡ğ—‚ğ—ğ—‚ğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P)ğ—‰ğ—ğ—Œğ—(L,s,g(s))ğ—‰ğ—ğ—Œğ—(L,C)ğ—‚ğ–¿s=ğ—€ğ—ˆğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P):ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¾ğ—…ğ—Œğ–¾:L=ğ–¯ğ—‹ğ—‚ğ—ˆğ—‹ğ—‚ğ—ğ—’ğ–°ğ—ğ–¾ğ—ğ–¾()CoÃ»t: chaque noeud doit contenir en plus l'information de son coÃ»tS,0D,3E,9P,1B,4A,6C,11A,13E,5H,13R,7P,17Q,17Q,32F,8C,11G,10A,13H,17R,11Q,21Q,36F,12C,15G,14A,17Q,16P,21\nEtapeÂ 8:[state:FR,fringe:âŸ¨(E,9)S,(Q,16)P,(C,11)D,(H,13)E,(G,10)F,(C,11)FâŸ©]Attention: mÃªme si l'Ã©tat ï¬nal est dans la fringe, il ne doit pas Ãªtre Ã©tendu en prioritÃ©\nğ—‰ğ—ğ—Œğ—(L,s,g(s)):ajouteÂ sÂ etÂ sonÂ coÃ»tÂ Ã Â laÂ structureÂ Lğ—‰ğ—ˆğ—‰(L):retireÂ l'Ã©lÃ©mentÂ ayantÂ leÂ plusÂ petitÂ coÃ»tÂ g(s)\ncoÃ»tÂ deÂ c=coÃ»tÂ deÂ s+coÃ»tÂ deÂ laÂ transitionÂ sâ†’cg(c)=g(s)+d(sâ†’c)"
      }
    ]
  },
  {
    "id": "9a362375-35d6-4b0b-9bd0-d7417ae95f10",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_46.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "UCS - illustration\n46\nSituation: la zone bleue a un coÃ»t supÃ©rieurEquivalent Ã  une recherche en largeurSituation: tous les coÃ»ts sont identiquesRetourne la solution optimale (et non le BFS)BFS"
      }
    ]
  },
  {
    "id": "978eb9fa-524c-4a92-9c93-9f25813d8b34",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_47.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche Ã  coÃ»t uniforme - analyse des performances\n47bb:nombreÂ maximumÂ deÂ successeursÂ (branchingÂ factor)Câ‹†:coÃ»tÂ deÂ laÂ solutionÂ optimaleÏµ:borneÂ infÃ©rieureÂ surÂ leÂ coÃ»tÂ d'uneÂ actionCâ‹†Ïµ:profondeurÂ deÂ laÂ solutionÂ optimaleÂ dansÂ leÂ pireÂ desÂ casÂ (eï¬€ectiveÂ depth)...Câ‹†Ïµdd:profondeurÂ deÂ laÂ solutionÂ laÂ plusÂ proche\nCritÃ¨re 3: complÃ©tudeCritÃ¨re 1: complexitÃ© temporelleCritÃ¨re 2: complexitÃ© spatiale (pire des cas)CritÃ¨re 4: optimalitÃ©\nQuelles sont les performances d'une recherche Ã  coÃ»t uniforme ?\nConclusion: toutes les solutions se situant avant la profondeur eï¬€ective doivent Ãªtre explorÃ©es Intuition: tous les noeuds ayant un coÃ»t moindre que celui de la meilleure solution seront Ã©tendusComplexitÃ©Â temporelle:Â ğ’ª(bCâ‹†/Ïµ)Â (trÃ¨sÂ coÃ»teux,Â potentiellementÂ plusÂ queÂ ğ’ª(bd))ComplexitÃ©Â spatiale:Â ğ’ª(bCâ‹†/Ïµ)Observation: similaire Ã  BFS, mais sur base de la profondeur eï¬€ective (tous les noeuds du dernier niveau)Bonne nouvelle: recherche complÃ¨te (hypothÃ¨se que les coÃ»ts sont positifs et ï¬nis)Bonne nouvelle: la recherche est optimale (mÃªme argument que pour la recherche en largeur)"
      }
    ]
  },
  {
    "id": "eb2d8002-c6a0-4eb6-a393-a98f412235b1",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_48.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche Ã  coÃ»t uniforme\n48\nPropriÃ©tÃ©: logiquement Ã©quivalent Ã  UCS (mÃªme ordre d'extension)Exemples: rÃ©seaux routiers, tÃ©lÃ©communications, etc.Algorithme de DijkstraTerminologie: utilisÃ©e par la communautÃ© des sciences informatiquesApplications: principalement pour rÃ©fÃ©rer Ã  des problÃ¨mes de rÃ©seauxRecherche Ã  coÃ»t uniforme\nTaille du graphe: souvent raisonnable dans ces applicationsTerminologie: utilisÃ©e par la communautÃ© de lâ€™intelligence artiï¬cielleChamps dâ€™application: recherche en graphe et recherche en arbreDiï¬ƒcultÃ©: la taille croÃ®t exponentiellement avec le nombre d'Ã©tatsDiï¬ƒcultÃ©: la taille de lâ€™arbre est Ã©ventuellement inï¬nieEn fonction de l'implÃ©mentation, quelques diï¬€Ã©rences peuvent exister\nPourquoi doit-on apprendre un nouvel algorithme - et ne pas rester sur Dikstra ?"
      }
    ]
  },
  {
    "id": "297a39bb-03a2-4483-ae7a-ccd76ebd96ff",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_49.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche Ã  coÃ»t uniforme vs Dijkstra\n49\nI claim that UCS is superior to DA in almost all aspects. It is easier to understand and implement. \nIts time and memory needs are also smaller.\nThe reason that DA is taught in universities and classes around the world is probably only historical.\nI encourage people to stop using and teaching DA, and focus on UCS only.\nPosition paper: Dijkstra's algorithm versus uniform cost search or a case against Dijkstra's algorithm [Felner, 2011]Remarque: il sâ€™agit dâ€™un papier dâ€™opinion, qui garde une certaine subjectivitÃ©Reste du papier: analyse de UCS et de Dijkstra Conclusion gÃ©nÃ©rale: ne plus utiliser (ni enseigner) Dijkstra, et considÃ©rer UCS Ã  la place Opinion personnelle: je prÃ©fÃ¨re Ã©galement UCS, par lâ€™aspect gÃ©nÃ©rique avec les autres algorithmes"
      }
    ]
  },
  {
    "id": "9884d6ab-fe14-4366-b438-00314ce87a09",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_50.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Table des matiÃ¨res\n50StratÃ©gies de recherche1. DÃ©ï¬nition et modÃ©lisation d'un problÃ¨me de recherche 2. Agents rÃ©ï¬‚exes 3. Agents axÃ©s sur la recherche 4. Recherche en arbre (tree search) 5. Recherche sans information: DFS, BFS, UCS, IDS 6. Recherche avec information: greedy search, A* 7. Conception d'heuristiques 8. Recherche en graphe (graph search)ProblÃ¨mes abordÃ©s1. Pacman 2. 8-puzzle 3. Planiï¬cation de routes\nSDEPBACAEHRPQQFCGAHRQQFCGAQP"
      }
    ]
  },
  {
    "id": "edf11107-59db-4886-9e2f-7947d26ebcff",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_51.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Motivation des stratÃ©gies de recherche avec information\n51\n On a dÃ©jÃ  vu 4 algorithmes de rÃ©solution ! Pourquoi en voir des nouveaux ?Bonne nouvelle: le dernier algorithme vu (UCS) est complet et optimalMauvaise nouvelle: il est trÃ¨s coÃ»teux en termes de mÃ©moire et de temps dâ€™exÃ©cution\nQuâ€™est-ce quâ€™on pourrait faire pour amÃ©liorer les performances ?Observation: on n'utilise aucune information spÃ©ciï¬que au problÃ¨me Ã  rÃ©soudreObservation: lâ€™exploration se fait de maniÃ¨re symÃ©trique (sur base des coÃ»ts) par rapport Ã  l'Ã©tat initialConsÃ©quence: on va autant explorer dans toutes les directions avant d'atteindre l'objectif\nSGSG\nIdÃ©e: essayer dâ€™orienter la recherche vers vers des Ã©tats que l'on pense Ãªtre de bonne qualitÃ©Exemple: de MontrÃ©al Ã  QuÃ©bec, est-ce plus probable de passer par Trois-RiviÃ¨re ou Toronto ?"
      }
    ]
  },
  {
    "id": "17d88752-79e9-4930-8ea1-07ef1b4bebad",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_52.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "StratÃ©gie de recherche avec information (informed search)\n52CritÃ¨re 1: le type de connaissance Ã  injecter Ã  la rechercheStratÃ©gie de recherche qui utilise des connaissances spÃ©ciï¬ques au problÃ¨me aï¬n d'orienter la recherche vers des Ã©tats qui nous paraissent plus prometteursStratÃ©gie de recherche avec information (informed search)\nQuels sont les points de conception majeurs de cette famille de mÃ©thode ?\nCritÃ¨re 2: la faÃ§on d'injecter cette connaissance dans la stratÃ©gie de recherche(1) La nature de la connaissance Ã  injecter(2) La validitÃ© et propriÃ©tÃ©s de la connaissance(4) Le degrÃ© de conï¬ance que l'on veut avoir dans la connaissance injectÃ©e(3) La complexitÃ© temporelle pour obtenir cette connaissance(5) Les propriÃ©tÃ©s souhaitÃ©es pour la stratÃ©gie (complexitÃ© spatiale, temporelle, complÃ©tude, optimalitÃ©)\nOn rentre vraiment dans de l'intelligence artiï¬cielle,  en insÃ©rant une forme d'intelligence Ã  nos stratÃ©gies de recherche !"
      }
    ]
  },
  {
    "id": "6f18802e-fbd5-49ad-82d8-52b3ca7b16b1",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_53.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Fonction heuristique\n53Intuition que l'on a sur le coÃ»t nÃ©cessaire pour atteindre un Ã©tat ï¬nal Ã  partir d'un certain Ã©tatFonction heuristique\nh(n)=coÃ»tÂ estimÃ©Â pourÂ atteindreÂ unÂ Ã©tatÂ ï¬nalÂ Ã Â partirÂ d'unÂ Ã©tatÂ nIntuition: on va privilÃ©gier l'exploration des Ã©tats dont l'heuristique retourne une faible valeur\n737,6\nAvez-vous des idÃ©es d'heuristiques pour ce problÃ¨me ?Travail supplÃ©mentaire: elles doivent gÃ©nÃ©ralement Ãªtre conÃ§ues spÃ©ciï¬quement pour chaque problÃ¨me(1) Distance euclidienne: chemin Ã  vol d'oiseau(2) Distance de Manhattan: chemin le plus court sur une grille\nQuelle heuristique vous semble de meilleure qualitÃ© ?Intuitivement: la distance de Manhattan, car elle donne une idÃ©e plus prÃ©cise du coÃ»t de chaque Ã©tatPrincipe: une heuristique donne une information sur Ã  quel point un Ã©tat est coÃ»teux\nOn va voir par la suite des techniques pour concevoir de bonnes heuristiques"
      }
    ]
  },
  {
    "id": "d5d46178-77e3-48e4-b156-90884b6dd73d",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_54.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche gloutonne (greedy best-ï¬rst search)\n54Algorithme de recherche consistant Ã  retirer le noeud le moins coÃ»teux selon lâ€™heuristiqueRecherche gloutonne (greedy best-ï¬rst search)\nBesoin: avoir dÃ©ï¬ni une heuristique pour le problÃ¨meh(n):ğ–­ğ—ˆğ–½ğ–¾â†’â„ImplÃ©mentation: identique Ã  UCS (seulement la prioritÃ© change)\ns=ğ—‰ğ—ˆğ—‰(L)C={âŸ¨c,g(c)âŸ©âˆˆğ—Œğ—ğ–¼ğ–¼ğ–¾ğ—Œğ—ˆğ—‹ğ—Œ(s,P)}ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—‡ğ—ˆğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–´ğ—‡ğ—‚ğ–¿ğ—ˆğ—‹ğ—†ğ–¢ğ—ˆğ—Œğ—ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P):ğ—ğ—ğ—‚ğ—…ğ–¾Lâ‰ âˆ…:s=ğ—‚ğ—‡ğ—‚ğ—ğ—‚ğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P)ğ—‰ğ—ğ—Œğ—(L,s,g(s))ğ—‰ğ—ğ—Œğ—(L,C)ğ—‚ğ–¿s=ğ—€ğ—ˆğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P):ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¾ğ—…ğ—Œğ–¾:L=ğ–¯ğ—‹ğ—‚ğ—ˆğ—‹ğ—‚ğ—ğ—’ğ–°ğ—ğ–¾ğ—ğ–¾()\nObservation: on a passÃ© du temps Ã  avoir une bonne formalisation, mais câ€™est rentable ! Principe: chaque Ã©tat est Ã©valuÃ© selon la fonction heuristique\ns=ğ—‰ğ—ˆğ—‰(L)C={âŸ¨c,h(c)âŸ©âˆˆğ—Œğ—ğ–¼ğ–¼ğ–¾ğ—Œğ—ˆğ—‹ğ—Œ(s,P)}ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—‡ğ—ˆğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¦ğ—‹ğ–¾ğ–¾ğ–½ğ—’ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P,h):ğ—ğ—ğ—‚ğ—…ğ–¾Lâ‰ âˆ…:s=ğ—‚ğ—‡ğ—‚ğ—ğ—‚ğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P)ğ—‰ğ—ğ—Œğ—(L,s,h(s))ğ—‰ğ—ğ—Œğ—(L,C)ğ—‚ğ–¿s=ğ—€ğ—ˆğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P):ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¾ğ—…ğ—Œğ–¾:L=ğ–¯ğ—‹ğ—‚ğ—ˆğ—‹ğ—‚ğ—ğ—’ğ–°ğ—ğ–¾ğ—ğ–¾()\nAttention: on nâ€™a plus aucune notion de coÃ»t dÃ©jÃ  gÃ©nÃ©rÃ© (comme avec UCS)"
      }
    ]
  },
  {
    "id": "137982a7-f51d-42be-8975-81e3f5295393",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_55.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche gloutonne (greedy best-ï¬rst search)\n55......\nMauvaise nouvelle: la recherche nâ€™est pas complÃ¨te (mÃªme problÃ¨me que le DFS)En pratique: les performances peuvent Ãªtre bonnes si l'heuristique est adaptÃ©eDiï¬ƒcultÃ© majeure: le manque de garanties thÃ©oriques\nQuelles sont les performances d'une recherche gloutonne ?CritÃ¨re 1: complexitÃ© temporelleCritÃ¨re 2: complexitÃ© spatialeComplexitÃ©Â temporelle:Â ğ’ª(bm)Pire des cas: agit comme un mauvais DFSPire des cas: agit comme un mauvais BFSComplexitÃ©Â spatiale:Â ğ’ª(bm)CritÃ¨re 3: complÃ©tudeCritÃ¨re 4: optimalitÃ©Mauvaise nouvelle: trÃ¨s haut risque de tomber sur une solution sous-optimaleIl y a une distinction entre pire cas thÃ©orique et bons rÃ©sultats en pratique\nAmÃ©lioration possible: apporter plus de garanties Ã  cet algorithme"
      }
    ]
  },
  {
    "id": "3808f10f-1379-4de1-84c4-7f89d1a9f0f4",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_56.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche gloutonne - exemples\n56\nQue va faire une recherche gloutonne dans ces situations ?\n\"La fonction heuristique,  vous dÃ©ï¬nirez\"\nRÃ©ponse: Ã§a dÃ©pend de l'heuristique qui a Ã©tÃ© choisie !\nHeuristique: distance de Manhattan entre l'Ã©tat actuel et l'Ã©tat ï¬nal\nAttention: sans dÃ©ï¬nir l'heuristique, cette question n'a aucun sens\nObservation: la solution retournÃ©e nâ€™est pas la meilleure"
      }
    ]
  },
  {
    "id": "26709587-c307-4a80-875a-a8998c41683b",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_57.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche gloutonne - exemple\n57\nAvez-vous des idÃ©es d'heuristiques pour ce problÃ¨me ?Objectif: trouver le chemin le plus court pour aller de Arad Ã  BucharestHeuristique: la distance Ã  vol d'oiseau semble Ãªtre un choix raisonnableRecherche gloutonne: sÃ©lectionne le successeur ayant la plus faible coÃ»t estimÃ©Valeur heuristique (vol d'oiseau) de chaque Ã©tat\nIdÃ©alement: lâ€™heuristique ne doit pas Ãªtre trop coÃ»teuse Ã  calculer (câ€™est bien le cas ici)"
      }
    ]
  },
  {
    "id": "f4b4ce1e-a702-4f82-aaa1-2e726392df5e",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_58.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche gloutonne - exÃ©cution de l'exemple\n58\nEtapeÂ 1:[state:A,fringe:âŸ¨(S,253)A,(T,329)A,(Z,374)AâŸ©]EtapeÂ 3:[state:FS,fringe:âŸ¨TA,ZA,AS,OS,RS,SF,BFâŸ©]EtapeÂ 2:[state:SA,fringe:âŸ¨(T,329)A,(Z,374)A,(A,366)S,(F,176)S,(O,380)S,(R,193)SâŸ©]EtapeÂ 4:[state:BF,path:Aâ†’Sâ†’Fâ†’B,cost:450]Arad, 366Sibiu, 253Timisoara, 329Zerind, 374Arad, 366Fagaras, 176Oradea, 380R. Vilcea, 193Sibiu, 253Bucharest, 0Solution trouvÃ©e !\nEst-ce que notre solution est optimale ?Exemple: exÃ©cution de lâ€™algorithme"
      }
    ]
  },
  {
    "id": "16d5e497-6a71-4348-853d-c2cd3316d425",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_59.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche gloutonne - exemple\n59Arad, 366Sibiu, 253Timisoara, 329Zerind, 374EtapeÂ 1:[state:A,fringe:âŸ¨SA,TA,ZAâŸ©]Arad, 366Sibiu, 253Timisoara, 329Zerind, 374Arad, 366Fagaras, 176Oradea, 380R. Vilcea, 193EtapeÂ 2:[state:SA,fringe:âŸ¨TA,ZA,AS,FS,OS,RSâŸ©]Arad, 366Sibiu, 253Timisoara, 329Zerind, 374Arad, 366Fagaras, 176Oradea, 380R. Vilcea, 193Sibiu, 253Bucharest, 0EtapeÂ 3:[state:FS,fringe:âŸ¨TA,ZA,AS,OS,RS,SF,BFâŸ©]Arad, 366Sibiu, 253Timisoara, 329Zerind, 374Arad, 366Fagaras, 176Oradea, 380R. Vilcea, 193Sibiu, 253Bucharest, 0EtapeÂ 4:[state:BF,path:Aâ†’Sâ†’Fâ†’B,cost:450]"
      }
    ]
  },
  {
    "id": "e77d878c-3b59-4d70-b3e0-0136a402c723",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_60.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche gloutonne - analyse de la solution\n60\nCoÃ»tÂ deÂ notreÂ solution:Â g(Aradâ†’Sibiuâ†’Fagarasâ†’Bucharest)â†’140+99+211=450CoÃ»tÂ d'uneÂ autreÂ solution:Â g(Aradâ†’Sibiuâ†’R.Â Vilceaâ†’Pitestiâ†’Bucharest)â†’140+80+97+101=418Arad, 366Sibiu, 253Timisoara, 329Zerind, 374Arad, 366Fagaras, 176Oradea, 380R. Vilcea, 193Sibiu, 253Bucharest, 0\nEst-ce que notre solution est optimale ?\nPourquoi a t-on manquÃ© cette meilleure solution ?DÃ©faut de notre heuristique: elle a complÃ¨tement nÃ©gligÃ© R. Vilcea au dÃ©triment de FagarasObservation: il s'agit pourtant d'un choix raisonnable, car le coÃ»t dÃ©jÃ  eï¬€ectuÃ© depuis Arad est moindreg(Aradâ†’Sibiuâ†’Fagaras)â†’140+99=239g(Aradâ†’Sibiuâ†’R.Â Vilcea)â†’140+80=220\nLa recherche gloutonne ne tient pas compte des coÃ»ts dÃ©jÃ  engendrÃ©s !"
      }
    ]
  },
  {
    "id": "13fda0ae-8282-467a-9f20-07ebe5d4cd93",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_61.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Motivation d'une nouvelle stratÃ©gie\n61(2) Tenter d'avoir une une vision du futur, en tant qu'intuitionQuestion philosophique: compliquÃ© Ã  rÃ©pondre, mais on peut suivre deux principes(1) Tenir compte de nos connaissances antÃ©rieures, en tant qu'expÃ©rience\nStratÃ©gie UCS: considÃ¨re uniquement les coÃ»ts dÃ©jÃ  gÃ©nÃ©rÃ©s\nEn pratique: souvent nos dÃ©cisions personnelles tiennent comptes de ces deux aspects\nLa combinaison de ces deux aspects forme un des algorithmes de recherche les plus rÃ©putÃ© en IAAvantage: ï¬able (optimal)InconvÃ©nient: lentStratÃ©gie gloutonne: considÃ¨re uniquement les coÃ»ts futurs estimÃ©sAvantage: peut accÃ©lÃ©rer la recherche si lâ€™heuristique est bonneInconvÃ©nient: non-ï¬able\nQuel est le lien avec nos stratÃ©gies de recherche ?\nIdÃ©e: crÃ©er une stratÃ©gie tenant Ã  la fois compte du passÃ© et du futur"
      }
    ]
  },
  {
    "id": "0e7c5d87-aab3-469d-bf5c-f9ac340a358f",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_62.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "StratÃ©gie de recherche A* (A-star search)\n62g(s):Â coÃ»tÂ duÂ noeudÂ sÂ (similaireÂ Ã Â UCS)h(s):Â heuristiqueÂ auÂ noeudÂ sÂ (estimationÂ desÂ coÃ»tsÂ futurs)StratÃ©gie qui consiste Ã  retirer le noeud en fonction des coÃ»ts passÃ©s et dâ€™une heuristiqueStratÃ©gie de recherche A* (A-star search)\nConstruction de la fonction: somme des coÃ»ts passÃ©s et du coÃ»t heuristique\nPrioritÃ©Â A*:f(s)=g(s)+h(s)Utilisation de la fonction: sÃ©lectionner le prochain noeud Ã  explorer dans la ï¬le de prioritÃ©Bonne nouvelle: encore une fois, on ne change quasi rien Ã  notre algorithme\ns=ğ—‰ğ—ˆğ—‰(L)C={âŸ¨c,g(c)+h(c)âŸ©|câˆˆğ—Œğ—ğ–¼ğ–¼ğ–¾ğ—Œğ—ˆğ—‹ğ—Œ(s,P)}ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—‡ğ—ˆğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ– ğ–²ğ—ğ–ºğ—‹ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P,h):ğ—ğ—ğ—‚ğ—…ğ–¾Lâ‰ âˆ…:s=ğ—‚ğ—‡ğ—‚ğ—ğ—‚ğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P)ğ—‰ğ—ğ—Œğ—(L,s,f(s))ğ—‰ğ—ğ—Œğ—(L,C)ğ—‚ğ–¿s=ğ—€ğ—ˆğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P):ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¾ğ—…ğ—Œğ–¾:L=ğ–¯ğ—‹ğ—‚ğ—ˆğ—‹ğ—‚ğ—ğ—’ğ–°ğ—ğ–¾ğ—ğ–¾()f(s)=g(s)+h(s)\nBonne nouvelle: pour le principe de l'algorithme, ouiMauvaise nouvelle: il nous reste Ã  Ã©tudier ses propriÃ©tÃ©s"
      }
    ]
  },
  {
    "id": "f960e448-9bd1-4661-af67-264d70267b59",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_63.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Illustration - UCS vs Greedy vs A*\n63Recherche Ã  coÃ»t uniformeRecherche gloutonne\nRecherche A*(S,0,6)(A,1,5)(B,2,6)(D,4,2)(E,9,1)(C,3,7)(G,6,0)(D,10,2)(G,12,0)(s,g(s),h(s))\nEtapeÂ 1:[state:S,fringe:âŸ¨(A,1)SâŸ©]EtapeÂ 1:[state:S,fringe:âŸ¨(A,5)SâŸ©]EtapeÂ 2:[state:AS,fringe:âŸ¨(B,2)A,(D,4)A,(E,9)AâŸ©]EtapeÂ 3:[state:BA,fringe:âŸ¨(D,4)A,(E,9)A,(C,3)BâŸ©]EtapeÂ 4:[state:CB,fringe:âŸ¨(D,4)A,(E,9)AâŸ©]EtapeÂ 5:[state:DA,fringe:âŸ¨(E,9)A,(G,6)DâŸ©]EtapeÂ 4:[state:GD,path:Sâ†’Aâ†’Dâ†’G(6)]EtapeÂ 2:[state:AS,fringe:âŸ¨(B,6)A,(D,2)A,(E,1)AâŸ©]EtapeÂ 3:[state:EA,fringe:âŸ¨(B,6)A,(D,2)A,(D,2)EâŸ©]EtapeÂ 4:[state:DE,fringe:âŸ¨(B,6)A,(D,2)A,(G,0)DâŸ©]EtapeÂ 5:[state:GD,path:Sâ†’Aâ†’Eâ†’Dâ†’G(12)]SCABDEG8111312h = 6h = 7h = 5h = 6h = 1h = 2h = 0\nEtapeÂ 2:[state:A,fringe:âŸ¨(B,8)A,(D,6)A,(E,10)AâŸ©]EtapeÂ 1:[state:S,fringe:âŸ¨(A,6)SâŸ©]EtapeÂ 3:[state:DA,fringe:âŸ¨(B,8)A,(E,10)A,(G,6)DâŸ©]EtapeÂ 6:[state:GD,path:Sâ†’Aâ†’Dâ†’G(6)]Le coÃ»t de chaque noeud est Ã©valuÃ© par une fonction heuristique"
      }
    ]
  },
  {
    "id": "d527c787-52f8-412c-a064-c975ea5c7b63",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_64.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche A* - exemple\n64\nChemin optimal  dÃ©couvert avec moins  de noeuds Ã©tendus\nRecherche gloutonnePeu de noeuds Ã©tendus mais non optimal\nRecherche Ã  coÃ»t uniformeOptimal mais beaucoup de noeuds Ã©tendus"
      }
    ]
  },
  {
    "id": "73cf44ab-cf7b-49aa-925a-532fbd04005b",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_65.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche A* - propriÃ©tÃ©s\n65Bonne nouvelle: la recherche est complÃ¨te (si tous les coÃ»ts sont positifs et que la solution a un coÃ»t ï¬ni)\nMauvaise nouvelle: mÃªmes diï¬ƒcultÃ©s quâ€™une recherche gloutonne en cas de mauvaise heuristique(1) Heuristiques admissibles(2) Heuristiques consistantesSGA135h = 7h = 6h = 0\nEtapeÂ 1:[state:S,fringe:âŸ¨(A,7)S,(G,5)SâŸ©]EtapeÂ 2:[state:GS,path:Sâ†’G(5)]Une solution non optimale est obtenueIntuition: similaire Ã  la recherche Ã  coÃ»t uniforme\nEst-ce que la recherche A* est optimale ?\nEst-ce que la recherche A* est complÃ¨te ?\nExemple: regardons un cas simple\nCause: notre heuristique a donnÃ© une estimation trop coÃ»teuse Ã  un Ã©tatObservation: une mauvaise solution a eu une meilleure prioritÃ© qu'un noeud de la solution optimale  \nUne des forces dâ€™A* est quâ€™il est possible de concevoir des heuristiques empÃªchant cette situation"
      }
    ]
  },
  {
    "id": "9ca91f7a-b35f-4516-bdfe-068b88671405",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_66.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Heuristique admissible\n66Une heuristique est admissible (ou optimiste) si elle ne surestime jamais le coÃ»t pour atteindre le meilleur Ã©tat ï¬nalHeuristique admissible\n0â‰¤h(n)â‰¤hâ‹†(n),Â pourÂ toutÂ Ã©tatÂ nhâ‹†(n)Â indiqueÂ leÂ coÃ»tÂ optimalÂ pourÂ atteindreÂ l'Ã©tatÂ ï¬nalÂ Ã Â partirÂ deÂ nPrincipe: une heuristique admissible garantit que le coÃ»t optimal d'un noeud ne sera jamais sur-estimÃ©EtapeÂ 1:[state:S,fringe:âŸ¨(A,3)S,(G,5)SâŸ©]EtapeÂ 2:[state:AD,fringe:âŸ¨(G,5)S,(G,4)AâŸ©]SGA135h = 4h = 2h = 0\nEtapeÂ 3:[state:GA,path:Sâ†’Aâ†’G(4)]Intuition: l'heuristique ne va jamais empÃªcher l'extension du noeud, s'il peut appartenir au chemin optimalAutrement dit: lâ€™heuristique va toujours donner une valeur infÃ©rieure au coÃ»t rÃ©el optimal du noeudAvec une heuristique admissible, on a la garantie qu'une recherche A* en arbre est optimaleOptimalitÃ© d'une recherche A* en arbre\nhâ‹†(G)=0hâ‹†(A)=3hâ‹†(S)=4\nDÃ©ï¬nir une heuristique admissible est un point de conception majeur pour une recherche A*"
      }
    ]
  },
  {
    "id": "7148879c-cb1c-47f1-9f0e-569b7df580e9",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_67.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Preuve d'optimalitÃ©\n67h(n):Â fonctionÂ heuristiqueÂ appliquÃ©Â Ã Â l'Ã©tatÂ duÂ noeudÂ ng(n):Â coÃ»tÂ pourÂ atteindreÂ leÂ noeudÂ nhâ‹†(n):Â coÃ»tÂ optimalÂ pourÂ atteindreÂ unÂ Ã©tatÂ ï¬nalÂ depuisÂ nSupposonsÂ que:f(n)=g(n)+h(n):Â fonctionÂ deÂ prioritÃ©Â deÂ l'algorithmeÂ A*Câ‹†:Â coÃ»tÂ deÂ laÂ solutionÂ optimalePreuve par contradictionPropriÃ©tÃ©Â Ã Â prouver:Â siÂ h(n)Â estÂ admissible,Â alorsÂ A*Â estÂ optimalgâ‹†(n):Â coÃ»tÂ optimalÂ pourÂ atteindreÂ unÂ Ã©tatÂ nÂ depuisÂ l'Ã©tatÂ initial\nD'unÂ cÃ´tÃ©,Â onÂ aÂ deÂ (1):C:Â coÃ»tÂ d'uneÂ solutionÂ nonÂ optimaleÂ (cheminÂ enÂ zigzag)(2)Â h(n)Â estÂ admissible:Â h(n)â‰¤hâ‹†(n)f(n)=g(n)+h(n)(dÃ©ï¬nitionÂ deÂ A*)f(n)â‰¥C>Câ‹†Â (IlÂ existeÂ forcÃ©mentÂ unÂ noeudÂ nÂ appartenantÂ auÂ cheminÂ optimalÂ quiÂ n'aÂ pasÂ Ã©tÃ©Â Ã©tendu)D'unÂ autreÂ cÃ´tÃ©,Â onÂ aÂ deÂ (2):f(n)=gâ‹†(n)+h(n)Â (carÂ nÂ appartientÂ auÂ cheminÂ optimal)f(n)â‰¤gâ‹†(n)+hâ‹†(n)Â (dÃ©ï¬nitionÂ d'uneÂ heuristiqueÂ admissible)f(n)â‰¤Câ‹†Â (dÃ©ï¬nitionÂ duÂ coÃ»tÂ duÂ cheminÂ optimal)(1)Â A*Â avecÂ laÂ fonctionÂ deÂ prioritÃ©Â fÂ retourneÂ unÂ cheminÂ deÂ coÃ»tÂ non-optimalÂ (C>Câ‹†)Contradiction !Si l'heuristique est admissible, alors A* ne peut pas retourner une solution non-optimaleSnGh(n)hâ‹†(n)gâ‹†(n)n:Â noeudÂ appartenantÂ auÂ cheminÂ optimalSnGh(n)"
      }
    ]
  },
  {
    "id": "59349446-5c5e-4147-90e5-7a69197f4d14",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_68.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Exemples d'heuristiques (non)-admissibles\n68\nEst-ce que les heuristiques suivantes sont admissibles ?h(n)=0\nh(n)=hâ‹†(n)h(n)=ğ–¬ğ–ºğ—‡ğ—ğ–ºğ—ğ—ğ–ºğ—‡ğ–£ğ—‚ğ—Œğ—ğ–ºğ—‡ğ–¼ğ–¾(n,G)h(n)=ğ–²ğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¢ğ—ˆğ—Œğ—ğ–¦ğ—‹ğ–¾ğ–¾ğ–½ğ—’(n)h(n)=ğ–¤ğ—ğ–¼ğ—…ğ—‚ğ–½ğ—‚ğ–ºğ—‡ğ–£ğ—‚ğ—Œğ—ğ–ºğ—‡ğ–¼ğ–¾(n,G)h(n)=ğ–²ğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¢ğ—ˆğ—Œğ—ğ–¡ğ–¥ğ–²(n)HeuristisqueÂ admissible:Â 0â‰¤h(n)â‰¤hâ‹†(n),Â pourÂ toutÂ Ã©tatÂ n\nNon ! risque de surestimer le coÃ»t de la solutionOui ! impossible de faire mieux que la distance Ã  vol d'oiseauOui ! mÃªme raisonnement, car on se dÃ©place sur une grilleOui ! mais inutile car plus coÃ»teux que A*Oui ! mais inutile... connaÃ®tre cette valeur revient Ã  avoir la solutionh(n)=ğ–²ğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¢ğ—ˆğ—Œğ—ğ–£ğ–¥ğ–²(n)Non ! risque de donner un coÃ»t non-optimale (sur-estimation)Notez que cela est vrai car les coÃ»ts sont unitaires !Oui ! mais inutile... (recherche rÃ©duite Ã  UCS)f(n)=g(n)+0"
      }
    ]
  },
  {
    "id": "a9e92561-1c40-4202-a354-cbda53fdcd9c",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_69.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Table des matiÃ¨res\n69StratÃ©gies de recherche1. DÃ©ï¬nition et modÃ©lisation d'un problÃ¨me de recherche 2. Agents rÃ©ï¬‚exes 3. Agents axÃ©s sur la recherche 4. Recherche en arbre (tree search) 5. Recherche sans information: DFS, BFS, UCS, IDS 6. Recherche avec information: greedy search, A* 7. Conception d'heuristiques 8. Recherche en graphe (graph search)ProblÃ¨mes abordÃ©s1. Pacman 2. 8-puzzle 3. Planiï¬cation de routes\nSDEPBACAEHRPQQFCGAHRQQFCGAQP"
      }
    ]
  },
  {
    "id": "ea60d35a-bae1-4fa7-9030-3bca092d3089",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_70.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Construction d'heuristiques - techniques et bonnes pratiques\n70\nComment construire des bonnes heuristiques (admissibles) ?Mauvaise nouvelle: trÃ¨s diï¬ƒcile de rÃ©pondre Ã  cette question !Raison: il s'agit plus d'un art qu'une science exacteBonne nouvelle: il existe nÃ©anmoins des astuces et des bonnes pratiques\nIdÃ©e: utiliser une solution du problÃ¨me relaxÃ© pour obtenir une heuristique admissible\nRelaxation forte: heuristique plus facile Ã  calculer mais peu prÃ©cise (grosse simpliï¬cation du problÃ¨me)Relaxation faible: heuristique plus prÃ©cise mais plus dure Ã  obtenir (faible simpliï¬cation du problÃ¨me)\n?ProblÃ¨me auquel on a retirÃ© certaines contraintes aï¬n de le rendre plus facile Ã  rÃ©soudreRelaxation dâ€™un problÃ¨me\nExemple: relaxations possible pour Pacman\nUne relaxation forte (aucun mur) met en Ã©vidence la distance de Manhattan comme heuristique"
      }
    ]
  },
  {
    "id": "f80bb450-ee9f-4fa9-850a-d2c47ba67ea3",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_71.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Construction d'heuristiques - techniques et bonnes pratiques\n71InconvÃ©nient: coÃ»t de calcul supplÃ©mentaire pour obtenir les diï¬€Ã©rentes heuristiquesSupposition: il faut quâ€™on ait plusieurs heuristiques disponiblesAvantage: si vos diï¬€Ã©rentes heuristiques sont admissibles, alors leur maximum l'est aussiAu lieu de choisir une heuristique, en Ã©valuer plusieurs, et prendre la meilleure pour chaque noeud Collection dâ€™heuristiques\nh(n)=max(h1(n),h2(n),â€¦,hk(n))\nUne heuristique h2 domine h1 si elle est strictement plus prÃ©cise que cette derniÃ¨reHeuristique dominante\nh1(n)<h2(n),Â pourÂ chaqueÂ Ã©tatÂ nh(n)=0hâ‹†(n)max(h1(n),h3(n))h1(n)h2(n)h3(n)Estimation parfaite du coÃ»tHeuristique nulleh3(n)Â domineÂ h2(n)Graphe de dominance: relations explicites des dominances entre vos diï¬€Ã©rentes heuristiques"
      }
    ]
  },
  {
    "id": "f4070fbf-2dee-4d45-9693-7654bf2cd1ee",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_72.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Construction d'heuristiques - considÃ©rations pratiques\n72\nQuelle heuristique est plus prÃ©cise entre h1(n) et h2(n) ?h(n)=0hâ‹†(n)max(h1(n),h3(n))h1(n)h2(n)h3(n)Estimation parfaite du coÃ»tHeuristique nulleh3(n)Â domineÂ h2(n)Diï¬ƒcile Ã  rÃ©pondre ! il existe des Ã©tats oÃ¹ h1 est plus prÃ©cise et inversement\nEn pratique, est-il prÃ©fÃ©rable d'utiliser h2(n) ou h3(n) ?RÃ©ponse: aucune heuristique ne domine l'autrePossibilitÃ© de conception: prendre le maximum entre les deux pour l'estimation d'un Ã©tat\nEn pratique: une heuristique dominÃ©e mais plus rapide peut Ãªtre plus intÃ©ressante Ã  utiliserCertitude: l'heuristique h3 domine h2, elle est donc plus prÃ©ciseIncertitude: on n'a aucune information sur le temps de construction de l'heuristiqueObtenir h3 est potentiellement beaucoup plus lent que h2 (Ã  l'extrÃªme, h* est inconcevable Ã  obtenir)\nLa vitesse d'exÃ©cution d'une heuristique est Ã©galement une considÃ©ration importante !"
      }
    ]
  },
  {
    "id": "96473e52-ac6f-431b-b61d-e7f024ec08de",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_73.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Exemple illustratif - 8-puzzle\n73\nEtat initial (s)\nEtat ï¬nal\nQuelle est la taille de l'espace d'Ã©tats ?Observation:Â chaqueÂ piÃ¨ceÂ estÂ uniqueÂ etÂ n'estÂ placÃ©eÂ qu'uneÂ seuleÂ foisEtats: chaque position possible du plateauActions: dÃ©placer la case vide (G,D,H,B)CoÃ»t: unitaire pour chaque dÃ©placementTransition: dÃ©placement de la caseModÃ©lisation\nHeuristiquesNombreÂ d'Ã©tats:Â 9!=362880\nAvez-vous une idÃ©e d'heuristique ?\nChoix 1: nombre de piÃ¨ces placÃ©es incorrectementRelaxation: les piÃ¨ces peuvent se tÃ©lÃ©porter directement Ã  leur position ï¬naleProblÃ¨me du 8-puzzleObjectif: dÃ©placer les piÃ¨ces aï¬n de les ordonnerCoÃ»t: eï¬€ectuer le moins de mouvements possibles\nChoix 2: distance de Manhattan cumulÃ©e de chaque piÃ¨ceRelaxation: les piÃ¨ces peuvent se dÃ©placer sans conï¬‚it Ã  leur position ï¬naleContrainte: une piÃ¨ce ne peut se dÃ©placer que dans le trou\nNote: il s'agit d'une borne supÃ©rieure car toutes les conï¬gurations ne sont pas atteignableshttps://mathworld.wolfram.com/15Puzzle.html\nh1(s)=1+1+1+1+1+1+1+1=8\nh2(s)=3+1+2+2+2+3+3+2=18"
      }
    ]
  },
  {
    "id": "aeee1c8f-7ace-42f6-8016-5a7e7c62006c",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_74.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Exemple illustratif - 8-puzzle\n74\nQuelle heuristique vous parait la plus prÃ©cise ?Analyse des performancesAnalyse 1: A* bat la stratÃ©gie BFS, mÃªme avec l'heuristique simpleAnalyse 2: lâ€™heuristique 2 est largement plus prÃ©cise que l'heuristique 1RÃ©sultats moyens sur 100 puzzles alÃ©atoires pour chaque dAnalyse 3: on peut facilement dÃ©montrer qu'elle domine l'autreConseils de conception\nEn pratique: il est parfois utile d'avoir des heuristiques non-admissiblesA temps d'exÃ©cution Ã©gal: prÃ©fÃ©rez une heuristique ayant de plus grandes valeursConseil: lorsque vous avez plusieurs bonnes heuristiques, prenez leur maximum\nd:coÃ»tÂ deÂ laÂ solutionÂ optimaleNombre de noeuds explorÃ©s avant de trouver la solution\nConseil: ayez toujours en tÃªte la complexitÃ© temporelle de vos heuristiquesExemple: une heuristique prÃ©cise mais lente ne vaut peut-Ãªtre pas le coup...Attention: le temps d'exÃ©cution n'est pas pris en compte (nÃ©gligeable ici)"
      }
    ]
  },
  {
    "id": "66857dc3-7c3b-43e8-9ec3-41f3ef312932",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_75.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "https://corail-research.github.io/Construction d'heuristiques - techniques supplÃ©mentaires\n75Conception d'heuristiques par des connaissances expertesIdÃ©e: utiliser nos propres connaissances du problÃ¨me (ou celles d'un expert) pour concevoir l'heuristiqueCela revient Ã  Ãªtre capable de quantiï¬er adÃ©quatement le coÃ»t de chaque Ã©tat\nConception d'heuristiques par apprentissage automatiqueInconvÃ©nient: diï¬ƒcile de s'assurer de l'admissibilitÃ© de l'heuristiqueInconvÃ©nient: compliquer Ã  concevoir et Ã  calibrerInconvÃ©nient: souvent incomplet (p.e., les positions prÃ©cises des piÃ¨ces ne sont pas prises en compte)Exemple: Ã©valuer la qualitÃ© d'un Ã©tat du 8-puzzlex1(n):nombreÂ deÂ tuilesÂ malÂ placÃ©esPrincipe: identiï¬er les caractÃ©ristiques d'un Ã©tat, et de les pondÃ©rer en fonction de leur importance\nIdÃ©e: utiliser de l'apprentissage automatique pour construire l'heuristiqueDÃ©celer automatiquement les caractÃ©ristiques (+ le poids)Un de mes sujets de recherches principaux :-)Avantage: permet d'intÃ©grer des connaissances trÃ¨s variÃ©es et non trivialesh(n)=w1x1(n)+w2x2(n)x2(n):nombreÂ deÂ pairesÂ deÂ tuilesÂ adjacentesÂ quiÂ neÂ sontÂ pasÂ adjacentesÂ dansÂ l'Ã©tatÂ ï¬nalw1,w2:poidsÂ associÃ©Â auxÂ deuxÂ caractÃ©ristiquesÂ (Ã Â dÃ©terminerÂ parÂ l'expert)"
      }
    ]
  },
  {
    "id": "fb050ce3-87c9-4aa6-a3cd-3a01413e2bed",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_76.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Table des matiÃ¨res\n76StratÃ©gies de recherche1. DÃ©ï¬nition et modÃ©lisation d'un problÃ¨me de recherche 2. Agents rÃ©ï¬‚exes 3. Agents axÃ©s sur la recherche 4. Recherche en arbre (tree search) 5. Recherche sans information: DFS, BFS, UCS, IDS 6. Recherche avec information: greedy search, A* 7. Conception d'heuristiques 8. Recherche en graphe (graph search)ProblÃ¨mes abordÃ©s1. Pacman 2. 8-puzzle 3. Planiï¬cation de routes\nSDEPBACAEHRPQQFCGAHRQQFCGAQP"
      }
    ]
  },
  {
    "id": "b477ab87-7785-4735-a0fc-67c25e6ba449",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_77.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Rappel: recherche en graphe\n77SD\nPQHEBACFRG\ns=ğ—Œğ–¾ğ—…ğ–¾ğ–¼ğ—ğ– ğ—‡ğ–½ğ–±ğ–¾ğ—†ğ—ˆğ—ğ–¾(L)C={câˆˆğ—Œğ—ğ–¼ğ–¼ğ–¾ğ—Œğ—ˆğ—‹ğ—Œ(s,P)|cğ—‡ğ—ˆğ—ğ—‚ğ—‡V}ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—‡ğ—ˆğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¦ğ—‹ğ–ºğ—‰ğ—ğ–²ğ–¾ğ–ºğ—‹ğ–¼ğ—(P):ğ—ğ—ğ—‚ğ—…ğ–¾Lâ‰ âˆ…:s=ğ—‚ğ—‡ğ—‚ğ—ğ—‚ğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P)L={s}V=âˆ…\nV=VâˆªsL=(LâˆªC)âˆ–sğ—‚ğ–¿s=ğ—€ğ—ˆğ–ºğ—…ğ–²ğ—ğ–ºğ—ğ–¾(P):ğ—‹ğ–¾ğ—ğ—ğ—‹ğ—‡ğ—Œğ—ˆğ—…ğ—ğ—ğ—‚ğ—ˆğ—‡ğ–¾ğ—…ğ—Œğ–¾:Rappel: on a vu qu'il Ã©tait possible de construire une recherche en graphe\nAvantage: on ne revisite pas le mÃªme Ã©tat lors de la rechercheInconvÃ©nient: on doit garder tous les Ã©tats vus en mÃ©moire, ce qui peut Ãªtre trÃ¨s coÃ»teuxPrincipe: maintenir un ensemble des Ã©tats dÃ©jÃ  visitÃ©s\nJusqu'Ã  prÃ©sent nos analyses se sont concentrÃ©es sur les recherches en arbre"
      }
    ]
  },
  {
    "id": "5d9fb70b-465b-45b9-bbf0-a374515713ac",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_78.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Performances de la recherche en graphe\n78Mauvaise nouvelle: lâ€™algorithme A* souï¬€re d'une diï¬ƒcultÃ© supplÃ©mentairePrincipe: ajout d'un mÃ©canisme de mÃ©moire pour retenir les noeuds visitÃ©s\nA t-on les mÃªmes algorithmes (DFS, BFS, A*, etc.) avec la recherche en graphe ?\nCas particulier de la recherche A*Bonne nouvelle: nos algorithmes peuvent Ãªtre utilisÃ©s presque sans modiï¬cation\nUne heuristique admissible n'est plus suï¬ƒsante pour garantir l'optimalitÃ©GÃ©nÃ©ralitÃ© de nos stratÃ©giesInconvÃ©nient majeur: la consommation mÃ©moire sera plus importantePire des cas: tous les Ã©tats doivent Ãªtre retenusPossibilitÃ©s de mitiger cette diï¬ƒcultÃ© (retenir qu'un certain nombre d'Ã©tats)\nIntroduction du concept d'heuristique consistante \nOn doit avoir une propriÃ©tÃ© plus forte pour cela"
      }
    ]
  },
  {
    "id": "474b80f8-a80f-4e34-bae5-05cf31e3d20e",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_79.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Recherche A* en graphe: cas pathologique\n79SA\nBCG11123h = 2h = 4h = 1h = 1h = 0Notez que l'heuristique est admissibleRecherche A* en arbre\nSolution optimale obtenue\nProblÃ¨me: notre heuristique a autorisÃ© l'extension de (C,3,1) avant (C,2,1)(S,0,2)(A,1,4)\n(G,5,0)(G,6,0)(B,1,1)(C,2,1)(C,3,1)(1)(2)(3)(4)(5)(6)Recherche A* en graphe(S,0,2)(A,1,4)\n(G,6,0)(B,1,1)(C,3,1)(1)(2)(3)(4)(5)Solution non-optimale obtenue\nQuel est le soucis selon vous ?ProblÃ¨me: le noeud (C,3,1) a Ã©tÃ© Ã©tendu avant (C,2,1), or (C,3,1) n'appartient pas au chemin optimalConsÃ©quence: une recherche en graphe ne va jamais Ã©tendre (C,2,1), car l'Ã©tat C a dÃ©jÃ  Ã©tÃ© explorÃ©ConsÃ©quence suivante: la solution optimale ne sera ainsi jamais dÃ©couverteLe soucis vient de l'heuristique appliquÃ©e Ã  l'Ã©tat ACas pathologiqueV={S,B}V={S}V={S,B,C}"
      }
    ]
  },
  {
    "id": "78ba2da0-311e-4508-948b-f038267fc089",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_80.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Heuristique consistante\n80SA\nBCG11123h = 2h = 4h = 1h = 1h = 0Ce blocage vient du fait que l'heuristique appliquÃ©e en A et en C a sur-estimÃ© le coÃ»t d'aller Ã  C (3 vs 1)h(A)âˆ’h(C)â‰¤c(Aâ†’C)Heuristique non consistanteAvec h(A) = 2Heuristique consistante4âˆ’1â‰¤1(Incorrect)\nSolution optimale trouvÃ©eUne heuristique est consistante si sa valeur appliquÃ©e Ã  un arc de transition ne surestime jamais le coÃ»t de l'arcHeuristique consistante\nh(n)âˆ’h(nâ€² )â‰¤c(nâ†’nâ€² ),Â pourÂ toutesÂ pairesÂ d'Ã©tats-sucesseursÂ (nâ†’nâ€² )PropriÃ©tÃ© 1: une heuristique consistante est Ã©galement admissible (l'inverse n'est pas vrai !)PropriÃ©tÃ© 2: une heuristique consistante est optimale pour A* avec une recherche en grapheCoÃ»t de l'arc: 1Estimation heuristique: 32âˆ’1â‰¤1(Correct)ConsÃ©quence: aller Ã  C via A est considÃ©rÃ© (Ã  tort) comme une mauvaise transitionHeuristique consistante: assure qu'un Ã©tat ne peut Ãªtre explorÃ© QUE via le chemin optimal(S,0,2)(A,1,2)\n(G,5,0)(G,6,0)(B,1,1)(C,2,1)(C,3,1)(1)(2)(3)(4)(5)h=2"
      }
    ]
  },
  {
    "id": "f9fd48f6-6bde-4d06-a55a-0578e0634d02",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_81.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Applications\n81\nStarGoalPathï¬ndingObjectif: trouver un chemin adÃ©quat dans un environnement parsemÃ© d'obstaclesApplications: gestion d'entrepÃ´ts, dÃ©placement dans les jeux vidÃ©os, etc.\nExploration de graphesReprÃ©sentation standard de systÃ¨mes complexes (rÃ©seaux routiers, sociaux, etc.)\nExemples: rÃ©seaux routiers, rÃ©seaux sociaux, reprÃ©sentation de connaissances, etc.Planiï¬cation de tÃ¢chesObjectif: trouver une sÃ©quence dâ€™actions pour rÃ©aliser une tÃ¢cheApplications: chaÃ®ne de production, sÃ©quenÃ§age gÃ©nÃ©ral de tÃ¢ches, etc."
      }
    ]
  },
  {
    "id": "c175023b-d5fb-442c-81c3-ce116cc9f921",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_82.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Table des matiÃ¨res\n82StratÃ©gies de recherche1. DÃ©ï¬nition et modÃ©lisation d'un problÃ¨me de recherche 2. Agents rÃ©ï¬‚exes 3. Agents axÃ©s sur la recherche 4. Recherche en arbre (tree search) 5. Recherche sans information: DFS, BFS, UCS, IDS 6. Recherche avec information: greedy search, A* 7. Conception d'heuristiques 8. Recherche en graphe (graph search)ProblÃ¨mes abordÃ©s1. Pacman 2. 8-puzzle 3. Planiï¬cation de routes\nSDEPBACAEHRPQQFCGAHRQQFCGAQP"
      }
    ]
  },
  {
    "id": "12e08ea2-3a79-4e5f-87ce-f8b8d70b03ff",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_83.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "SynthÃ¨se des notions vues\n83Conception d'heuristiques: relaxation, connaissances expertes, etc.StratÃ©gies sans informationProblÃ¨mes de rechercheMotivation: planiï¬er d'une sÃ©quence d'actions pour aller d'un Ã©tat initial Ã  un Ã©tat ï¬nalObjectif idÃ©al: trouver la sÃ©quence engendrant le moins de coÃ»ts\nStratÃ©gies avec informationRecherche en profondeur...\nSGRecherche gloutonne: rapide mais sans garantieRecherche A*: combinaison de la recherche gloutonne et de coÃ»t uniformeInclusion d'une heuristique (information du problÃ¨me) pour accÃ©lÃ©rer la rechercheHeuristique admissible: A* avec une recherche en arbre est optimalHeuristique consistante: A* avec une recherche en arbre/graphe est optimal...Recherche en largeur...Iterative deepening search...Recherche Ã  coÃ»t uniformePatron de rÃ©solution gÃ©nÃ©rique: recherche en graphe ou en arbre"
      }
    ]
  },
  {
    "id": "4ac7f2b2-dbc9-4b03-bef9-d80f30f97a2f",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_84.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Conseils pratiques\n84StratÃ©gie de rechercheConception d'heuristiquesPour commencer: faites des heuristiques simples et complexiï¬ez les progressivementImplÃ©mentationTechnique de relaxation: souvent un bon point de dÃ©partAu long de votre travail: testez rÃ©guliÃ¨rement vos algorithmes sur des situations simplesA vÃ©riï¬er: les noeuds Ã©tendus sont bien ceux attendusUne heuristique prÃ©cise n'est pas toujours la meilleure en pratique (temps d'exÃ©cution)Recherche en graphe: implÃ©mentez la mÃ©moire par un ensemble (set), et non une listePour commencer: considÃ©rez d'abord la recherche en graphe\nUne grande partie de votre code peut-Ãªtre rÃ©utilisÃ© pour les diï¬€Ã©rentes stratÃ©gies !\nSi l'optimalitÃ© n'est pas requise n'ayez pas peur d'avoir des heuristiques non admissiblesEnsuite: passez en recherche en arbre si vous avez des problÃ¨mes de mÃ©moire\nAttention: il est trÃ¨s facile d'avoir des bugs cachÃ©s !A vÃ©riï¬er: la solution obtenue est bien optimale (sur des petits problÃ¨mes)"
      }
    ]
  },
  {
    "id": "3e98860f-7738-44a2-922c-755d776ed816",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_85.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "MÃ©thodes avancÃ©es et limitation de nos stratÃ©gies\n85Autres stratÃ©gies de rechercheIterative-deepening A* search (IDA*): principe de IDS mais pour A*Recherche bidirectionnelle: recherche Ã  partir de l'Ã©tat initial et de l'Ã©tat ï¬nal et les faire se rencontrerSimpliï¬ed memory-bounded A* (SMA*): A* en indiquant une borne sur la mÃ©moire Ã  utiliserConceptions d'heuristiquesWeighted A*: perdre l'optimalitÃ© pour accÃ©lÃ©rer la recherche via une heuristique faiblement non admissibleDÃ©composer le problÃ¨me en sous-problÃ¨mes et rÃ©soudre les sous-problÃ¨mes pour obtenir une heuristiquePrÃ©-calculer certaines solutions et les insÃ©rer comme estimations heuristiquesLimitations(1) L'environnement considÃ©rÃ© Ã  prÃ©sent est entiÃ¨rement observable, statique, et dÃ©terministe(2) Recherche avec adversaireMÃ©thodes de pruning: enlever les cycles dans une recherche en arbre\nQue faire quand ces propriÃ©tÃ©s ne sont pas prÃ©sentes ?Comment agir en prÃ©sence d'un adversaire ?Lectures complÃ©mentaires (non obligatoires) disponibles sur MoodleSujet du prochain module"
      }
    ]
  },
  {
    "id": "50cf9df0-29ea-41be-b472-812a058a7d41",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_86.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "DerniÃ¨res illustrations\n86\nGeometric A-Star Algorithm: An Improved A* Algorithm for AGV Path Planning in a Port Environment [Tang et al., 2021]\nRecherche en profondeurRecherche en largeur\nRecherche gloutonneRecherche A*A* bidirectionnelStartGoal\nNote: la dÃ©ï¬nition du problÃ¨me fait que les coÃ»ts ne sont pas totalement unitaires (expliquant pourquoi BFS n'est pas optimal)"
      }
    ]
  },
  {
    "id": "9ec2225c-73d4-46d3-a779-96f346e703a5",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_87.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Exemples de questions d'examen\n871. ModÃ©liser une situation comme un problÃ¨me de recherche (Ã©tats, actions, coÃ»t, succession) 2. Savoir Ã©valuer la taille d'un espace de recherche 3. Savoir appliquer correctement un algorithme de recherche sur une situation donnÃ©e 4. Savoir construire des heuristiques non-triviales pour rÃ©soudre diï¬€Ã©rents problÃ¨mesThÃ©oriePratique1. Expliquer le fonctionnement et les propriÃ©tÃ©s d'une stratÃ©gie de recherche vue 2. Donner les avantages/inconvÃ©nients d'une stratÃ©gie de recherche par rapport Ã  une autre 3. Expliquer ce qu'est une heuristique admissible ou consistante, et l'implication de ces propriÃ©tÃ©s\nhttps://xkcd.com/761/"
      }
    ]
  },
  {
    "id": "f9e370aa-ca9d-4f5f-a5d8-31acf25bd693",
    "image": "extracted_content\\M1-strategie-recherche\\images\\page_88.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "DALLE: Pacman lost in a labyrinth on an oil painting"
      }
    ]
  }
]