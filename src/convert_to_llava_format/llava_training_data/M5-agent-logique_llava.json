[
  {
    "id": "700d0d83-a5fb-4f09-87d1-a49aa2467a42",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_1.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "INF8175 - Intelligence artiﬁcielleMéthodes et algorithmesModule 5: Agents logiques"
      }
    ]
  },
  {
    "id": "b47cfe1a-20c2-4ec0-a7dc-6960f2618738",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_2.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Contenu du cours\n2Considérations pratiques et sociétalesModule 10: Utilisation en industrie, éthique, et philosophie Raisonnement par recherche (essais-erreurs avec de l'intuition)Module 1: Stratégies de recherche Module 2: Recherche en présence d'adversaires Module 3: Recherche locale \nRaisonnement par apprentissageModule 6: Apprentissage supervisé Module 7: Réseaux de neurones et apprentissage profond Module 8: Apprentissage non-supervisé Module 9: Apprentissage par renforcement \nRaisonnement logiqueModule 4: Programmation par contraintes Module 5: Agents logiques"
      }
    ]
  },
  {
    "id": "6187d891-f153-465a-8c76-dcb79b909119",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_3.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Table des matières\n3Agents logiques1. Motivation et déﬁnition d'un agent logique 2. Représentation des connaissances 3. Système logique (syntaxe, sémantique, et règles d'inférences) 4. Formalisation de la logique des propositions 5. Raisonnement par model-checking 6. Inférences logiques et propriétés   7. Algorithme de résolution 8. Clauses de Horn 9. Extension à d'autres systèmes logiques"
      }
    ]
  },
  {
    "id": "8670b4d9-0aa5-4ad3-97f3-c3730f5e4ef6",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_4.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Retour sur les modules précédents\n4Stratégies de recherche avec adversaires (Module 2)Objectif: trouver la meilleure action à eﬀectuer, en présence d'adversairesTechniques vues: Minimax, Alpha-beta pruning, MCTS, ExpectiminimaxPrincipe: tester des scénarios, et prendre l'action du scénario maximisant notre score46212835214\nRecherche locale (Module 3)Objectif: trouver la meilleure solution faisable, parmi un ensemble de solutionsTechniques vues: hill climbing, méthode des restarts, simulated annealingPrincipe: tester des états en se déplaçant de solutions en solutions\nProgrammation par contraintes (Module 4)Objectif: trouver la meilleure solution faisable, et obtenir des garantiesTechniques vues: backtracking search, arc consistency, algorithme du point ﬁxePrincipe: tester des solutions, en assignant successivement les variablesWANTSAQ\nTVNSW\nWANTSAQ\nTVNSW\nWANTSAQ\nTVNSWWANTSAQ\nTVNSW\nWANTSAQ\nTVNSWWANTSAQ\nTVNSWWANTSAQ\nTVNSW\nWANTSAQ\nTVNSW\nStratégies de recherche (Module 1)Objectif: trouver une séquence d'action de plus faible coût entre un état initial et ﬁnalTechniques vues: DFS, BFS, IDS, UCS, Greedy, A*Principe: tester systématiquement des états jusqu'à trouver un chemin..."
      }
    ]
  },
  {
    "id": "ae5e3bda-eee7-4ce9-9554-b398e05b1366",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_5.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Limitation des stratégies de recherche\n5Stratégies de rechercheIdée générale: résoudre le problème en testant, d'une façon ou d'une autre, diﬀérentes conﬁgurationsEn pratique: intégration de mécanismes pour améliorer la recherche (heuristiques, propagation, etc.)\nEst-ce que ce type de raisonnement est adapté dans toutes les situations ?(1) Isolation d'un terme: X2=X1−4X1+X2=10X1−X2=4X1=?\nLimitation: très peu eﬃcace d'exécuter une recherche pour ce problème !(3) Simpliﬁcation algébrique: X1=7(2) Substitution d'un terme: X1+X1−4=10Résolution que vous savez faire depuis de nombreuses années\nAlgorithme: simple application de plusieurs règles arithmétiquesObservation: certains problèmes se résolvent plus eﬃcacement par d’autres stratégiesExemple: résolution d’un système d’équations simples\nCe module est dédié à la résolution de problèmes par raisonnements logiques automatisés"
      }
    ]
  },
  {
    "id": "2c6f0907-9334-4083-b13d-88b2fc2bbe53",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_6.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Programmation logique\n6Agent logiqueMotivation: créer un agent capable de raisonner et d'agir sur base d'un ensemble de connaissancesSouhait: deux interactions sont souhaitées avec l'agent(1) TELL: donner des nouvelles connaissances à l'agent(2) ASK: poser une question à l'agentTELL(\"Aucun étudiant n'aime les examens\")TELL(\"Simon aime les examens\")\nBase de connaissancesAucun étudiant n'aime les examensSimon aime les examensSimon n'est pas un étudiantASK(\"Est-ce que Simon est un étudiant ?\")NONRaisonnement logiqueBesoins de l'agent(1) Etre capable d'intégrer des connaissances très diverses(2) Etre capable de raisonner sur base des connaissances disponiblesObjectif 1: avoir un raisonnement supérieur à une simple énumération des connaissances disponiblesObjectif 2: concevoir un agent capable d'inférer par lui même de nouvelles connaissances"
      }
    ]
  },
  {
    "id": "3eda4ac9-6b6d-48df-8734-db09520a3263",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_7.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Intégration des connaissances\n7\nQuel langage utiliser pour représenter les connaissances ?Votre langue maternelle (ou langue naturelle)\nLe raisonnement logique en tant que tel est valideObjectif idéal: on souhaite interagir avec l’agent comme on le ferait avec une autre personneL'argent est plus précieux que le bronzeL'or est plus précieux que l'argentL'or est plus précieux que le bronzeRaisonnement logique\nA dollar is better than nothingNothing is better than world peaceA dollar is better than world peaceRaisonnement logique\nQuel est le soucis ?Objectif: créer un agent capable d'ingérer et de raisonner sur base de phrases en français (ou autre)\nDiﬃculté: la langue naturelle est souvent ambigüe Ambiguïté: Nothing a un sens à la fois concret et abstrait"
      }
    ]
  },
  {
    "id": "bab882ae-72c1-44fb-8688-352ec430f95b",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_8.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Notion de langage \n8Français: Les nombres pairs sont divisibles par 2Anglais: Even numbers are divisible by 2Objectif: on souhaite que l’entité soit capable de comprendre ce qui lui est expriméLangue naturelle: langage informel, pour la communication dans notre vie quotidienneLangage de programmation: langage formel, pour la communication avec un ordinateur \nMathématique\nChimie\nDanse des abeilles\ndef even(x): return x % 2 == 0Python:bool even(int x) { return x % 2 == 0; }C++: \nUn langage est un mécanisme pour exprimer quelque chose à une entité (communiquer)\nCe ne sont que deux exemples, et il existe plein d’autres langages dans le monde\nElements caractéristiques: les forces des interlocuteurs, l’objet à communiquer, et l’objectif en découlant"
      }
    ]
  },
  {
    "id": "655ca773-79d9-488b-8f8a-4a40bd7cc7a9",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_9.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Langage logique\n9Objectif 1: possibilité de représenter les connaissances relatives à l'environnementObjectif 2: possibilité de raisonner à partir de ces connaissances\nf:∀xEvenNumber(x)⟹Divides(x,2)Attention: il n’existe pas un unique langage logique mais une multitudef:Raining∧Snowing⟹Dangerous(1) Logique des propositions\nIntérêt: permettre un équilibre diﬀérent entre eﬃcacité et expressivitéEn général: plus le langage est expressif, plus il est diﬃcile de raisonner dessus(2) Logique du premier ordre(3) Logique du deuxième ordre, logique ﬂoue, etc.Langage naturel: très expressif, mais très diﬃcile de raisonner dessus (p.ex., ChatGPT)Langage mathématique: sans faille, mais limité à des calculs arithmétiques\nLes langages logiques visent à remédier à l'ambiguïté des langues naturelles pour faire des raisonnements"
      }
    ]
  },
  {
    "id": "6f7ab206-a69a-402a-a2b7-74ca2f85ac69",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_10.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Composants d'un langage logique\n10Un langage logique est un langage déﬁni par 3 éléments:Langage logique\n(1) Une syntaxe, qui déﬁnit l'ensemble de formules valides(2) Une sémantique, qui déﬁnit la signiﬁcation d'une formule(3) Des règles d'inférences, qui permettent d'obtenir des nouvelles formules validesSyntaxe et sémantique: notions courantes dans n'importe quel langageRègles d’inférences: spéciﬁques aux langages logiques\nFormule valide: formule correctement écrite au sens grammatical\nBase de connaissancesAucun étudiant n'aime les examensSimon aime les examensFormule en  langue naturelleFormule syntaxiquement correcte dans le langage mathématique: x+y=4Formule syntaxiquement incorrecte dans le langage mathématique: x+y+=4−Base de connaissances: ensemble des formules connues de l’agentEntité correspondant à l’expression d’une connaissanceFormule\nElément d’un langage permettant de déﬁnir quelles sont les formules validesSyntaxe"
      }
    ]
  },
  {
    "id": "89db3b5b-2dbd-47a7-ab1a-37f0b3b34223",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_11.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Syntaxe diﬀérente, même sémantiqueComposants d'un langage logique: sémantique\n11Exemple: x=3+2→signiﬁe que x vaut 5Conseil: pour ce module, il est très important de bien faire la distinction entre syntaxe et sémantiqueAttention: sans sémantique, les formules ne sont qu'une suite de caractères sans aucune signiﬁcation !Tâche non intuitive: on a tendance à associer mentalement ces deux notions\n\"Je mange une pomme\"Très diﬃcile de lire cette phrase sans associer le mot \"pomme\" au fruitExemples\nFormule 1:Je vais chez le dépanneur (Québécois)Formule 2:Je vais chez le dépanneur (Belge)Formule 1:3+2Formule 2:2+3Formule 1:return 3/2 (Python 2.7)Formule 2:return 3/2 (Python 3)Elément d’un langage permettant de donner une signiﬁcation aux formulesSémantique\nSyntaxe identique, sémantique diﬀérente (1 et 1.5)\nSyntaxe identique, sémantique diﬀérente"
      }
    ]
  },
  {
    "id": "0793b5c6-c765-4316-9e87-d42fa69ab449",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_12.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Composants d'un langage logique: règles d'inférence\n12Il s’agit du coeur du raisonnement d'un agent logiqueObjectif: accroître les connaissances d'un agent\nTELL(\"Aucun étudiant n'aime les examens\")TELL(\"Simon aime les examens\")ASK(\"Est-ce que Simon est un étudiant ?\")NON(1) L’inférence se fait sur base des connaissances de l'agent (obtenue via TELL)\nBase de connaissancesAucun étudiant n'aime les examensSimon aime les examens(2) L’inférence est généralement exécutée lors d'une requête à l'agent (via ASK)\nInférence logiqueSimon n'est pas un étudiantMise à jour des connaissances: la nouvelle formule est ensuite ajoutée à la base de connaissancesEnsemble de règles qui permettent d'obtenir de nouvelles formules validesRègles d’inférence"
      }
    ]
  },
  {
    "id": "6258629c-5ddc-4594-b9f2-936106ea5e7c",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_13.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Types de langages logiques\n13Logique des propositionsLogique des propositions avec clauses de Horn\nLogique temporelleLogique du premier ordreLogique du second ordre...Gain en expressivitéGain en performance\nExpressivité: qualité des connaissances pouvant être intégrées dans la logiquePerformance: qualité et eﬃcacité des raisonnements logiques pouvant être faits"
      }
    ]
  },
  {
    "id": "9b217925-c6ae-4204-9ad7-b73376ef8023",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_14.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Table des matières\n14Agents logiques1. Motivation et déﬁnition d'un agent logique 2. Représentation des connaissances 3. Système logique (syntaxe, sémantique, et règles d'inférences) 4. Formalisation de la logique des propositions 5. Raisonnement par model-checking 6. Inférences logiques et propriétés   7. Algorithme de résolution 8. Clauses de Horn 9. Extension à d'autres systèmes logiques"
      }
    ]
  },
  {
    "id": "517d5463-b1fc-4247-a90b-a7c417a6a7d5",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_15.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Logique des propositions\n15Logique des propositionsLogique des propositions avec clauses de Horn\nLogique temporelleLogique du premier ordreLogique du second ordre...Gain en expressivitéGain en performance"
      }
    ]
  },
  {
    "id": "fef28fb0-5738-4745-a427-f5cecf0c5614",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_16.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Logique des propositions: syntaxe\n16Nature: formules constituées d'un seul symboleConvention: les symboles commencent par une lettre majusculeExemples: A, B, Q, P, Raining, Wet, Dangerous, etc.Deux symboles particuliers: True et False (mots-clef réservés)Element 2: connecteurs logiquesNature: 5 connecteurs sont disponibles dans la logique de propositionsObjectif: permettre d'assembler les formules pour en former des plus complexes\nListe des connecteurs: ¬,∧,∨,⟹,⟺\nNégation: ¬f\nConjonction: f∧g (et)Nature: formules construites récursivement en utilisant les opérateurs logiquesRègles de composition: permet de créer une formule, à partir de deux formules f et g\n𝖡Element 1: formules atomiques (symboles)\n∨Element 3: formules complexes\nB∨C\nDisjunction: f∨g (ou)\nImplication: f⟹g(également avec les symboles →,⊃)\nEquivalence: f⟺g (si et seulement si, également avec le symbole≡)\nToutes les formules ne respectant pas ces règles ne sont pas syntaxiquement valides"
      }
    ]
  },
  {
    "id": "29632310-7aec-4fe7-8f23-a224a11a8be3",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_17.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Syntaxe: exemple\n17Note: Il est permis d'ajouter des parenthèses pour établir les priorités\nAttention: les formules et les opérateurs n'ont aucune signiﬁcation ! Ce sont juste des symboles !PRaining∧Wet(P∧Q)∨(¬(R⟹False)∨A)Oui\nEst-ce que les formules suivantes sont syntaxiquement valides ?Raining¬∧WetRaining∧¬¬¬Wet¬∨BRaining+WetNon (composition non valide)OuiNon (composition non valide)Non (connecteur inconnu)OuiOuiNégation: ¬fConjonction: f∧gDisjunction: f∨gImplication: f⟹gEquivalence: f⟺g\nPriorité des opérateurs: donne un ordre de lecture aux opérateurs\nOrdre de priorité:¬,∧,∨,⟹,⟺\nUn agent basé sur la logique des propositions ne peut ingérer que des formules respectant cette syntaxe"
      }
    ]
  },
  {
    "id": "1128b947-7819-4eb2-8fd5-f9310a78502a",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_18.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Logique des propositions: sémantique\n18Langage logique: la signiﬁcation d'une formule passe par la notion de modèle et de fonction d'interprétationDans le domaine de la logique, un modèle m est une assignation possible d'une valeur  de vérité (true (1) ou false (0)) à chaque symbole présent dans un ensemble de formulesModèle (logique)\nExemple: considérons 3 symboles (Raining, Snowing, Dangerous)Nombre de modèle: on a 8 modèles disponibles (2 * 2 * 2)m1={Raining : true,Snowing : true,Dangerous : true}m2={Raining : false,Snowing : true,Dangerous : true}m3={Raining : true,Snowing : false,Dangerous : true}m8={Raining : false,Snowing : false,Dangerous : false}...Intuition: un modèle correspond à une réalisation possible du monde, caractérisé par la valeur des symbolesAttention: a ce stade, aucun lien avec les formules n'est établiEnsemble des modèlesm1m2m3m4m5m6m7m8\nL’objectif de la sémantique est d’associer à chaque formule valide une signiﬁcation\nEn général, on a 2kmodèles pour k symbolesPoint piégeux: aucune relation n’est encore faite entre un symbole (syntaxe) et son sens (sémantique)"
      }
    ]
  },
  {
    "id": "1dfbe75f-9c00-40b1-b7a3-d0195de55064",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_19.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Logique des propositions: sémantique\n19Objectif: donner une signiﬁcation (un sens) à une formule, étant donné un modèleFonction qui associe la valeur de vérité d'une formule (f) selon un modèle spéciﬁque (m)Fonction d’interprétation\nI(f,m):F×M→{false,true}I(f,m):F×M→{0,1}Valeur de vérité: autre nom donné à la signiﬁcation donnée à une formuleCas 1: formules atomiquesRègle 1: le symbole True (élément de syntaxe) a toujours la valeur de vérité true (sémantique)Règle 2: le symbole False (élément de syntaxe) a toujours la valeur de vérité false (sémantique)\nAttention: grosse source de confusion possible entre ces deux notionsDiﬀérence: le symbole commence par une majuscule, contrairement à la valeur de véritéNotation: pour éviter les confusions, je vais remplacer les valeurs de vérité par 1/0Règle 3: tout autre symbole a directement la valeur de vérité associée à celle déﬁnie dans le modèlem={Raining:true (1), Snowing:true (1), Dangerous:false (0)}Raining:true (1)Snowing:true (1)Dangerous:false (0)\nLa prochaine étape est de déﬁnir cette fonction pour la logique des propositions"
      }
    ]
  },
  {
    "id": "e3037bea-f9ad-4bb3-b1e5-5fd53d4f8f79",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_20.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Logique des propositions: sémantique\n20Cas 2: formules complexesConnecteurs logiques: chaque connecteur implique deux formules (sauf la négation qui en implique une)Table de vérité: déﬁnition des valeurs de vérités d’une formule complexe, pour les 4 possibilités de modèle\n4 modèles possibles\nNégation:¬P est vrai si et seulement si P est faux (et inversément)Nombre de modèles: on a 4 modèles qui sont issus des 2 formules impliqués par le connecteur\nConjonction:P∧Q est vrai si et seulement si P et Q sont tous les deux vrais\nDisjonction:P∨Q est vrai si et seulement si au moins P ou Q est vrai\nImplication:P⟹Q est vrai sauf si P est vrai et Q est faux\nEquivalence:P⟺Q est vrai si P à la même valeur que Q"
      }
    ]
  },
  {
    "id": "8d3487a2-e297-411b-95cb-a51f6e7b7dc2",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_21.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Sémantique: exemple\n21Cas 1: m1={P:1,Q:1,R:0}\nQuelle est la valeur sémantique de cette formule étant donné ces modèles ?f=(¬P∧Q)⟺RP=1¬P=0Q=1R=0¬P∧Q=0f=1Résultat: la formule f est vraie sous m1Cas 2: m2={P:0,Q:1,R:0}P=0¬P=1Q=1R=0¬P∧Q=1f=0Résultat: la formule f est fausse sous m2\nOn a un mécanisme donnant une signiﬁcation à chacune des formules valides en logique des propositions"
      }
    ]
  },
  {
    "id": "ddc71586-4c92-4988-85ee-0def5bc85742",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_22.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Modèles d'une formule\n22Un modèle m est un modèle pour une formule f, si f est vrai sous l'interprétation de mModèles d'une formule\nI(f,m)=1 signiﬁe que m est un modèle pour fOn déﬁnit également M(f), l'ensemble des modèles de la formule fM(f)=tous les modèles m tels que I(f,m)=1\nExemple: f=Raining∨WetSémantiqueSyntaxe\nIntuition: on peut voir une formule comme une représentation compacte d'un ensemble de modèlesM(f)=0101RainingWetNote: ce n’est que réellement maintenant qu’on fait le lien entre sémantique et syntaxeEnsemble des modèlesFormule fM(f)\nLa formule a 3 modèles parmi les 4 modèles existants"
      }
    ]
  },
  {
    "id": "05545529-80fe-4e0b-813b-943eaf054cfa",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_23.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Base de connaissances (knowledge base)\n23Ensemble de formules prises de façon conjointe. Les modèles de la base de connaissances correspondent à l'intersection des modèles de toutes les formules qui la composent  Base de connaissances (knowledge base - KB)\nIntuition: la base de connaissances indique un ensemble de contraintes sur le monde (ce qu’on connait)M(KB)=⋂f∈KBM(f)\nEnsemble des modèlesM(f2)f1=Rain∨SnowM(f1)f2=TraﬃcExemple: KB={Rain∨Snow,Traﬃc}M(KB)\"Il pleut, il ne neige pas et il y a du traﬁc\"  (Rain = 1, Snow = 0, Traﬃc = 1)\"Il ne pleut pas, il ne neige pas, et il n'y a pas de traﬁc\"  (Rain = 0, Snow = 0, Traﬃc = 0)\n\"Il ne pleut pas, il ne neige pas,  et il y a du traﬁc\" (Rain = 0, Snow = 0, Traﬃc = 1)  \nM(KB) donne ainsi l'ensemble des réalisations possibles selon les contraintes (nos connaissances)"
      }
    ]
  },
  {
    "id": "2c3f03af-a402-4df9-af04-f09259801d92",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_24.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Base de connaissances (knowledge base)\n24Base de connaissances: KB={Rain,Rain⟹Wet}Etape 1: détailler le modèle de chaque connaissance\"Il pleut\"M(Rain)=0101RainWet\n\"Lorsqu'il pleut, le sol est mouillé\"M(Rain⟹Wet)=0101RainWet\nM(KB)=0101RainWet\"Il pleut et le sol est mouillé\"Etape 2: prendre l’intersection pour avoir le modèle de la base de connaissances\nDétaillons les modèles d’une base de connaissances à travers un exemple\n0101RainWet0101RainWet∩"
      }
    ]
  },
  {
    "id": "ffa8b397-2edf-4bac-9ba9-57b90358d40a",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_25.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Enrichir la base de connaissances\n25\nUn des intérêts d’une base de connaissances est de pouvoir y ajouter des nouvelles formulesKB→KB∪{f}Mise à jour: l'intersection des deux ensembles donnent les nouveaux modèles de la base de connaissancesConséquence: l’intersection va réduire le nombre de modèles\nQuel est l'impact d'ajouter une formule à la base de connaissance ?Attention: cette réduction peut paraître contre-intuitive !\nObservation: acquérir des connaissances réduit (ou garde) le nombre de modèlesInterprétation: on a une vision plus précise du monde (moins de possibilités)KB={Rain⟹Wet}\"Je sais que lorsqu'il pleut, le sol est mouillé\"KB=KB∪{Rain}\"Je sais maintenant qu'il pleut\"\"Dès lors, je sais maintenant que le sol est mouillé\"\nM(KB)→M(KB)∩M(f)\nM(KB)=0101RainWet\nQuel est l’impact sur les modèles de la base de connaissances ?\nOn a 3 situations qui peuvent se produire"
      }
    ]
  },
  {
    "id": "4718e209-6fb6-4341-9fd7-b7b1aeed3d45",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_26.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Cas 1: Conséquence logique (entailment)\n26Ensemble des modèlesKBfM(KB)M(f)Intuition: la formule f n'ajoute aucune information à la base de connaissanceExplication: toutes les connaissances de f étaient déjà contenues dans la base de connaissances\nTerminologie: on dit également que KB implique logiquement (entails) la formule fSoit KB et une formule f, f est une conséquence logique de KB si et seulement si f est vrai pour chaque modèle où KB est vraiConséquence logique (entailement)\nKB⊨f si et seulement si M(KB)⊆M(f)Exemple: {Raining∧Wet}⊨{Wet}Utilité: permet de vériﬁer si une formule f est toujours vraie si la KB est vraieS’il pleut et que le sol est mouillé… alors, il pleut également\nCas 1: situation où tous les modèles de KB sont inclus dans les modèles de la nouvelle formule"
      }
    ]
  },
  {
    "id": "4048a6e7-ca78-4b0d-974c-6b159e89d61b",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_27.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Cas 2: Contradiction\n27Explication: la nouvelle connaissance obtenue est incompatible avec ce qu'on connait déjàSoit KB et une formule f, f est en contradiction avec KB s'ils n'ont aucun modèle en communContradiction\nKB est en contradiction avec f si et seulement si M(KB)∩M(f)=∅Exemple: {Raining∧Wet} est en contradiction avec {¬Raining}Ensemble des modèlesKBfM(KB)M(f)Intuition: la formule f ajoute une information contradictoire avec la base de connaissance\nUtilité: le principe de contradiction est très fort utilisé pour des raisonnements logiques par l'absurdeIntuition: si on est dans un monde où KB est vrai, alors il est impossible de satisfaire fIl pleut et le sol est mouillé…  et il ne pleut pas… : contradiction\nCas 2: situation où les modèles de KB sont tous diﬀérents des modèles de f"
      }
    ]
  },
  {
    "id": "5e7f599e-b559-4efd-a5b6-caae20737727",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_28.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Cas 3: Contingence\n28Explication: une nouvelle connaissance non triviale a été ajoutée à la base de connaissanceSoit KB et une formule f, f est en contingence avec KB si et seulement si elle n'est ni une conséquence logique de KB, ni en contradictionContingence\n∅⊂M(KB)∩M(f)⊂M(KB)Exemple: {Raining} est en contingence avec {Wet}Ensemble des modèlesKBfM(KB)M(f)Intuition: la formule f est une nouvelle information, non contradictoire, à la base de connaissance\nUtilité: une contingence permet de raﬃner les connaissances que l’agent a à dispositionJe sais qu’il pleut…  j’ai appris également que le sol est mouillé\nCas 3: situation où le nombre de modèles de KB est réduit, sans qu'on ait une contradiction"
      }
    ]
  },
  {
    "id": "6cdf04c8-27d9-4f98-be6c-b8c777ed7d71",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_29.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Relation entre conséquence logique et contradiction\n29KBfEnsemble des modèles\nKBEnsemble des modèles¬f(2) Point de vue d'une conséquence logique: on considère la négation de la formule\nQue peut-on en conclure ?\nKB contredit f si et seulement si KB⊨¬f(1) Point de vue d'une contradiction: supposons qu’on soit dans une situation où f contredit KB\nIl existe une relation intéressante entre conséquence logique et contradiction\nCe résultat va servir de base à plusieurs raisonnements logiques par la suite"
      }
    ]
  },
  {
    "id": "b59fa5fd-937f-438e-8d53-a21868a9ba23",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_30.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Lien avec l'opération TELL\n30Fonction: enrichir les connaissances de l'agent\nTell(Rain)?KB\nQuelles sont les réactions possibles de la part de KB ? \nf est une conséquence logique de KBKB⊨f\nf est en contradiction avec KBKB⊨¬f\nf est en contingence avec KBKB est mis à jourExemple: Je veux intégrer la connaissance \"Il pleut\" à l'agentOpération consistant à donner une nouvelle formule f à la base de connaissancesOpération TELL"
      }
    ]
  },
  {
    "id": "0ce21f58-a80f-4070-be71-a5a241ce9451",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_31.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Lien avec l'opération ASK\n31\nAsk(Rain)?KB\nQuelles sont les réactions possibles de la part de KB ? \nL'agent ne connait pas la réponsef est en contingence avec KB\nLa réponse est OUIKB⊨ff est une conséquence logique de KB\nLa réponse est NONKB⊨¬ff est en contradiction avec KB\nOpération consistant à demander à la KB si une formule est vraie ou fausseOpération ASK\nFonction: obtenir de l’information venant de l’agentExemple: Je veux savoir si il pleut"
      }
    ]
  },
  {
    "id": "bdb70cf5-7b99-4440-969d-5c29f6e424ae",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_32.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Satisﬁabilité d'une base de connaissance\n32Une base de connaissance KB est satisﬁable si elle contient au moins un modèleSatisﬁabilité\nM(KB)≠∅\nPermet de vériﬁer de manière uniﬁée siImportance de la satisﬁabilité(1) Une formule est une conséquence logique d'une KB(2) Une formule est en contradiction avec KBApplicable à la fois pour les opérations TELL et ASK(3) Une formule est en contingence avec KBIllustration: supposons une base de connaissances KB et une formule fKB∪{¬f} est satisﬁable ?Principe: on eﬀectue deux requêtes impliquant f à KBKB⊨f(conséquence logique)NON\nKB et f sont contingentsOUIKB contredit fNONKB∪{f} est satisﬁable ?OUICar la négation de f n'a aucun modèle  commun avec KBCar KB n'a aucun modèle  commun avec fCar KB a un modèle commun à la fois avec f et sa négation\nTâche importante: pouvoir calculer la satisﬁabilitéKBEnsemble des modèles"
      }
    ]
  },
  {
    "id": "f04944b7-ccb8-4390-bf05-cbc233e825f5",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_33.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Vériﬁcation de satisﬁabilité\n33\nComment vériﬁer la satisﬁabilité d'une KB ?\nRequête ASK: Dangerous?\nBase de connaissancesP⟹QL∧M⟹PB∧L⟹MA∧P⟹LA∧B⟹LAB\nBase de connaissancesSnowingRaining⟹WetWet∧Snowing⟹DangerousRaining\nRequête ASK: Q?Model checking: méthode pour vériﬁer la satisﬁabilité d’une KBSatisﬁable: Il s'agit de trouver un moins un modèleNon-satisﬁable: il s'agit de prouver qu'il n'en existe aucunMauvaise nouvelle: il s'agit d'un problème NP-completBonne nouvelle: on a vu des algorithmes pour résoudre cela !Principe: on peut modéliser ce problème comme un CSPSymboles: variables de décision à domaine binaireFormules: contraintes Modèle: assignation complète des variablesAlgorithme DPLL: résolution par backtracking search et pruningWalkSat: résolution par recherche locale intégrant de l'aléatoire Vous pouvez même faire un modèle Minizinc !Description de ces algorithmes en lectures complémentaires"
      }
    ]
  },
  {
    "id": "8f1c11b2-1b1f-40d1-b6e2-c63f3a272815",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_34.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Exemple: utilisation de la satisﬁabilité\n34Requête: Dangerous?\nBase de connaissancesSnowingRaining⟹WetWet∧Snowing⟹DangerousRaining Question 1: est ce que KB∪{¬Dangerous} est satisﬁable ?\nRéponse: NONRésolution: exécution du CSP pour obtenir la réponse\nRésultat: on sait que Dangerous est une conséquence logique de KB"
      }
    ]
  },
  {
    "id": "36cb60ca-8e7a-4c45-9653-fea75bcb7605",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_35.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Exemple: utilisation de la satisﬁabilité\n35Requête: Q?\nBase de connaissancesP⟹¬QL∧M⟹PB∧L⟹MA∧P⟹LA∧B⟹LAB Question 1: est ce que KB∪{¬Q} est satisﬁable ?OUINON Question 2: est ce que KB∪{Q} est satisﬁable ?\nRésultat: on sait que Q est en contradiction avec KB"
      }
    ]
  },
  {
    "id": "f274dc40-8675-41c0-a358-dd95d53a587c",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_36.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Table des matières\n36Agents logiques1. Motivation et déﬁnition d'un agent logique 2. Représentation des connaissances 3. Système logique (syntaxe, sémantique, et règles d'inférences) 4. Formalisation de la logique des propositions 5. Raisonnement par model-checking 6. Inférences logiques et propriétés   7. Algorithme de résolution 8. Clauses de Horn 9. Extension à d'autres systèmes logiques"
      }
    ]
  },
  {
    "id": "ad62b37f-8e6e-4539-b6ea-b9fdcbdbb38a",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_37.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Complexité de la vériﬁcation de satisﬁabilité en logique des proposition\n37\nPeut-on faire mieux ?Implication: on utilise des algorithmes de recherche pour sa résolutionHistorique: SAT est le premier problème prouvé NP-complet (Cook, 1971)Certitude: on aura toujours une complexité exponentielle dans le pire des cas pour une résolution exacte\nBonne nouvelle: permet d'obtenir de meilleures performances en pratique Résolution actuelle: basée sur une stratégie de recherche\nPeut-on exploiter cela dans notre processus de résolution ? Particularité du problème: on a aﬀaire à des formules logiquesOui: on peut utiliser un autre type de processus de résolution, à savoir l'inférence logiqueIntuition: on a un nombre exponentiel de modèles à tester\nFormules logiques: forme spéciﬁque de contraintes\nMalheureusement, trouver un modèle qui satisfait les formules d'une KB est NP-complet (problème SAT)\nRegardons comment exploiter au mieux le fait qu’on travaille avec des formules logiques"
      }
    ]
  },
  {
    "id": "334415c7-3898-461d-bc66-46301062ed8f",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_38.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Schéma de la situation actuelle\n38Model checking: raisonnement possible pour vériﬁer cela en restant dans le monde de la sémantiqueRésultat: si les les modèles d'une formule englobent les modèles de KB, alors elle en conséquence logiquef1f2f3f4...Base de connaissance (KB)\nM(KB)M(fnew)\nfnewSémantiqueSyntaxe"
      }
    ]
  },
  {
    "id": "6856f1c0-a0a0-4e35-85fd-7333fbbdccb2",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_39.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Règles d'inférence\n39f1f2f3f4...Base de connaissance (KB)\nM(KB)M(fnew)\nfnewSémantiqueSyntaxe\nRègles  d'inférences\nPeut-on obtenir un résultat similaire en restant dans le monde de la syntaxe ?Oui: en utilisant des règles d'inférence (troisième élément central d'un système logique)"
      }
    ]
  },
  {
    "id": "ff147486-f398-4eac-8472-020fcd350c41",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_40.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Une inférence logique est un processus par lequel on obtient une nouvelle formule via des formules connuesRègles d'inférence\n40Intuition: une règle d'inférence est une règle qui déﬁnit la façon dont une nouvelle règle peut être générée\nIl existe un très grand nombre de règles d'inférence (certaines étant plus utiles que d'autres)f1,…,fkgRègle d'inférence\nSoit un ensemble de formules f1,f2,…,fk et g.Une règle d'inférence à la forme suivante:Elle indique que la formule g peut être générée à partir des formules f1,…,fk(1) Modus Ponens(3) Règle de résolution(2) Règle d'éliminationPrémices: formules déjà connuesprémicesconclusionConclusion: formule générée en appliquant la règle d'inférence\nCes règles peuvent être utilisées dans la conception d'algorithmes pour obtenir des conséquences logiques"
      }
    ]
  },
  {
    "id": "6feab3d1-1887-4b60-b5dc-33c50f075be5",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_41.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Règle d'inférence: Modus ponens et règle d’élimination\n41Règle d'inférence sous la forme suivante:Modus Ponens\np,p⟹qqavec p et q deux formulesExemple: Rain,Rain⟹WetWet\nRègles d'inférence sous la forme suivante:Règles d'élimination\np∧qqavec p et q deux formulesp∧qpExemple: Rain∧SnowRain\nAttention: les règles d'inférences appartiennent au monde de la syntaxeConséquence: à ce stade, elles n'ont aucune relation avec la sémantiqueAutrement dit, elles n'ont aucune interprétation !Fonctionnement: on ne fait qu'appliquer des règles opérant sur des formulesPrémisse 1: il pleutPrémisse 2: quand il pleut, le sol est mouilléConclusion: le sol est mouillé (Wet)Prémisse 1: Il pleut et il neigeConclusion: il pleut"
      }
    ]
  },
  {
    "id": "5c719d1a-7953-4799-a51f-16c4ae04b395",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_42.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Algorithme générique d'inférences logiques\n42\n𝗅𝗈𝗀𝗂𝖼𝖺𝗅𝖨𝗇𝖿𝖾𝗋𝖾𝗇𝖼𝖾(KB,R):𝗐𝗁𝗂𝗅𝖾KB𝗂𝗌𝗆𝗈𝖽𝗂𝖿𝗂𝖾𝖽:KB=KB∪g𝗋𝖾𝗍𝗎𝗋𝗇KBf1,…,fk=𝗌𝖾𝗅𝖾𝖼𝗍𝖥𝗈𝗋𝗆𝗎𝗅𝖺𝖥𝗋𝗈𝗆(KB)𝗂𝖿𝖺𝗆𝖺𝗍𝖼𝗁𝗂𝗇𝗀𝗋𝗎𝗅𝖾f1,…,fkg𝖾𝗑𝗂𝗌𝗍𝗌𝗂𝗇R:Objectif: on souhaite appliquer un ensemble de règles d'inférence (R) à KBTant qu'on peut rajouter une formule à KBOn sélectionne un ensemble de formules de KBSi une règle d'inférence existe sur les règles sélectionnéesOn ajoute la formule inférée (g) à KBAttention: cet algorithme est encore incomplet pour une utilisation pratique(1) Quelles règles d'inférences utiliser ?(2) Comment sélectionner les formules pertinentes (potentiellement des millions dans une KB)Dérivation de formules\nKB⊢AfS'il est possible d'obtenir une formule f par application d'un algorithme d'inférence A sur une base de connaissance KB, on dit que f est dérivé de KB par AAttention: on est toujours dans le monde de la syntaxe, sans relation faite avec celui de la sémantique\nA ce stade, cet algorithme ne fait que dériver mécaniquement de nouvelles formules"
      }
    ]
  },
  {
    "id": "9077360e-f2d9-4ff0-84c8-508651b40151",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_43.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Exemple de dérivation de formules\n43\nQuelles nouvelles formules peut-on dériver ?\nBase de connaissancesRainRain⟹WetWet⟹SlipperyExample: algorithme (A) utilisant la règle: {p,p⟹qq} (mod ponens)\nRain,Rain⟹WetWet\nWet,Wet⟹SlipperySlipperyKB⊢AWetKB⊢ASlipperyDérivation 1: première application du modus ponens\nBase de connaissancesRainRain⟹WetWet⟹SlipperyWetDérivation 2: deuxième application du modus ponens\nBase de connaissancesRainRain⟹WetWet⟹SlipperyWetSlipperyConvergence: on ne sait plus rien ajouter\nEst-ce que les règles qu'on génère ont du sens ?En pratique: on souhaite générer des règles qui ont un sens sémantique correct"
      }
    ]
  },
  {
    "id": "ba77cbd3-9949-4fd3-b979-3a1353d2d948",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_44.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "On souhaite dériver des règles également correctes d'un point de vue sémantiqueLien avec la sémantique\n44Monde de la syntaxeElement 1: déﬁnition de formules correctes grammaticalementElement 2: moyen de dériver de nouvelles formules (règle d’inférence)\nIntuition: lorsqu’on dérive une formule, on souhaite ne pas dériver n'importe quoi\nPour une formule f, quelles sont les relations possibles entre KB⊢f et KB⊨f?f1f2f3f4...Base de connaissance (KB)\nfnewElement: notion de conséquence logique entre KB et une formuleMonde de la sémantiqueEnsemble des modèlesKBfnewM(KB)M(fnew)Intérêt: donne la garantie que pour chaque modèle de KB, la formule f est également vraieVériﬁcation actuelle: model checking (algorithme de recherche)\nKB⊢fnew\nKB⊨fnew"
      }
    ]
  },
  {
    "id": "2859eea0-89cf-436f-82b2-8a6c8064977f",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_45.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Propriété de cohérence (soundness)\n45Visualisation: on peut considérer que toutes ces formules permettent de remplir exactement un récipientIntuition: ce récipient contient UNIQUEMENT et TOUTES les formules en conséquence logique avec KBPropriété de cohérence (soundness)\nUn algorithme d'inférence A est cohérent (sound) s'il ne  génère QUE des formules en conséquence logique avec KB{fKB⊢Af}⊆{fKB⊨f}Signiﬁcation: on veut générer UNIQUEMENT les formules vraies, et rien d'autreVisualisation: on génère UNIQUEMENT des formules appartenant au récipientPropriété indispensable d'un algorithme d'inférence et des règles liéesIntérêt: nous assure qu'on va jamais générer des formules faussesLimitation: aucune assurance que toutes les formules vraies peuvent être généréesEnsemble des formules vraies (déﬁnition sémantique)\n{fKB⊨f}:ensemble des formules vraies dans le monde de KBEnsemble de toutes les formules en conséquence logique de KBf1f2f6f10f3f20f45f22f30f211f29f18f73{fKB⊨f}"
      }
    ]
  },
  {
    "id": "92a75933-50d0-4d63-9d83-2e349758da47",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_46.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Propriété de complétude (completeness)\n46Propriété de complétude (completeness)\nUn algorithme d'inférence A est complet s'il peut générer TOUTES les formules en conséquence logique avec KB{fKB⊢Af}⊇{fKB⊨f}Signiﬁcation: on veut pouvoir générer TOUTES les formules vraiesVisualisation: on génère TOUTES les formules du récipient, et potentiellement d'autres\nPropriété désirable d'un algorithme d'inférence et des règles liéesIntérêt: assure qu'on peut générer toutes les formules qui sont vraiesLimitation: risque de générer des formules qui ne sont pas vraies\nQue souhaiterions-nous à l'idéal pour notre algorithme d’inférence (A) ?"
      }
    ]
  },
  {
    "id": "bb4d9ab9-9f64-4fb2-ac9d-79280fb9806d",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_47.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Cohérence et complétude\n47Mauvaise nouvelle: ce n'est pas toujours facile (ni possible) à avoir En pratique: on doit souvent se contenter d'une, en préférant la cohérenceAinsi, la complétude est parfois sacriﬁéeCohérence: nous assure de ne générer que des formules vraiesComplétude: nous assure de générer toutes les formules vraies\nVisuellement: on souhaite couvrir tout et uniquement le récipient\n\"Je veux la vérité, toute la vérité, rien que la vérité\"f1f2f6f10f3f20f45f22f30f211f29f18f73\nEst-ce un objectif réaliste ?Prix à payer: perte de performances ou perte d'expressivité\nIdéalement, on souhaite que notre algorithme possède ces deux propriétés\n{fKB⊢Af}⊆{fKB⊨f}{fKB⊢Af}⊇{fKB⊨f}ET"
      }
    ]
  },
  {
    "id": "ca4bf25f-4219-4623-ba6b-b3f26b762cdb",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_48.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Vériﬁcation de la cohérence\n48\nComment s'assurer qu'un algorithme d'inférence est cohérent ?\n𝗅𝗈𝗀𝗂𝖼𝖺𝗅𝖨𝗇𝖿𝖾𝗋𝖾𝗇𝖼𝖾(KB,R):𝗐𝗁𝗂𝗅𝖾KB𝗂𝗌𝗆𝗈𝖽𝗂𝖿𝗂𝖾𝖽:KB=KB∪g𝗋𝖾𝗍𝗎𝗋𝗇KBf1,…,fk=𝗌𝖾𝗅𝖾𝖼𝗍𝖥𝗈𝗋𝗆𝗎𝗅𝖺𝖥𝗋𝗈𝗆(KB)𝗂𝖿𝖺𝗆𝖺𝗍𝖼𝗁𝗂𝗇𝗀𝗋𝗎𝗅𝖾f1,…,fkg𝖾𝗑𝗂𝗌𝗍𝗌𝗂𝗇R:Principe: s'assurer que chaque règle utilisée est cohérenteProcédure: on peut vériﬁer directement les modèles des formules Rain,Rain⟹WetWet\nM(prémices)⊆M(conclusion)\n0101RainWet0101RainWet∩0101RainWet=OK\nEst-ce que la règle du modus ponens (p,p⟹qq) est cohérente ?0101RainWet⊆0101RainWet?Déﬁnition d’une conséquence logique\n{fKB⊢Af}⊆{fKB⊨f}\nVériﬁcation de modèles: M(Rain)∩M(Rain⟹Wet)⊆M(Wet)?\nEn conclusion, la règle du modus ponens est cohérente ! (exemple générique)"
      }
    ]
  },
  {
    "id": "58f39fd6-e91e-4711-aba1-4e38ddbefc43",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_49.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Vériﬁcation de la cohérence\n49Wet,Rain⟹WetRain\nConclusion: la règle n'est pas cohérente !NON\nEst-ce que la règle q,p⟹qp est cohérente ?0101RainWet∩=0101RainWet0101RainWet0101RainWet⊆0101RainWet?\nBonne nouvelle: généralement facile à vériﬁer dans la logique des propositionsVériﬁcation de la cohérenceVériﬁcation: peut se faire via model checking car le nombre de possibilités est généralement faible Cohérence: propriété fondamentale qui nous assure que les formules générées sont vraiesProcédure: on doit vériﬁer que les modèles des prémices sont inclus dans ceux de la conclusion\nVériﬁcation de modèles: M(Wet)∩M(Rain⟹Wet)⊆M(Rain)?\nQuestion de l’examen A2022"
      }
    ]
  },
  {
    "id": "a747ebd2-733f-42f4-9fe9-dc29d28add0f",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_50.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Vériﬁcation de la complétude\n50\nComment s'assurer qu'un algorithme d'inférence est complet ?Besoin: l’algorithme doit pouvoir générer tout ce qui est vrai\nEst-ce qu'un algorithme basé uniquement sur la règle du modus ponens (p,p⟹qq) est complet ?KB={Rain,Rain ∨ Snow⟹ Wet}Soit la KB suivante:Considérons la formule:f=Wet\nEst-ce que f est une conséquence logique de KB ?\"Ce qui est vrai\": les formules en conséquences logiques de KB\n{fKB⊢Af}⊇{fKB⊨f}\nOui: vériﬁcation possible par modèle checking\nEst-ce que f est dérivable par l'algorithme ?\nRègle utilisable: p,p⟹qqNon: le modus ponens n'est pas applicable dans KB\n𝗅𝗈𝗀𝗂𝖼𝖺𝗅𝖨𝗇𝖿𝖾𝗋𝖾𝗇𝖼𝖾(KB,R):𝗐𝗁𝗂𝗅𝖾KB𝗂𝗌𝗆𝗈𝖽𝗂𝖿𝗂𝖾𝖽:KB=KB∪g𝗋𝖾𝗍𝗎𝗋𝗇KBf1,…,fk=𝗌𝖾𝗅𝖾𝖼𝗍𝖥𝗈𝗋𝗆𝗎𝗅𝖺𝖥𝗋𝗈𝗆(KB)𝗂𝖿𝖺𝗆𝖺𝗍𝖼𝗁𝗂𝗇𝗀𝗋𝗎𝗅𝖾f1,…,fkg𝖾𝗑𝗂𝗌𝗍𝗌𝗂𝗇R:\nUn algorithme basé juste sur le modus ponens n'est pas complet dans la logique des propositions"
      }
    ]
  },
  {
    "id": "8632859f-5fb2-4ee6-8297-fa1485f5379e",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_51.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Impact d'un algorithme incomplet\n51Conséquence: l’agent sera incapable de répondre, même si WET est une conséquence logique de KB\nQue peut-on faire pour pallier cette diﬃculté ?\nOption 1: considérer des règles d'inférences plus expressivesOption 2: se rabattre sur une logique plus simple\nQuel est l’impact d’un algorithme d’inférence incomplet ?"
      }
    ]
  },
  {
    "id": "ad4097be-9436-4088-81a8-a04d398ba2e0",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_52.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Table des matières\n52Agents logiques1. Motivation et déﬁnition d'un agent logique 2. Représentation des connaissances 3. Système logique (syntaxe, sémantique, et règles d'inférences) 4. Formalisation de la logique des propositions 5. Raisonnement par model-checking 6. Inférences logiques et propriétés   7. Algorithme de résolution 8. Clauses de Horn 9. Extension à d'autres systèmes logiques"
      }
    ]
  },
  {
    "id": "56c719be-9adb-477f-a440-c10fa140339f",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_53.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Etat de la situation\n53Gain en expressivitéGain en performanceInférence logique (MP)IncompletCohérentToutes les formules  propositionnellesLogique des propositionsLogique des propositions avec clauses de Horn\nLogique temporelleLogique du premier ordreLogique du second ordre..."
      }
    ]
  },
  {
    "id": "902f97e8-af36-46c0-99ea-ad577546e11c",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_54.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Règle de résolution\n54Règle d'inférence sous la forme suivante:Règle de résolution\n(f1∨…∨fn∨p)(¬p∨g1∨…∨gm)f1∨…∨fn∨g1∨…∨gm\nRain∨Snow¬Snow∨WindRain∨WindJe sais qu'il pleut ou qu'il neigeJe sais qu'il vente ou qu'il ne neige pasSi il ne neige pas: alors il pleut obligatoirementSi il neige: alors il vente obligatoirementJe peux alors conclure qu'il pleut ou qu'il vente (ou les deux)Prémices: supposons qu'une formule (p) et sa négation (non p) apparaissent dans deux disjonctions de KBConclusion: alors on peut inférer une nouvelle règle en combinant la conjonction et en retirant la formule \nLe Modus Ponens n’est complet. Pourrait-on envisager d’autres règles d’inférence ?\nExemple: illustration de la règle de résolution"
      }
    ]
  },
  {
    "id": "ddae674b-43ca-43e1-8124-93b1cc37124a",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_55.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Règle de résolution\n55\nEst-ce que la règle de résolution est cohérente ?Rain∨Snow¬Snow∨WindRain∨Wind\nConclusion: la règle de résolution est cohérente ! (formalisation de l'exemple précédent)Note: le principe est similaire pour des conjonctions impliquant plus de formules∩=010,00,1Rain, WindSnow1,01,1010,00,1Rain, WindSnow1,01,1010,00,1Rain, WindSnow1,01,1OK⊆?010,00,1Rain, WindSnow1,01,1010,00,1Rain, WindSnow1,01,1\nEst-ce que la règle de résolution est complète ?Première intuition: il semble que non !\nf:Snow⟹WindKB={Rain∨Snow,¬Snow∨Wind}Limitation: la règle de résolution ne fonctionne pas directement avec des implicationsObservation: La formule f est bien une conséquence logique de KB010,00,1Rain, WindSnow1,01,1010,00,1Rain, WindSnow1,01,1OK⊆?KBf\nVériﬁcation de modèles: M(Rain∨Snow)∩M(¬Snow∨Wind)⊆M(Rain∨Wind)?"
      }
    ]
  },
  {
    "id": "e89b1d7a-1f5b-4eed-9d5c-cfd02ceca36e",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_56.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Propriétés de la règle de résolution\n56\nLimitation: la règle est limitée aux règles n’ayant que des OU logiquesCela empêche notamment les inférences sur des formules ayant des implicationsLa règle de résolution est complète et cohérente en logique des propositionsPropriétés de la règle de résolution\n(f1∨…∨fn∨p)(¬p∨g1∨…∨gm)f1∨…∨fn∨g1∨…∨gmCohérence: démonstration à la diapositive précédenteComplétude: cela semble conte-intuitif !Astuce: on peut transformer n’importe quelle formule en une forme simpliﬁée\nIdée: élaborer des règles de transformations permettant de ramener n’importe quelle formule en clause \nClause: une disjonction (∨) de littérauxExigence sur la forme requise: la règle de résolution ne fonctionne que sur une KB constituées de clauses\nLittéral: un symbole propositionel ou sa négation (P ou ¬P)"
      }
    ]
  },
  {
    "id": "1b1b6c43-6cc6-4fa3-bf76-b31e27945496",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_57.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Forme normale conjonctive et simpliﬁcation\n57Simpliﬁcation de formules en logique des propositions\nN'importe quelle formule f peut être ré-exprimée en une formule CNF équivalente gM(f)=M(g)Précédemment: prendre l'ensemble des formules d'une KB est identique à prendre leur conjonction\n{f1,f2,…,fn} est équivalent à la (grande) formule f1∧f2∧…∧fnForme normale conjonctive (CNF - Conjonctive normal form)\nUne formule CNF est une conjonction (∧) de clauses\nConséquence: une KB peut être représentée comme en CNF si toutes les formules sont des clausesNote: formellement, cela signiﬁe que les deux formules ont exactement les mêmes modèlesIntérêt: assure que la règle de résolution peut être utilisée sur n'importe quelle KB (après simpliﬁcation)Conséquence: n'importe quelle KB peut être transformée en une formule CNFAttention: on n’a pas prouvé que la règle de résolution est complète (preuve en lecture complémentaire)Exemple: KB={Rain∨Snow,¬Snow∨Wind}⟺KB=(Rain∨Snow)∧(¬Snow∨Wind)\nLa base de connaissance est représentée comme une conjonction de deux clauses"
      }
    ]
  },
  {
    "id": "7747855e-3ec0-4af5-af4b-eb328fda48a4",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_58.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Transformation en CNF\n58Etape 1: Elimination des équivalences logiques (⟺)Etape 2: Elimination des implications (⟹)Etape 3: Avancer les négations (¬) pour les coller aux littéraux Etape 4: Eliminer les doubles négations (¬¬)Etape 5: Distribuer les disjonctions (∨) dans les conjonctions (∧)Idée: exploiter successivement des équivalences logiques connues pour transformer la formuleTransformation: fonctionne en 5 étapes successives\nRègle: (f⟺g)((f⟹g)∧(g⟹f))(une équivalence est une implication das les deux sens)\nExercice supplémentaire: vériﬁer l'exactitude de ces formules via model checking\nComment réaliser cette transformation ?\nRègle: (f⟹g)(¬f∨g)\nRègles: ¬(f∨g)¬f∧¬g et ¬(f∧g)¬f∨¬g\nRègle: ¬¬ff\nRègle: f∨(g∧h)(f∨g)∧(f∨h)(application de la Loi de De Morgan)\nOn est ainsi capable de transformer n'importe quelle formule en CNF (logique des propositions)(vériﬁcation triviale par model checking)(deux négations s’annulent mutuellement)"
      }
    ]
  },
  {
    "id": "76487b08-b7ea-44f6-8138-3e429675a2cf",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_59.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Transformation en CNF: exemple\n59\nExemple de transformation pour une formule f:P⟺(Q∨R)Etape 1: Elimination de l'équivalence logiquef:(P⟹(Q∨R))∧((Q∨R)⟹P)f:(¬P∨(Q∨R))∧(¬(Q∨R)∨P)Etape 2: Elimination des implicationsEtape 3: Avancer les négationsf:(¬P∨(Q∨R))∧((¬Q∧¬R)∨P)Etape 4: Retirer les doubles négations (rien à faire)Etape 5: Distribuer les disjonctionsf:(¬P∨(Q∨R))∧(¬Q∨P)∧(¬R∨P)Formule ﬁnale (après retrait des parenthèses inutiles):\nRègle: (f⟺g)((f⟹g)∧(g⟹f))\nRègle: (f⟹g)(¬f∨g)\nRègles: ¬(f∨g)¬f∧¬g et ¬(f∧g)¬f∨¬g\nRègle: ¬¬ff\nRègle: f∨(g∧h)(f∨g)∧(f∨h)\nf:(¬P∨Q∨R)∧(¬Q∨P)∧(¬R∨P) (CNF de 3 clauses)"
      }
    ]
  },
  {
    "id": "83e96511-986a-4075-a30e-def89c4f4684",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_60.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Rappels de concepts\n60\nComment utiliser tous ces mécanismes pour concevoir notre agent ?Ask(Wet)?\nBase de connaissancesRainRain ∨ Snow⟹ Wet\nKB∪{¬f} est non-satisﬁableKB⊨f(conséquence logique)KB et ¬fsont en contradictionPrécédemment: on a vu qu'il existait un lien entre conséquence logique et satisﬁabilité (slide 32)Relation 1: prouver la conséquence logique (KB⊨f) revient à prouver la non satisﬁabilité de KB∪{¬f}Relation 2: de manière équivalente, cela revient à prouver que KB et ¬f sont en contradictionIdée: exploiter ces relations pour établir un algorithme consistant à calculer si la formule peut être inférée Objectif initial: vériﬁer si une formule en requête (ASK) est en conséquence logique avec KB\nNote: pour avoir la certitude d’une réponse correcte, il faut que l’algorithme soit cohérent et complet\nOn va ainsi construire un algorithme basé sur ces principes pour vériﬁer la conséquence logique"
      }
    ]
  },
  {
    "id": "89088bd1-c819-4c36-a34e-6fd6c8dcd4fa",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_61.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Algorithme de résolution\n61Principes de l’algorithme: procédure en 4 étapes:Etape 1: ajouter temporairement ¬f à la base de connaissance (KB)Etape 2: convertir toutes les formules de KB en CNFEtape 3: appliquer répétitivement la règle de résolution à chaque paire de clausesEtape 4: si la clause vide est générée (non-satisﬁabilité), alors on a prouvé la conséquence logique\n𝗋𝖾𝗌𝗈𝗅𝗎𝗍𝗂𝗈𝗇𝖠𝗅𝗀𝗈𝗋𝗂𝗍𝗁𝗆(KB,f):𝖿𝗈𝗋𝖾𝖺𝖼𝗁𝗉𝖺𝗂𝗋(ci,cj)∈(C,C):F=𝖿𝗈𝗋𝗆𝗎𝗅𝖺𝖥𝗋𝗈𝗆(KB)∪{¬f}cnew=𝗋𝖾𝗌𝗈𝗅𝗎𝗍𝗂𝗈𝗇𝖱𝗎𝗅𝖾(ci,cj)𝗂𝖿cnew=∅:𝗋𝖾𝗍𝗎𝗋𝗇𝗍𝗋𝗎𝖾C=𝗍𝗋𝖺𝗇𝗌𝖿𝗈𝗋𝗆𝖨𝗇𝗍𝗈𝖢𝖭𝖥(F)N={}𝗐𝗁𝗂𝗅𝖾𝗍𝗋𝗎𝖾:\nC=C∪NN=N∪{cnew}𝗂𝖿N⊆C:𝗋𝖾𝗍𝗎𝗋𝗇𝖿𝖺𝗅𝗌𝖾Etape 1: ajout temporaire de non f à KBEtape 2: transformation en CNF, ce qui donne un ensemble de clausesEnsemble des nouvelles clauses générées par l'itération actuelleEtape 3: tant que l'algorithme n'a pas su conﬁrmer la conséquence logiqueOn considère toutes les paires de clausesOn applique la règle de résolution dessusEtape 4: si l'ensemble vide est généré, alors la cons. logique est prouvée (contradiction trouvée)On rajoute la nouvelle clause à notre ensembleSi on a rien généré de nouveau, l'algorithme a convergé: f n'est pas une conséquence logiqueOn rajoute les clauses générées à notre ensemble de clause pour la prochaine itération\nL’objectif est de prouver qu'une formule f est une conséquence logique de KB\nIntuition: appliquer la règle de résolution en boucle jusqu’à avoir une réponse (vrai ou faux)"
      }
    ]
  },
  {
    "id": "fa95b437-e504-4dca-92db-da7d056bbf93",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_62.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Algorithme de résolution: exemple\n62Ask(Wet)?\nBase de connaissancesRainRain ∨ Snow⟹ Wet\nEst-ce que Wet est est une cons. logique de KB ?\nKB={Rain,(Rain ∨ Snow)⟹ Wet,¬Wet}Etape 1: ajouter ¬f à la base de connaissance (KB)\nf=WetKB={Rain,(Rain ∨ Snow)⟹ Wet}Etape 2: convertir toutes les formules de KB en CNFEtape 3: appliquer répétitivement la règle de résolution à chaque paire de clausesInférence 1: Rain¬Rain∨WetWet\nKB={Rain,¬Rain∨Wet,¬Snow∨Wet,¬Wet}Inférence 2: ¬WetWet∅\nKB={Rain,¬Rain∨Wet,¬Snow∨Wet,¬Wet,Wet}Contradiction obtenue: Wet est une conséquence logique de KB\nNote: toutes les inférences ne sont pas montrées\nPour rappel, on n’était pas capable de prouver cela avec le modus ponens"
      }
    ]
  },
  {
    "id": "784595e6-1cfa-443c-9670-393038362ade",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_63.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Algorithme de résolution: propriétés\n63\n{fKB⊢Af}⊆{fKB⊨f}CohérenceInférence: basée exclusivement sur la règle de résolutionPrécédemment: on a vu que cette règle est cohérenteBonne nouvelle: l’algorithme de résolution est cohérentPreuve: la clause vide est toujours générée avec une cons. logique\nQu'en est-il de la complexité temporelle ?Considérons que l'on ait n symboles propositionnels impliqués dans KBRègle de résolution: ajout potentiel de clauses d'au plus n-1 symbolesConséquence: un nombre exponentiel de clauses peut ainsi être généréMauvaise nouvelle: l'algorithme a une complexité temporelle exponentielle Note: cela n'est pas étonnant, sachant que c'est un problème NP-completLecture complémentaire: preuve de complétude (par contradiction)\n{fKB⊢Af}⊇{fKB⊨f}ComplétudeBonne nouvelle: l’algorithme de résolution est complet(f1∨…∨fn∨p)(¬p∨g1∨…∨gm)f1∨…∨fn∨g1∨…∨gm\nRègle de résolution"
      }
    ]
  },
  {
    "id": "ffddb8de-53ff-438c-aed1-1cde38b5a2dd",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_64.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Algorithme de résolution: visualisation\n64\nQue pensez-vous de cette exécution ?Visualisation: comme un graphe dirigé(1) Chaque arête correspond à une application de la règle de résolution(2) Chaque noeud correspond à une clause dans KB (présente initialement ou générée)\nAmélioration possible: choisir adéquatement les clauses pour appliquer la règle (heuristique de sélection)\nPeut-on gagner en eﬃcacité ?\nRègle à prouver: f=¬RBase de connaissances: KB={¬P∨Q,¬Q∨R∨P,¬R∨Q,¬Q}Base intermédiaire: KB′ ={¬P∨Q,¬Q∨R∨P,¬R∨Q,¬Q,R}"
      }
    ]
  },
  {
    "id": "a26b2775-3772-4579-a1c7-7b000fe8a56c",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_65.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Table des matières\n65Agents logiques1. Motivation et déﬁnition d'un agent logique 2. Représentation des connaissances 3. Système logique (syntaxe, sémantique, et règles d'inférences) 4. Formalisation de la logique des propositions 5. Raisonnement par model-checking 6. Inférences logiques et propriétés   7. Algorithme de résolution 8. Clauses de Horn 9. Extension à d'autres systèmes logiques"
      }
    ]
  },
  {
    "id": "6089f4c9-989a-400f-88ff-fa904f759908",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_66.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Cas d'étude: le monde de Wumpus\n66Mise en situation: vous entrez dans une grotte en vue de trouver un trésorDiﬃcultés: cette grotte présente plusieurs dangers susceptibles de vous tuer...\nObjectif de l’agent: trouver le lingot d'or sans mourirWumpus: monstre qui vous dévore si vous entrez dans sa caseGrotte: environnement constitué de 16 cases disposées en carréTrous (pits): pièges vous tuant si vous entrez dans la case\nActions: déplacement en haut, bas, gauche, ou droitePosition initiale: en bas à gauche - case (1,1)Capteurs sensoriels: présence d'or, de puanteur, ou d'air frais sur la casePuanteur (stench): information présente aux cases adjacentes du WumpusAir frais (breeze): information présente aux cases adjacentes aux trous\nL'agent n'a connaissance que de sa case, et de ce qu'il a déjà visitéLingot d'or: trésor que doit trouver l'agent\nRaisonnement logique\nDiﬃculté: on doit absolument éviter les cases amenant à la mort de l'agent\nEnvironnement: statique (ne change pas avec le temps), et partiellement observable\nAinsi, le raisonnement par essais-erreurs pour découvrir les cases n’est pas possible dans ce contexte"
      }
    ]
  },
  {
    "id": "110b02d1-c5e0-433e-b864-d3d3ee467c79",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_67.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Le monde de Wumpus: approche de résolution\n67Etape 1: faire l'état de toutes nos connaissances concernant l'environnementEtape 2: les exprimer dans un système logiqueEtape 3: eﬀectuer des inférences pour connaître les cases sécuritairesEtape 4: déplacer l'agent dans ces cases pour obtenir de nouvelles connaissancesConnaissance 1: présence de trous, de Wumpus, et d'un lingot dans la grotteConnaissance 2: les trous relâchent de l'air frais sur les cases adjacentes Connaissance 3: les Wumpus relâchent de la puanteur sur les cases adjacentesChaque case peut contenir: wumpus, trou, lingot, air frais, et puanteurSituation initiale de l’agent: l'agent n'a observé que sa case de départ (1,1)Connaissances observées: rien sur la case (pas de Wumpus, etc., sur la case (1,1))Connaissance du monde: les relations entre air frais/puanteur et Wumpus/trou\nxy"
      }
    ]
  },
  {
    "id": "e8c88acb-3a61-4f1b-a2db-83d47596d98d",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_68.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Le monde de Wumpus: encodage des connaissances\n68P1,1: Vrai s'il y a un trou (pit) dans la case (1,1)W1,1: Vrai s'il y a un Wumpus dans la case (1,1)B1,1: Vrai s'il y a de l'air frais (breeze) dans la case (1,1)Nombre de symboles: 5×16=80Autres cases: même encodage (16 cases au total)\nCombien de symboles propositionnels avons-nous ?S1,1: Vrai s'il y a de la puanteur (stench) dans la case (1,1)L1,1: Vrai s'il y a un lingot dans la case (1,1)\nBase de connaissancesFaits: ¬P1,1,¬W1,1,¬B1,1,¬S1,1,¬L1,1R1: B1,1⟺(P1,2∨P2,1)R2: S1,1⟺(W1,2∨W2,1)La case (1,1) est videIl y a un trou en (1,2) ou (2,1) si et seulement s'il y a de l'air frais en (1,1)Il y a un Wumpus en (1,2) ou (2,1) si et seulement s'il y a de la puanteur en (1,1)\nQuelle(s) action(s) l'agent peut-il prendre pour obtenir plus d'informations sécuritairement ?\nxy\nEncodons toutes ces connaissances dans la logique des propositions\nEtat actuel: on a une base de connaissances pour l’agent"
      }
    ]
  },
  {
    "id": "c7546bab-86d6-44e3-aacd-04725ae6e416",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_69.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Base de connaissancesFaits: ¬P1,1,¬W1,1,¬B1,1,¬S1,1,¬L1,1Le monde de Wumpus: acquisition de connaissances\n69Formule à prouver: ¬P2,1(f)Requête ASK: assurons nous qu'il n'y a pas de trous en (2,1)\nxyEtape 1: ajouter ¬f à la base de connaissance (KB)Etape 2: convertir toutes les formules de KB en CNFEtape 3: appliquer répétitivement la règle de résolution à chaque paire de clausesEtape 4: si la clause vide est générée (non-satisﬁabilité), alors on a a prouvé la conséquence logique\nO: P2,1R1-C1: ¬B1,1∨P1,2∨P2,1R1-C2: ¬P1,2∨B1,1R1-C3: ¬P2,1∨B1,1R2-C1: ¬S1,1∨W1,2∨W2,1R2-C2: ¬W1,2∨S1,1R2-C3: ¬W2,1∨S1,1Inférence 1 (R1-C2 avec un fait): ¬P2,1∨B1,1¬B1,1¬P2,1\nN-C1: ¬P2,1Inférence 2 (N-C1 avec O): ¬P2,1P2,1∅On a prouvé f: certitude qu'il n'y a pas de trous en (2,1)Même raisonnement: il n'y pas de Wumpus en (2,1)Même raisonnement: il n'y pas de trous en (1,2)Même raisonnement: il n'y pas de Wumpus en (1,2)(f1∨…∨fn∨p)(¬p∨g1∨…∨gm)f1∨…∨fn∨g1∨…∨gm\nObtenons de nouvelles connaissances via l’algorithme de résolution!\nRésultat: contradiction"
      }
    ]
  },
  {
    "id": "8a08dc13-ffc2-439e-8f8a-8cff152ce5ba",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_70.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Le monde de Wumpus: acquisition de connaissances\n70\nActions de l’agent: on peut découvrir dans risque ce qu'il y a en (1,2) et (2,1)xyCase (1,2): présence uniquement de puanteurCase (2,1): présence uniquement d'air fraisR3: B2,1⟺(P1,1∨P3,1∨P2,2)R4: S2,1⟺(W1,1∨W3,1∨W2,2)R5: B1,2⟺(P1,1∨P1,3∨P2,2)R6: S1,2⟺(W1,1∨W1,3∨W2,2)\nBase de connaissancesR1-C1: ¬B1,1∨P1,2∨P2,1R1-C2: ¬P1,2∨B1,1R1-C3: ¬P2,1∨B1,1R2-C1: ¬S1,1∨W1,2∨W2,1R2-C2: ¬W1,2∨S1,1R2-C3: ¬W2,1∨S1,1Faits: ¬P1,1,¬W1,1,¬B1,1,¬S1,1,¬L1,1Faits: ¬P2,1,¬W2,1,B2,1,¬S2,1,¬L2,1Faits: ¬P1,2,¬W1,2,¬B1,2,S1,2,¬L1,2R3-C1: ¬B2,1∨P1,1∨P3,1∨P2,2R3-C2: ¬P1,1∨B2,1R3-C3: ¬P3,1∨B2,1R3-C4: ¬P2,2∨B2,1R4-C1: ¬S2,1∨W1,1∨W3,1∨W2,2R4-C2: ¬W1,1∨S2,1R4-C3: ¬W3,1∨S2,1R4-C4: ¬W2,2∨S2,1R5-C1: ¬B1,2∨P1,1∨P1,3∨P2,2R5-C2: ¬P1,1∨B1,2R5-C3: ¬P1,3∨B1,2R5-C4: ¬P2,2∨B1,2R6-C1: ¬S1,2∨W1,1∨W1,3∨W2,2R6-C2: ¬W1,1∨S1,2R6-C3: ¬W1,3∨S1,2R6-C4: ¬W2,2∨S1,2Connaissances: mise-à-jour avec les nouvelles informations¬P2,1,¬W2,1,B2,1,¬S2,1,¬L2,1¬P1,2,¬W1,2,¬B1,2,S1,2,¬L1,2\nOn peut continuer le processus pour obtenir de nouvelles connaissances"
      }
    ]
  },
  {
    "id": "0bcb4a37-b811-46ad-a323-495e2efb7723",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_71.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Le monde de Wumpus: acquisition de connaissances\n71\nxy\nBase de connaissancesR1-C1: ¬B1,1∨P1,2∨P2,1R1-C2: ¬P1,2∨B1,1R1-C3: ¬P2,1∨B1,1R2-C1: ¬S1,1∨W1,2∨W2,1R2-C2: ¬W1,2∨S1,1R2-C3: ¬W2,1∨S1,1Faits: ¬P1,1,¬W1,1,¬B1,1,¬S1,1,¬L1,1Faits: ¬P2,1,¬W2,1,B2,1,¬S2,1,¬L2,1Faits: ¬P1,2,¬W1,2,¬B1,2,S1,2,¬L1,2R3-C1: ¬B2,1∨P1,1∨P3,1∨P2,2R3-C2: ¬P1,1∨B2,1R3-C3: ¬P3,1∨B2,1R3-C4: ¬P2,2∨B2,1R4-C1: ¬S2,1∨W1,1∨W3,1∨W2,2R4-C2: ¬W1,1∨S2,1R4-C3: ¬W3,1∨S2,1R4-C4: ¬W2,2∨S2,1R5-C1: ¬B1,2∨P1,1∨P1,3∨P2,2R5-C2: ¬P1,1∨B1,2R5-C3: ¬P1,3∨B1,2R5-C4: ¬P2,2∨B1,2R6-C1: ¬S1,2∨W1,1∨W1,3∨W2,2R6-C2: ¬W1,1∨S1,2R6-C3: ¬W1,3∨S1,2R6-C4: ¬W2,2∨S1,2\nEst-il sécuritaire de se déplacer en (2,2) ?Diﬃculté: information est non triviale à obtenirObservation 1: Par l'air frais en (2,1), il est possible qu'il y ait un trou en (2,2)Observation 2: Par la puanteur en (1,2), il est possible qu'il y ait un Wumpus en (2,2)\nAppliquons l’algorithme de résolution pour répondre à cette question"
      }
    ]
  },
  {
    "id": "c8de8682-ac2c-46d9-9cc2-19135b321d0c",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_72.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Le monde de Wumpus\n72\nxy\nBase de connaissancesR1-C1: ¬B1,1∨P1,2∨P2,1R1-C2: ¬P1,2∨B1,1R1-C3: ¬P2,1∨B1,1R2-C1: ¬S1,1∨W1,2∨W2,1R2-C2: ¬W1,2∨S1,1R2-C3: ¬W2,1∨S1,1Faits: ¬P1,1,¬W1,1,¬B1,1,¬S1,1,¬L1,1Faits: ¬P2,1,¬W2,1,B2,1,¬S2,1,¬L2,1Faits: ¬P1,2,¬W1,2,¬B1,2,S1,2,¬L1,2R3-C1: ¬B2,1∨P1,1∨P3,1∨P2,2R3-C2: ¬P1,1∨B2,1R3-C3: ¬P3,1∨B2,1R3-C4: ¬P2,2∨B2,1R4-C1: ¬S2,1∨W1,1∨W3,1∨W2,2R4-C2: ¬W1,1∨S2,1R4-C3: ¬W3,1∨S2,1R4-C4: ¬W2,2∨S2,1R5-C1: ¬B1,2∨P1,1∨P1,3∨P2,2R5-C2: ¬P1,1∨B1,2R5-C3: ¬P1,3∨B1,2R5-C4: ¬P2,2∨B1,2R6-C1: ¬S1,2∨W1,1∨W1,3∨W2,2R6-C2: ¬W1,1∨S1,2R6-C3: ¬W1,3∨S1,2R6-C4: ¬W2,2∨S1,2Formule à prouver: f:¬W2,2 (observez ce qui est mis dans KB)O: W2,2Inférence 1 (R4-C4 avec un fait): ¬W2,2∨S2,1¬S2,1¬W2,2Inférence 2(N-C1 avec O): ¬W2,2W2,2∅N-C1: ¬W2,2\nConclusion: il n'y a pas de Wumpus en (2,2)Requête ASK: pas de Wumpus en (2,2)"
      }
    ]
  },
  {
    "id": "7f0cc24d-fbfc-4bc7-b746-0b037ce10073",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_73.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Le monde de Wumpus\n73\nBase de connaissancesR1-C1: ¬B1,1∨P1,2∨P2,1R1-C2: ¬P1,2∨B1,1R1-C3: ¬P2,1∨B1,1R2-C1: ¬S1,1∨W1,2∨W2,1R2-C2: ¬W1,2∨S1,1R2-C3: ¬W2,1∨S1,1Faits: ¬P1,1,¬W1,1,¬B1,1,¬S1,1,¬L1,1Faits: ¬P2,1,¬W2,1,B2,1,¬S2,1,¬L2,1Faits: ¬P1,2,¬W1,2,¬B1,2,S1,2,¬L1,2R3-C1: ¬B2,1∨P1,1∨P3,1∨P2,2R3-C2: ¬P1,1∨B2,1R3-C3: ¬P3,1∨B2,1R3-C4: ¬P2,2∨B2,1R4-C1: ¬S2,1∨W1,1∨W3,1∨W2,2R4-C2: ¬W1,1∨S2,1R4-C3: ¬W3,1∨S2,1R4-C4: ¬W2,2∨S2,1R5-C1: ¬B1,2∨P1,1∨P1,3∨P2,2R5-C2: ¬P1,1∨B1,2R5-C3: ¬P1,3∨B1,2R5-C4: ¬P2,2∨B1,2R6-C1: ¬S1,2∨W1,1∨W1,3∨W2,2R6-C2: ¬W1,1∨S1,2R6-C3: ¬W1,3∨S1,2R6-C4: ¬W2,2∨S1,2Formule à prouver: f:¬P2,2 (observez ce qui est mis dans KB)O: P2,2Inférence 1 (R5-C4 avec un fait): ¬P2,2∨B1,2¬B1,2¬P2,2Inférence 2 (N-C1 avec O): ¬P2,2P2,2∅N-C1: ¬P2,2Requête ASK: pas de trous en (2,2)\nConclusion: il n'y a pas de trous en (2,2)\nxy"
      }
    ]
  },
  {
    "id": "13e4ed31-77d4-49b7-a6bf-7add133a46dd",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_74.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Le monde de Wumpus\n74Certitude: on peut se déplacer de façon sécuritaire sur (2,2)Ensuite: on obtient de la nouvelle information, et on recommence…\nQuelles sont les diﬃcultés de notre approche ?\nMitigation possible: utiliser un système logique moins complexe (mais moins expressif)Diﬃculté 1: manque de concisionTaille du problème: on a énormément de symboles et de formules dans notre base de connaissancesObservation: un grand nombre de formules ont une structure très similaireMise à l’échelle: le nombre de formules grandit très vite avec l'acquisition de nouvelles connaissances\nR1: B1,1⟺(P1,2∨P2,1)R2: B2,1⟺(P1,1∨P3,1∨P2,2)R3: B1,2⟺(P1,1∨P1,3∨P2,2)\nR4: S1,1⟺(W1,2∨W2,1)R5: S2,1⟺(W1,1∨W3,1∨W2,2)R6: S1,2⟺(W1,1∨W1,3∨W2,2)Conséquence: les preuves de conséquence logique peuvent être très coûteuses à réaliserMitigation possible: utiliser un système logique plus expressif (mais plus complexe/coûteux)\nAu ﬁnal: on sera capable d’atteindre l’or qu’avec des raisonnements logiques\nDiﬃculté 2: complexité exponentielle de l’algorithme"
      }
    ]
  },
  {
    "id": "c578b517-6ae8-4380-b7c5-9095bd1c9b86",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_75.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Table des matières\n75Agents logiques1. Motivation et déﬁnition d'un agent logique 2. Représentation des connaissances 3. Système logique (syntaxe, sémantique, et règles d'inférences) 4. Formalisation de la logique des propositions 5. Raisonnement par model-checking 6. Inférences logiques et propriétés   7. Algorithme de résolution 8. Clauses de Horn 9. Extension à d'autres systèmes logiques"
      }
    ]
  },
  {
    "id": "8c641bfc-a109-4bac-9aad-51854434a2f9",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_76.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Logique des propositions avec l'algorithme de résolution\n76Gain en expressivitéGain en performanceAlgorithme de résolutionCompletCohérentComplexité exponentielleToutes les formules  propositionnellesLogique des propositionsLogique des propositions avec clauses de Horn\nLogique temporelleLogique du premier ordreLogique du second ordre..."
      }
    ]
  },
  {
    "id": "c9735d95-0cff-4fb6-8ce0-c28e34508a7b",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_77.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Logique des propositions avec clauses de Horn\n77Gain en expressivitéGain en performanceSeulement les  clauses de HornInférence logique (MP)CompletCohérentComplexité linéaireLogique des propositionsLogique des propositions avec clauses de Horn\nLogique temporelleLogique du premier ordreLogique du second ordre..."
      }
    ]
  },
  {
    "id": "93ec8c60-0f3d-4002-a2af-aef5a68e81af",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_78.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Logique des propositions avec clauses de Horn\n78Algorithme de résolution: génération d’un nombre exponentiel de clausesEn théorie: c’est le cas de tout algorithme cohérent et complet (si P != NP) Astuce: c’est vrai tant qu'on reste dans la logique des propositions !\nPeut-on considérer une autre logique avec de meilleures propriétés ?Cas 1: une logique plus expressive sera également plus coûteuse au niveau des inférencesCas 2: à l’inverse, une logique moins expressive peut être moins coûteuse à raisonnerLogique des propositions avec clauses de Horn\nForme simpliﬁée de la logique des propositions qui contient que des clauses de Horn\nA. Horn (1918-2001)Intérêt: ces algorithmes peuvent à la fois être cohérents et complets !Prix à payer: on est limité aux clauses de Horn pour représenter nos connaissancesClause de Horn: type particulier de clauses (déﬁnie aux diapositives suivantes)Intérêt: on peut concevoir des algorithmes d’inférence à complexité temporelle linéaire ! \nCette logique sacriﬁe un peu d’expressivité pour améliorer le processus d’inférence"
      }
    ]
  },
  {
    "id": "7fce3a58-2f6c-4429-9879-d762591ad1f7",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_79.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Deﬁnite clauses et goal clauses\n79Deﬁnite clause (Clause déﬁnie)\nClause (disjonction de littéraux) ayant exactement un littéral qui est positifS'exprime également sous la forme suivantef:P∨¬Q1∨¬Q2∨…∨¬Qnf:(Q1∧Q2∧…∧Qn)⟹PNote: la deuxième expression est obtenue via l'application de deux règles(¬f∨g)(f⟹g)Objectif de la deuxième expression: mettre en évidence une implication entre deux formules ¬f1∨…∨¬fn¬(f1∧…∧fn)\nInterprétation: si Q1,…,Qn sont tous vraies, alors P l'est égalementGoal clause (Clause de but)\nClause (disjonction de littéraux) n’ayant aucun littéral positifS'exprime également sous la forme suivantef:¬Q1∨¬Q2∨…∨¬Qnf:(Q1∧Q2∧…∧Qn)⟹falseObjectif: mettre en évidence que la formule est vraie si au moins un symbole est fauxUne clause constituée d'un seul littéral est appelé un fait (fact)f:R"
      }
    ]
  },
  {
    "id": "05412358-45d2-4ca9-baa0-535f259cab6f",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_80.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Clause de Horn\n80Clause de Horn\nClause (disjonction de littéraux) ayant au plus un littéral qui est positif:(1) Soit une deﬁnite clause(2) Soit une goal clausef:(Q1∧Q2∧…∧Qn)⟹PLogique des propositions avec clauses de Horn: système logique qui ne contient que des clauses de Hornf:(Q1∧Q2∧…∧Qn)⟹falseConséquence: on a un sytème plus restrictif que la logique des propositions standard\nQuel est l'avantage de cette restriction ?Intérêt: le Modus Ponens est suﬃsant pour construire des algorithmes d'inférence cohérent et complet\nComplexité de ces algorithmes: complexité linéaire en fonction de la taille de la base de connaissancesExemples: algorithme du chaînage avant et du chaînage arrière (lectures complémentaires)\nMP généralisé:p1,…,pn(p1∧…∧pn)⟹qqRainSnow(Rain∧Snow)⟹DangerousDangerousSi il pleut et neige actuellement, et si je sais que la pluie avec de la neige sont dangereux, alors la situation actuelle est dangereuse Intuition: on observe que les clauses de Horn correspondent au type de formules attendues dans le MP"
      }
    ]
  },
  {
    "id": "1b0b2af5-7bfb-418f-a064-9f45c3c53bc9",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_81.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Table des matières\n81Agents logiques1. Motivation et déﬁnition d'un agent logique 2. Représentation des connaissances 3. Système logique (syntaxe, sémantique, et règles d'inférences) 4. Formalisation de la logique des propositions 5. Raisonnement par model-checking 6. Inférences logiques et propriétés   7. Algorithme de résolution 8. Clauses de Horn 9. Extension à d'autres systèmes logiques"
      }
    ]
  },
  {
    "id": "ec19bbb9-bb71-4121-952b-ff5487583057",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_82.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Etat actuel de nos logiques\n82Gain en expressivitéGain en performanceSeulement les  clauses de HornInférence logique (MP)Cohérent et completComplexité linéaireLogique des propositionsLogique des propositions avec clauses de Horn\nLogique temporelleLogique du premier ordreLogique du second ordre...Algorithme de résolutionComplexité exponentielleToutes les formules  propositionnellesCohérent et complet"
      }
    ]
  },
  {
    "id": "503230e9-f4d8-4a39-ac69-3b92649d17c2",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_83.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Logiques plus expressives\n83Gain en expressivitéGain en performanceLogique des propositionsLogique des propositions avec clauses de Horn\nLogique temporelleLogique du premier ordreLogique du second ordre...Formules plus expressives"
      }
    ]
  },
  {
    "id": "14c8c697-9f22-4e21-9c7f-779ec3f1e444",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_84.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Limitation de l'expressivité de la logique des propositions\n84\nQuelles sont les limitations de la logique des propositions ?Observation: certaines connaissances peuvent être très verbeusesExemple 2: tous les étudiants qui suivent INF8175 connaissent Python\n(QuentinIsStudent∧QuentinFollowsINF8175)⟹QuentinKnowsPython(AliceIsStudent∧AliceFollowsINF8175)⟹AliceKnowsPython(SimonIsStudent∧SimonFollowsINF8175)⟹SimonKnowsPython...(pour tous les étudiants)Ensembles non-ﬁni: \"Tous les nombres pairs sont divisibles par deux\"Connaissances temporelles:  \"A 17h, il y a toujours du traﬁc à Montréal\"Connaissances ﬂoues: \"La ville de Montréal est grande\" (grande est un terme vague)Connaissances incertaines: \"Il y a 50% de chance qu'il pleuve demain »Diﬃculté 2: des connaissances sont inexprimables par la logique des propositions Diﬃculté 1: manque de concision\nExemple 1: notre situation du monde de Wumpus"
      }
    ]
  },
  {
    "id": "aba98b9a-0b70-47de-909d-86d95d69d993",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_85.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Logique du premier ordre (ou logique des prédicats - ﬁrst-order logic)\n85Objets: Quentin, maison, nombres, étudiants, Montréal, jaune, voiture, etc.Relations entre objets: est le frère de, se produit après, a la couleur, est inscrit à, etc.Fonctions (relation avec une seule valeur par input): est le père de, est la capitale de, etc. Quantiﬁcateur universel: \"pour tout\"Quantiﬁcateur existentiel: \"il existe\"\n∀,∃L'entièreté des éléments de la logique des propositions est également disponible\nf:∃x(Student(x)⟹UnderstandsQuantumPhysics(x))Exemple 1: tous les étudiants qui suivent INF8175 connaissent PythonExemple 2: il existe au moins un étudiant qui comprend la physique quantique\nf:∀x((Student(x)∧FollowsINF8175(x))⟹KnowsPython(x))Exemple 3: tous les nombres pairs sont divisibles par 2\nf:∀x((Number(x)∧Even(x))⟹DivisibleBy2(x))\nExtension de la logique des prop. avec des objets, des relations, des fonctions, et 2 quantiﬁcateurs"
      }
    ]
  },
  {
    "id": "b4b7dcb3-951f-4915-ba00-64a1be83a4c0",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_86.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Logique temporelle (temporal logic)\n86Suivant (next - ◯f): la formule f doit tenir à l'instant suivantGloballement (globally - □f): la formule f doit toujours tenir dans le futurReprésentation du temps: discrétisation en une séquence d'instantJusqu'à ce que (until - f𝒰g): la formule f doit être vraie jusqu'à ce que g soit vraieParticularité: la valeur de vérité d'une formule peut changer avec le tempsExemple 1: quand on est triste, on devient heureux plus tardFinalement (ﬁnally - ◊f): la formule f doit devenir vraie au moins une fois dans le futur\nExemple 2: quand je commence un cours, je parle jusqu'à ce que le cours soit ﬁni\nf:□((¬Passport∨¬BoardingPass)⟹◯¬Boarding)Exemple 3: en tout temps, si je n'ai pas de passeport ou de ticket, je ne peux pas monter dans un avion\nExtension de la logique des prop. avec des opérateurs temporels\nf:Sad⟹◊HappySadHappy\nf:StartLecture⟹(Talking 𝒰EndLecture)StartLectEndLectTalkTalkTalkTalkTalk\n◯,□◊,𝒰"
      }
    ]
  },
  {
    "id": "fe4d8bfc-1e09-4759-a757-125b38b6cd07",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_87.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Logique ﬂoue (fuzzy logic)\n87Idée: au lieu d'avoir une valeur sémantique vrai/faux, on considère un degré de conﬁance entre 0 et 1Intérêt: permet d'exprimer des connaissances qui ne sont pas absolues mais relatives \nExemple 1: Montréal est une grande ville\nNewYorkBig=0.9: indique que New-York est également grande, mais plus que MontréalExemple 2: New York est une grande ville\nMontrealBig=0.7: indique que Montréal est grande avec une vérité relative de 0.7Mise en situation: comment exprimer qu'une vitesse est rapide ?Logique des propositions: ﬁxer un seuil de séparation arbitraire (p.e., 100 km/h)Logique ﬂoue: autoriser une transition progressive du faux vers le vrai\n10090807060110FVkm/h\n1009080706011001km/h\nExtension de la logique des propositions en rajoutant la notion de vérité partielle"
      }
    ]
  },
  {
    "id": "f664e654-bda6-49d1-86db-39ec76297a22",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_88.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Logique probabiliste (probabilistic reasoning)\n88Idée: au lieu d'avoir une valeur binaire pour chaque modèle, on a une probabilité d'occurence0101RainingWet.1.2.2.50101RainingWetDiﬃculté: demande de connaître les probabilités d'occurence d'évènements (ou de savoir les estimer)\nLogique probabiliste: intégration de probabilités\nP(Raining)=0.2+0.5=0.7Exemple 1: quelle est la probabilité qu'il pleuve ?Exemple 2: quelle est la probabilité qu'il pleuve et que le sol soit mouillé ?\nP(Raining∧Wet)=0.5Exemple 3: quelle est la probabilité qu'il pleuve sans que le sol soit mouillé ?\nP(Raining∧¬Wet)=0.2.1.2.2.50101RainingWet.1.2.2.50101RainingWet.1.2.2.50101RainingWetAttention: notez la diﬀérence avec la logique ﬂoue où les connaissances sont connues mais non absoluesLogique des propositions: f=Raining∨Wet\nExtension de la logique des prop. avec des probabilités pour tenir compte de situations incertaines"
      }
    ]
  },
  {
    "id": "b1f37b55-533e-4ddb-845a-831d0c69fcbc",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_89.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Table des matières\n89Agents logiques1. Motivation et déﬁnition d'un agent logique 2. Représentation des connaissances 3. Système logique (syntaxe, sémantique, et règles d'inférences) 4. Formalisation de la logique des propositions 5. Raisonnement par model-checking 6. Inférences logiques et propriétés   7. Algorithme de résolution 8. Clauses de Horn 9. Extension à d'autres systèmes logiques"
      }
    ]
  },
  {
    "id": "ced563c2-aaae-4028-915c-e0ca09369529",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_90.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Synthèse des notions vues\n90Langage logiqueSyntaxe: déﬁnit un ensemble de formules validesSémantique: déﬁnit la signiﬁcation d'une formuleRègles d'inférence: façon d'obtenir de nouvelles connaissances\nObjectif: raisonner sur base d'un ensemble de connaissancesComposé de 3 éléments fondamentauxVériﬁcation par model checkingVériﬁcation de la satisﬁabilité d'une formule basée sur les modèles (sémantique)\nRésolution: via des méthodes de rechercheLimitation: ne tient pas compte qu'on a des formules logiquesAlgorithmes d'inférencesAlgorithme de résolution: cohérent et complet dans la logique des propositionsCohérence: assure que l'algorithme ne génère que des formules vraiesComplétude: assure que l'algorithme génère toutes les formules vraies existantesAlgorithme utilisé pour inférer des nouvelles connaissances en conséquence logique de KB"
      }
    ]
  },
  {
    "id": "7856dc05-29a4-422c-8091-855bf433b843",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_91.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Aller plus loin en programmation logique\n91Bonne nouvelle: les notions vues sont valides pour d'autres systèmes logiquesDiﬀérence: au niveau de la syntaxe, sémantique, et règles d'inférenceAutres logiques: premier ordre, temporelle, ﬂoue, probabiliste, etc.En fonction de vos besoins, vous pouvez sélectionner la logique la plus appropriéeImplémentation: langages déclaratifs permettant d’utiliser des langages logiquesProlog: le plus populaire, réalisant des inférences logiques sur des clauses de HornNuSMV: langage permettant une résolution basée sur du model checkingMinizinc: propose une interface avec le solveur Chuﬀed (apprentissage des clauses)\nINF8225: I.A.: techniques probabilistes et d'apprentissage (Christopher Pal)Cours consacré en partie au raisonnement probabiliste\nRecherche scientiﬁque: paradigme de l’intelligence neuro-symboliquePrincipe: améliorer l’apprentissage profond avec des raisonnements logiques"
      }
    ]
  },
  {
    "id": "0b92ee9a-fd7b-44f4-8b8d-6059512fd34f",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_92.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "Exemples de questions d'examen\n921. Savoir comparer diﬀérents algorithmes dédiés à la logique (model checking, résolution, etc.) 2. Savoir appliquer l'algorithme de résolution 3. Savoir indiquer si un algorithme d'inférence est cohérent et/ou completThéoriePratique1. Expliquer ce qu'est un langage logique et ses diﬀérentes composantes 2. Comprendre le fonctionnement de la logique des propositions 3. Comprendre les notions de cohérence et de complétude pour un algorithme d'inférence"
      }
    ]
  },
  {
    "id": "dbd1de39-31d4-4a5a-9512-2c9d27afa0a9",
    "image": "src\\convert_to_llava_format\\llava_training_data\\images\\M5-agent-logique_page_93.png",
    "conversations": [
      {
        "from": "human",
        "value": "<image>\nExplain the content of this page from the AI course material."
      },
      {
        "from": "gpt",
        "value": "INF8175 - Intelligence artiﬁcielleMéthodes et algorithmesAgents logiques: FIN\nDALLE: The world of wumpus, painted by Vermeer"
      }
    ]
  }
]